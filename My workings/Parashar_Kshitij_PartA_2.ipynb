{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0edc610-21e6-4cc7-9603-59318b961990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e12861-4713-4914-9f4b-8a7381708243",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1a982-de85-46de-b890-3b81f79f5887",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from common_utils import MLP, CustomDataset, loss_fn, split_dataset, preprocess_dataset\n",
    "\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, ['filename', 'label'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae6b33318200b4bc38d431576963edb1",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
   "metadata": {
    "deletable": false,
    "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02dac62baa528c191eb4f47b2495406",
     "grade": false,
     "grade_id": "dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "\n",
    "    X_train_scaled_dict = {}\n",
    "    X_val_scaled_dict = {}\n",
    "    y_train_dict = {}\n",
    "    y_val_dict = {}\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    \n",
    "    for batch_size in parameters:\n",
    "        X_train_folds = []\n",
    "        X_val_folds = []\n",
    "        y_train_folds = []\n",
    "        y_val_folds = []\n",
    "#         print(batch_size)\n",
    "        \n",
    "        for i, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "#             print(f\"Fold {i}:\")\n",
    "#             print(f\"  Train: index={train_index}\")\n",
    "#             print(f\"  Test:  index={val_index}\")\n",
    "            \n",
    "            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "#             print(len(X_train_fold))\n",
    "            # Preprocess the data\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "            X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "            X_train_folds.append(X_train_fold_scaled)\n",
    "            X_val_folds.append(X_val_fold_scaled)\n",
    "            y_train_folds.append(y_train_fold)\n",
    "            y_val_folds.append(y_val_fold)\n",
    "\n",
    "        X_train_scaled_dict[batch_size] = X_train_folds\n",
    "        X_val_scaled_dict[batch_size] = X_val_folds\n",
    "        y_train_dict[batch_size] = y_train_folds\n",
    "        y_val_dict[batch_size] = y_val_folds\n",
    "        \n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ca332-9676-42bd-9801-0f5f4157a777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "235ca332-9676-42bd-9801-0f5f4157a777",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ae5f281cd84f4d36f81f2ae126cf915",
     "grade": true,
     "grade_id": "correct_dataset",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf6be1ad49306172e6f27243e613f2",
     "grade": true,
     "grade_id": "correct_dataset2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
   "metadata": {
    "deletable": false,
    "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9665887943f38ae7bed6c1d8351903b",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kp27d\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ..\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128, fold: 1| Epoch 1: Train_accuracy: 53.65%, Train_loss: 0.688948, Test_accuracy: 57.29%, Test_loss: 0.680288\n",
      "batch size: 128, fold: 1| Epoch 2: Train_accuracy: 57.58%, Train_loss: 0.677010, Test_accuracy: 59.30%, Test_loss: 0.669738\n",
      "batch size: 128, fold: 1| Epoch 3: Train_accuracy: 60.61%, Train_loss: 0.664578, Test_accuracy: 63.21%, Test_loss: 0.650207\n",
      "batch size: 128, fold: 1| Epoch 4: Train_accuracy: 62.06%, Train_loss: 0.651599, Test_accuracy: 62.38%, Test_loss: 0.652181\n",
      "batch size: 128, fold: 1| Epoch 5: Train_accuracy: 63.84%, Train_loss: 0.639158, Test_accuracy: 62.26%, Test_loss: 0.653279\n",
      "batch size: 128, fold: 1| Epoch 6: Train_accuracy: 65.37%, Train_loss: 0.627340, Test_accuracy: 63.09%, Test_loss: 0.653990\n",
      "batch size: 128, fold: 1| Epoch 7: Train_accuracy: 67.32%, Train_loss: 0.613481, Test_accuracy: 64.28%, Test_loss: 0.641415\n",
      "batch size: 128, fold: 1| Epoch 8: Train_accuracy: 67.99%, Train_loss: 0.607013, Test_accuracy: 64.81%, Test_loss: 0.641690\n",
      "batch size: 128, fold: 1| Epoch 9: Train_accuracy: 69.74%, Train_loss: 0.597016, Test_accuracy: 63.98%, Test_loss: 0.634035\n",
      "batch size: 128, fold: 1| Epoch 10: Train_accuracy: 70.42%, Train_loss: 0.590452, Test_accuracy: 64.69%, Test_loss: 0.629562\n",
      "batch size: 128, fold: 1| Epoch 11: Train_accuracy: 71.69%, Train_loss: 0.578627, Test_accuracy: 63.80%, Test_loss: 0.640005\n",
      "batch size: 128, fold: 1| Epoch 12: Train_accuracy: 71.75%, Train_loss: 0.577555, Test_accuracy: 66.94%, Test_loss: 0.618212\n",
      "batch size: 128, fold: 1| Epoch 13: Train_accuracy: 73.38%, Train_loss: 0.563124, Test_accuracy: 64.57%, Test_loss: 0.637328\n",
      "batch size: 128, fold: 1| Epoch 14: Train_accuracy: 73.17%, Train_loss: 0.563679, Test_accuracy: 66.53%, Test_loss: 0.627780\n",
      "batch size: 128, fold: 1| Epoch 15: Train_accuracy: 74.24%, Train_loss: 0.557804, Test_accuracy: 66.29%, Test_loss: 0.621217\n",
      "batch size: 128, fold: 1| Epoch 16: Train_accuracy: 74.54%, Train_loss: 0.554115, Test_accuracy: 65.40%, Test_loss: 0.638059\n",
      "batch size: 128, fold: 1| Epoch 17: Train_accuracy: 75.62%, Train_loss: 0.542111, Test_accuracy: 67.12%, Test_loss: 0.612165\n",
      "batch size: 128, fold: 1| Epoch 18: Train_accuracy: 76.28%, Train_loss: 0.538243, Test_accuracy: 67.18%, Test_loss: 0.619102\n",
      "batch size: 128, fold: 1| Epoch 19: Train_accuracy: 77.44%, Train_loss: 0.530623, Test_accuracy: 67.71%, Test_loss: 0.623950\n",
      "batch size: 128, fold: 1| Epoch 20: Train_accuracy: 77.43%, Train_loss: 0.527632, Test_accuracy: 66.94%, Test_loss: 0.623252\n",
      "batch size: 128, fold: 1| Epoch 21: Train_accuracy: 78.79%, Train_loss: 0.518571, Test_accuracy: 67.30%, Test_loss: 0.611834\n",
      "batch size: 128, fold: 1| Epoch 22: Train_accuracy: 77.65%, Train_loss: 0.526622, Test_accuracy: 68.42%, Test_loss: 0.608423\n",
      "batch size: 128, fold: 1| Epoch 23: Train_accuracy: 78.67%, Train_loss: 0.517440, Test_accuracy: 66.82%, Test_loss: 0.618140\n",
      "batch size: 128, fold: 1| Epoch 24: Train_accuracy: 78.80%, Train_loss: 0.513348, Test_accuracy: 67.06%, Test_loss: 0.607467\n",
      "batch size: 128, fold: 1| Epoch 25: Train_accuracy: 79.43%, Train_loss: 0.509179, Test_accuracy: 68.31%, Test_loss: 0.609978\n",
      "batch size: 128, fold: 1| Epoch 26: Train_accuracy: 79.04%, Train_loss: 0.511233, Test_accuracy: 66.23%, Test_loss: 0.633104\n",
      "batch size: 128, fold: 1| Epoch 27: Train_accuracy: 80.06%, Train_loss: 0.503694, Test_accuracy: 71.09%, Test_loss: 0.589836\n",
      "batch size: 128, fold: 1| Epoch 28: Train_accuracy: 80.94%, Train_loss: 0.498490, Test_accuracy: 66.65%, Test_loss: 0.624138\n",
      "batch size: 128, fold: 1| Epoch 29: Train_accuracy: 80.85%, Train_loss: 0.496865, Test_accuracy: 69.85%, Test_loss: 0.597197\n",
      "batch size: 128, fold: 1| Epoch 30: Train_accuracy: 81.32%, Train_loss: 0.491439, Test_accuracy: 68.31%, Test_loss: 0.616138\n",
      "batch size: 128, fold: 1| Epoch 31: Train_accuracy: 81.75%, Train_loss: 0.491997, Test_accuracy: 69.49%, Test_loss: 0.602838\n",
      "batch size: 128, fold: 1| Epoch 32: Train_accuracy: 81.81%, Train_loss: 0.487334, Test_accuracy: 69.85%, Test_loss: 0.602452\n",
      "batch size: 128, fold: 1| Epoch 33: Train_accuracy: 82.02%, Train_loss: 0.484469, Test_accuracy: 69.96%, Test_loss: 0.589291\n",
      "batch size: 128, fold: 1| Epoch 34: Train_accuracy: 82.28%, Train_loss: 0.484302, Test_accuracy: 68.90%, Test_loss: 0.595574\n",
      "batch size: 128, fold: 1| Epoch 35: Train_accuracy: 82.48%, Train_loss: 0.480542, Test_accuracy: 69.85%, Test_loss: 0.590354\n",
      "batch size: 128, fold: 1| Epoch 36: Train_accuracy: 82.91%, Train_loss: 0.476349, Test_accuracy: 70.38%, Test_loss: 0.585526\n",
      "batch size: 128, fold: 1| Epoch 37: Train_accuracy: 82.73%, Train_loss: 0.480434, Test_accuracy: 69.96%, Test_loss: 0.597694\n",
      "batch size: 128, fold: 1| Epoch 38: Train_accuracy: 83.10%, Train_loss: 0.476395, Test_accuracy: 70.20%, Test_loss: 0.596466\n",
      "batch size: 128, fold: 1| Epoch 39: Train_accuracy: 83.60%, Train_loss: 0.471846, Test_accuracy: 72.39%, Test_loss: 0.578623\n",
      "batch size: 128, fold: 1| Epoch 40: Train_accuracy: 82.83%, Train_loss: 0.478969, Test_accuracy: 69.02%, Test_loss: 0.615246\n",
      "batch size: 128, fold: 1| Epoch 41: Train_accuracy: 83.22%, Train_loss: 0.473317, Test_accuracy: 71.45%, Test_loss: 0.585025\n",
      "batch size: 128, fold: 1| Epoch 42: Train_accuracy: 83.97%, Train_loss: 0.469806, Test_accuracy: 70.14%, Test_loss: 0.600994\n",
      "batch size: 128, fold: 1| Epoch 43: Train_accuracy: 84.25%, Train_loss: 0.466401, Test_accuracy: 69.43%, Test_loss: 0.593861\n",
      "batch size: 128, fold: 1| Epoch 44: Train_accuracy: 83.81%, Train_loss: 0.467956, Test_accuracy: 71.50%, Test_loss: 0.587443\n",
      "batch size: 128, fold: 1| Epoch 45: Train_accuracy: 84.68%, Train_loss: 0.459321, Test_accuracy: 70.62%, Test_loss: 0.599103\n",
      "batch size: 128, fold: 1| Epoch 46: Train_accuracy: 84.52%, Train_loss: 0.462580, Test_accuracy: 71.03%, Test_loss: 0.580536\n",
      "batch size: 128, fold: 1| Epoch 47: Train_accuracy: 84.94%, Train_loss: 0.457017, Test_accuracy: 70.56%, Test_loss: 0.591641\n",
      "batch size: 128, fold: 1| Epoch 48: Train_accuracy: 84.48%, Train_loss: 0.463018, Test_accuracy: 69.19%, Test_loss: 0.599615\n",
      "batch size: 128, fold: 1| Epoch 49: Train_accuracy: 84.52%, Train_loss: 0.461959, Test_accuracy: 71.39%, Test_loss: 0.586156\n",
      "batch size: 128, fold: 1| Epoch 50: Train_accuracy: 85.28%, Train_loss: 0.455054, Test_accuracy: 69.73%, Test_loss: 0.599799\n",
      "batch size: 128, fold: 1| Epoch 51: Train_accuracy: 85.19%, Train_loss: 0.456642, Test_accuracy: 71.45%, Test_loss: 0.582842\n",
      "batch size: 128, fold: 1| Epoch 52: Train_accuracy: 84.88%, Train_loss: 0.456636, Test_accuracy: 72.33%, Test_loss: 0.580861\n",
      "batch size: 128, fold: 1| Epoch 53: Train_accuracy: 85.99%, Train_loss: 0.450027, Test_accuracy: 71.68%, Test_loss: 0.590818\n",
      "batch size: 128, fold: 1| Epoch 54: Train_accuracy: 86.14%, Train_loss: 0.448717, Test_accuracy: 71.80%, Test_loss: 0.586797\n",
      "batch size: 128, fold: 1| Epoch 55: Train_accuracy: 86.06%, Train_loss: 0.448811, Test_accuracy: 71.68%, Test_loss: 0.581743\n",
      "batch size: 128, fold: 1| Epoch 56: Train_accuracy: 85.47%, Train_loss: 0.452317, Test_accuracy: 71.80%, Test_loss: 0.587186\n",
      "batch size: 128, fold: 1| Epoch 57: Train_accuracy: 85.96%, Train_loss: 0.449058, Test_accuracy: 70.68%, Test_loss: 0.599951\n",
      "batch size: 128, fold: 1| Epoch 58: Train_accuracy: 86.48%, Train_loss: 0.443697, Test_accuracy: 72.33%, Test_loss: 0.582896\n",
      "batch size: 128, fold: 1| Epoch 59: Train_accuracy: 86.17%, Train_loss: 0.446584, Test_accuracy: 70.50%, Test_loss: 0.599981\n",
      "batch size: 128, fold: 1| Epoch 60: Train_accuracy: 86.15%, Train_loss: 0.446981, Test_accuracy: 70.97%, Test_loss: 0.587606\n",
      "batch size: 128, fold: 1| Epoch 61: Train_accuracy: 85.96%, Train_loss: 0.446940, Test_accuracy: 71.92%, Test_loss: 0.579859\n",
      "batch size: 128, fold: 1| Epoch 62: Train_accuracy: 87.23%, Train_loss: 0.438028, Test_accuracy: 71.03%, Test_loss: 0.589432\n",
      "batch size: 128, fold: 1| Epoch 63: Train_accuracy: 86.73%, Train_loss: 0.440151, Test_accuracy: 71.03%, Test_loss: 0.588425\n",
      "batch size: 128, fold: 1| Epoch 64: Train_accuracy: 86.89%, Train_loss: 0.440697, Test_accuracy: 72.75%, Test_loss: 0.575273\n",
      "batch size: 128, fold: 1| Epoch 65: Train_accuracy: 86.89%, Train_loss: 0.440219, Test_accuracy: 73.16%, Test_loss: 0.579358\n",
      "batch size: 128, fold: 1| Epoch 66: Train_accuracy: 86.88%, Train_loss: 0.438347, Test_accuracy: 70.08%, Test_loss: 0.611560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128, fold: 1| Epoch 67: Train_accuracy: 86.86%, Train_loss: 0.438648, Test_accuracy: 71.80%, Test_loss: 0.574275\n",
      "batch size: 128, fold: 1| Epoch 68: Train_accuracy: 87.39%, Train_loss: 0.435527, Test_accuracy: 73.76%, Test_loss: 0.567258\n",
      "batch size: 128, fold: 1| Epoch 69: Train_accuracy: 87.78%, Train_loss: 0.431272, Test_accuracy: 72.22%, Test_loss: 0.571577\n",
      "batch size: 128, fold: 1| Epoch 70: Train_accuracy: 86.95%, Train_loss: 0.436477, Test_accuracy: 71.86%, Test_loss: 0.579110\n",
      "batch size: 128, fold: 1| Epoch 71: Train_accuracy: 87.85%, Train_loss: 0.431638, Test_accuracy: 71.56%, Test_loss: 0.585166\n",
      "batch size: 128, fold: 1| Epoch 72: Train_accuracy: 87.84%, Train_loss: 0.429119, Test_accuracy: 72.22%, Test_loss: 0.574050\n",
      "batch size: 128, fold: 1| Epoch 73: Train_accuracy: 87.96%, Train_loss: 0.430404, Test_accuracy: 71.09%, Test_loss: 0.583876\n",
      "batch size: 128, fold: 1| Epoch 74: Train_accuracy: 87.28%, Train_loss: 0.435300, Test_accuracy: 70.68%, Test_loss: 0.590403\n",
      "batch size: 128, fold: 1| Epoch 75: Train_accuracy: 87.96%, Train_loss: 0.430446, Test_accuracy: 72.69%, Test_loss: 0.568793\n",
      "batch size: 128, fold: 1| Epoch 76: Train_accuracy: 88.25%, Train_loss: 0.429036, Test_accuracy: 71.86%, Test_loss: 0.582057\n",
      "batch size: 128, fold: 1| Epoch 77: Train_accuracy: 87.20%, Train_loss: 0.434812, Test_accuracy: 71.80%, Test_loss: 0.580661\n",
      "batch size: 128, fold: 1| Epoch 78: Train_accuracy: 87.54%, Train_loss: 0.431818, Test_accuracy: 72.04%, Test_loss: 0.588605\n",
      "batch size: 128, fold: 1| Epoch 79: Train_accuracy: 87.94%, Train_loss: 0.430989, Test_accuracy: 70.97%, Test_loss: 0.587497\n",
      "batch size: 128, fold: 1| Epoch 80: Train_accuracy: 87.94%, Train_loss: 0.428786, Test_accuracy: 72.16%, Test_loss: 0.580985\n",
      "batch size: 128, fold: 1| Epoch 81: Train_accuracy: 87.68%, Train_loss: 0.432052, Test_accuracy: 71.45%, Test_loss: 0.585102\n",
      "batch size: 128, fold: 1| Epoch 82: Train_accuracy: 88.61%, Train_loss: 0.423745, Test_accuracy: 72.22%, Test_loss: 0.576116\n",
      "batch size: 128, fold: 1| Epoch 83: Train_accuracy: 88.15%, Train_loss: 0.427449, Test_accuracy: 72.93%, Test_loss: 0.569439\n",
      "batch size: 128, fold: 1| Epoch 84: Train_accuracy: 88.98%, Train_loss: 0.419615, Test_accuracy: 71.80%, Test_loss: 0.578882\n",
      "batch size: 128, fold: 1| Epoch 85: Train_accuracy: 87.85%, Train_loss: 0.431229, Test_accuracy: 71.98%, Test_loss: 0.577611\n",
      "batch size: 128, fold: 1| Epoch 86: Train_accuracy: 88.64%, Train_loss: 0.422097, Test_accuracy: 72.99%, Test_loss: 0.572061\n",
      "batch size: 128, fold: 1| Epoch 87: Train_accuracy: 88.58%, Train_loss: 0.423858, Test_accuracy: 72.99%, Test_loss: 0.566925\n",
      "batch size: 128, fold: 1| Epoch 88: Train_accuracy: 88.48%, Train_loss: 0.424885, Test_accuracy: 72.10%, Test_loss: 0.585586\n",
      "batch size: 128, fold: 1| Epoch 89: Train_accuracy: 88.12%, Train_loss: 0.425837, Test_accuracy: 72.39%, Test_loss: 0.573134\n",
      "batch size: 128, fold: 1| Epoch 90: Train_accuracy: 89.02%, Train_loss: 0.418260, Test_accuracy: 72.33%, Test_loss: 0.579159\n",
      "batch size: 128, fold: 1| Epoch 91: Train_accuracy: 89.25%, Train_loss: 0.417117, Test_accuracy: 72.04%, Test_loss: 0.578210\n",
      "batch size: 128, fold: 1| Epoch 92: Train_accuracy: 89.04%, Train_loss: 0.420403, Test_accuracy: 72.39%, Test_loss: 0.572411\n",
      "batch size: 128, fold: 1| Epoch 93: Train_accuracy: 89.13%, Train_loss: 0.417383, Test_accuracy: 70.85%, Test_loss: 0.593019\n",
      "batch size: 128, fold: 1| Epoch 94: Train_accuracy: 89.07%, Train_loss: 0.417887, Test_accuracy: 72.22%, Test_loss: 0.569854\n",
      "batch size: 128, fold: 1| Epoch 95: Train_accuracy: 89.05%, Train_loss: 0.418389, Test_accuracy: 73.76%, Test_loss: 0.569599\n",
      "batch size: 128, fold: 1| Epoch 96: Train_accuracy: 88.99%, Train_loss: 0.419104, Test_accuracy: 73.93%, Test_loss: 0.566920\n",
      "batch size: 128, fold: 1| Epoch 97: Train_accuracy: 89.28%, Train_loss: 0.416829, Test_accuracy: 69.43%, Test_loss: 0.595718\n",
      "batch size: 128, fold: 1| Epoch 98: Train_accuracy: 88.80%, Train_loss: 0.420441, Test_accuracy: 72.57%, Test_loss: 0.570156\n",
      "batch size: 128, fold: 1| Epoch 99: Train_accuracy: 89.72%, Train_loss: 0.412655, Test_accuracy: 73.22%, Test_loss: 0.580328\n",
      "batch size: 128, fold: 1| Epoch 100: Train_accuracy: 89.62%, Train_loss: 0.413959, Test_accuracy: 72.75%, Test_loss: 0.572310\n",
      "batch size: 128, fold: 2| Epoch 1: Train_accuracy: 54.02%, Train_loss: 0.689180, Test_accuracy: 54.74%, Test_loss: 0.686631\n",
      "batch size: 128, fold: 2| Epoch 2: Train_accuracy: 58.47%, Train_loss: 0.675406, Test_accuracy: 57.35%, Test_loss: 0.678387\n",
      "batch size: 128, fold: 2| Epoch 3: Train_accuracy: 60.69%, Train_loss: 0.660863, Test_accuracy: 59.36%, Test_loss: 0.670275\n",
      "batch size: 128, fold: 2| Epoch 4: Train_accuracy: 63.25%, Train_loss: 0.646145, Test_accuracy: 58.77%, Test_loss: 0.668686\n",
      "batch size: 128, fold: 2| Epoch 5: Train_accuracy: 63.61%, Train_loss: 0.641077, Test_accuracy: 61.61%, Test_loss: 0.662586\n",
      "batch size: 128, fold: 2| Epoch 6: Train_accuracy: 66.01%, Train_loss: 0.625807, Test_accuracy: 62.09%, Test_loss: 0.658071\n",
      "batch size: 128, fold: 2| Epoch 7: Train_accuracy: 67.35%, Train_loss: 0.615808, Test_accuracy: 61.49%, Test_loss: 0.656499\n",
      "batch size: 128, fold: 2| Epoch 8: Train_accuracy: 68.23%, Train_loss: 0.607651, Test_accuracy: 64.16%, Test_loss: 0.645024\n",
      "batch size: 128, fold: 2| Epoch 9: Train_accuracy: 69.53%, Train_loss: 0.601317, Test_accuracy: 62.20%, Test_loss: 0.648788\n",
      "batch size: 128, fold: 2| Epoch 10: Train_accuracy: 69.99%, Train_loss: 0.596756, Test_accuracy: 63.51%, Test_loss: 0.647096\n",
      "batch size: 128, fold: 2| Epoch 11: Train_accuracy: 70.58%, Train_loss: 0.587328, Test_accuracy: 64.87%, Test_loss: 0.635022\n",
      "batch size: 128, fold: 2| Epoch 12: Train_accuracy: 70.97%, Train_loss: 0.583240, Test_accuracy: 65.28%, Test_loss: 0.631893\n",
      "batch size: 128, fold: 2| Epoch 13: Train_accuracy: 71.60%, Train_loss: 0.577565, Test_accuracy: 63.45%, Test_loss: 0.645209\n",
      "batch size: 128, fold: 2| Epoch 14: Train_accuracy: 72.34%, Train_loss: 0.572239, Test_accuracy: 66.29%, Test_loss: 0.626129\n",
      "batch size: 128, fold: 2| Epoch 15: Train_accuracy: 73.59%, Train_loss: 0.560909, Test_accuracy: 66.35%, Test_loss: 0.626937\n",
      "batch size: 128, fold: 2| Epoch 16: Train_accuracy: 73.93%, Train_loss: 0.560275, Test_accuracy: 67.18%, Test_loss: 0.616668\n",
      "batch size: 128, fold: 2| Epoch 17: Train_accuracy: 75.25%, Train_loss: 0.551097, Test_accuracy: 66.65%, Test_loss: 0.618579\n",
      "batch size: 128, fold: 2| Epoch 18: Train_accuracy: 75.56%, Train_loss: 0.543386, Test_accuracy: 68.07%, Test_loss: 0.612370\n",
      "batch size: 128, fold: 2| Epoch 19: Train_accuracy: 75.78%, Train_loss: 0.545083, Test_accuracy: 67.30%, Test_loss: 0.609429\n",
      "batch size: 128, fold: 2| Epoch 20: Train_accuracy: 75.87%, Train_loss: 0.542730, Test_accuracy: 67.77%, Test_loss: 0.606217\n",
      "batch size: 128, fold: 2| Epoch 21: Train_accuracy: 77.22%, Train_loss: 0.528066, Test_accuracy: 69.37%, Test_loss: 0.598470\n",
      "batch size: 128, fold: 2| Epoch 22: Train_accuracy: 77.22%, Train_loss: 0.530199, Test_accuracy: 69.61%, Test_loss: 0.596619\n",
      "batch size: 128, fold: 2| Epoch 23: Train_accuracy: 78.64%, Train_loss: 0.520645, Test_accuracy: 67.48%, Test_loss: 0.610845\n",
      "batch size: 128, fold: 2| Epoch 24: Train_accuracy: 77.44%, Train_loss: 0.526230, Test_accuracy: 68.54%, Test_loss: 0.601099\n",
      "batch size: 128, fold: 2| Epoch 25: Train_accuracy: 78.46%, Train_loss: 0.518733, Test_accuracy: 69.31%, Test_loss: 0.598129\n",
      "batch size: 128, fold: 2| Epoch 26: Train_accuracy: 79.29%, Train_loss: 0.511235, Test_accuracy: 68.66%, Test_loss: 0.598465\n",
      "batch size: 128, fold: 2| Epoch 27: Train_accuracy: 79.66%, Train_loss: 0.507424, Test_accuracy: 68.90%, Test_loss: 0.608632\n",
      "batch size: 128, fold: 2| Epoch 28: Train_accuracy: 80.42%, Train_loss: 0.500741, Test_accuracy: 68.66%, Test_loss: 0.612778\n",
      "batch size: 128, fold: 2| Epoch 29: Train_accuracy: 80.12%, Train_loss: 0.503135, Test_accuracy: 68.54%, Test_loss: 0.598086\n",
      "batch size: 128, fold: 2| Epoch 30: Train_accuracy: 80.77%, Train_loss: 0.496774, Test_accuracy: 70.62%, Test_loss: 0.589025\n",
      "batch size: 128, fold: 2| Epoch 31: Train_accuracy: 80.54%, Train_loss: 0.497590, Test_accuracy: 70.14%, Test_loss: 0.592811\n",
      "batch size: 128, fold: 2| Epoch 32: Train_accuracy: 81.38%, Train_loss: 0.489552, Test_accuracy: 68.60%, Test_loss: 0.614428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128, fold: 2| Epoch 33: Train_accuracy: 81.96%, Train_loss: 0.488372, Test_accuracy: 70.02%, Test_loss: 0.590398\n",
      "batch size: 128, fold: 2| Epoch 34: Train_accuracy: 81.25%, Train_loss: 0.493638, Test_accuracy: 70.91%, Test_loss: 0.576466\n",
      "batch size: 128, fold: 2| Epoch 35: Train_accuracy: 82.34%, Train_loss: 0.483134, Test_accuracy: 69.91%, Test_loss: 0.595478\n",
      "batch size: 128, fold: 2| Epoch 36: Train_accuracy: 82.89%, Train_loss: 0.478309, Test_accuracy: 70.85%, Test_loss: 0.583626\n",
      "batch size: 128, fold: 2| Epoch 37: Train_accuracy: 83.44%, Train_loss: 0.474588, Test_accuracy: 70.73%, Test_loss: 0.578194\n",
      "batch size: 128, fold: 2| Epoch 38: Train_accuracy: 82.68%, Train_loss: 0.478462, Test_accuracy: 72.22%, Test_loss: 0.578753\n",
      "batch size: 128, fold: 2| Epoch 39: Train_accuracy: 83.05%, Train_loss: 0.476073, Test_accuracy: 70.56%, Test_loss: 0.583850\n",
      "batch size: 128, fold: 2| Epoch 40: Train_accuracy: 83.35%, Train_loss: 0.473917, Test_accuracy: 71.74%, Test_loss: 0.584025\n",
      "batch size: 128, fold: 2| Epoch 41: Train_accuracy: 82.76%, Train_loss: 0.476867, Test_accuracy: 70.91%, Test_loss: 0.590566\n",
      "batch size: 128, fold: 2| Epoch 42: Train_accuracy: 83.60%, Train_loss: 0.471187, Test_accuracy: 70.32%, Test_loss: 0.588046\n",
      "batch size: 128, fold: 2| Epoch 43: Train_accuracy: 84.22%, Train_loss: 0.466429, Test_accuracy: 71.80%, Test_loss: 0.581509\n",
      "batch size: 128, fold: 2| Epoch 44: Train_accuracy: 83.69%, Train_loss: 0.469658, Test_accuracy: 72.22%, Test_loss: 0.579499\n",
      "batch size: 128, fold: 2| Epoch 45: Train_accuracy: 84.65%, Train_loss: 0.461009, Test_accuracy: 72.45%, Test_loss: 0.578398\n",
      "batch size: 128, fold: 2| Epoch 46: Train_accuracy: 84.34%, Train_loss: 0.465045, Test_accuracy: 72.45%, Test_loss: 0.573416\n",
      "batch size: 128, fold: 2| Epoch 47: Train_accuracy: 84.79%, Train_loss: 0.458453, Test_accuracy: 72.10%, Test_loss: 0.584854\n",
      "batch size: 128, fold: 2| Epoch 48: Train_accuracy: 84.31%, Train_loss: 0.463972, Test_accuracy: 73.28%, Test_loss: 0.567814\n",
      "batch size: 128, fold: 2| Epoch 49: Train_accuracy: 85.71%, Train_loss: 0.453146, Test_accuracy: 71.74%, Test_loss: 0.585586\n",
      "batch size: 128, fold: 2| Epoch 50: Train_accuracy: 86.02%, Train_loss: 0.451164, Test_accuracy: 71.56%, Test_loss: 0.582879\n",
      "batch size: 128, fold: 2| Epoch 51: Train_accuracy: 85.02%, Train_loss: 0.458107, Test_accuracy: 71.39%, Test_loss: 0.587995\n",
      "batch size: 128, fold: 2| Epoch 52: Train_accuracy: 84.64%, Train_loss: 0.458248, Test_accuracy: 72.10%, Test_loss: 0.569455\n",
      "batch size: 128, fold: 2| Epoch 53: Train_accuracy: 85.25%, Train_loss: 0.453371, Test_accuracy: 71.62%, Test_loss: 0.577505\n",
      "batch size: 128, fold: 2| Epoch 54: Train_accuracy: 86.03%, Train_loss: 0.449310, Test_accuracy: 71.39%, Test_loss: 0.599170\n",
      "batch size: 128, fold: 2| Epoch 55: Train_accuracy: 85.87%, Train_loss: 0.450343, Test_accuracy: 71.62%, Test_loss: 0.577368\n",
      "batch size: 128, fold: 2| Epoch 56: Train_accuracy: 86.02%, Train_loss: 0.449284, Test_accuracy: 70.91%, Test_loss: 0.589340\n",
      "batch size: 128, fold: 2| Epoch 57: Train_accuracy: 86.05%, Train_loss: 0.447546, Test_accuracy: 71.09%, Test_loss: 0.585841\n",
      "batch size: 128, fold: 2| Epoch 58: Train_accuracy: 85.72%, Train_loss: 0.449901, Test_accuracy: 73.22%, Test_loss: 0.567935\n",
      "batch size: 128, fold: 2| Epoch 59: Train_accuracy: 86.49%, Train_loss: 0.442611, Test_accuracy: 70.73%, Test_loss: 0.587609\n",
      "batch size: 128, fold: 2| Epoch 60: Train_accuracy: 86.68%, Train_loss: 0.440013, Test_accuracy: 72.33%, Test_loss: 0.577726\n",
      "batch size: 128, fold: 2| Epoch 61: Train_accuracy: 86.76%, Train_loss: 0.441423, Test_accuracy: 72.10%, Test_loss: 0.582116\n",
      "batch size: 128, fold: 2| Epoch 62: Train_accuracy: 86.77%, Train_loss: 0.440371, Test_accuracy: 72.45%, Test_loss: 0.580220\n",
      "batch size: 128, fold: 2| Epoch 63: Train_accuracy: 86.55%, Train_loss: 0.443221, Test_accuracy: 72.51%, Test_loss: 0.576781\n",
      "batch size: 128, fold: 2| Epoch 64: Train_accuracy: 86.61%, Train_loss: 0.441047, Test_accuracy: 73.16%, Test_loss: 0.571776\n",
      "batch size: 128, fold: 2| Epoch 65: Train_accuracy: 86.91%, Train_loss: 0.439622, Test_accuracy: 73.46%, Test_loss: 0.565106\n",
      "batch size: 128, fold: 2| Epoch 66: Train_accuracy: 86.73%, Train_loss: 0.440061, Test_accuracy: 71.98%, Test_loss: 0.569984\n",
      "batch size: 128, fold: 2| Epoch 67: Train_accuracy: 87.78%, Train_loss: 0.432582, Test_accuracy: 73.40%, Test_loss: 0.568412\n",
      "batch size: 128, fold: 2| Epoch 68: Train_accuracy: 87.51%, Train_loss: 0.433243, Test_accuracy: 73.64%, Test_loss: 0.570701\n",
      "batch size: 128, fold: 2| Epoch 69: Train_accuracy: 87.44%, Train_loss: 0.434215, Test_accuracy: 73.22%, Test_loss: 0.565106\n",
      "batch size: 128, fold: 2| Epoch 70: Train_accuracy: 86.56%, Train_loss: 0.442686, Test_accuracy: 72.75%, Test_loss: 0.573152\n",
      "batch size: 128, fold: 2| Epoch 71: Train_accuracy: 87.56%, Train_loss: 0.433098, Test_accuracy: 73.76%, Test_loss: 0.565933\n",
      "batch size: 128, fold: 2| Epoch 72: Train_accuracy: 87.48%, Train_loss: 0.433758, Test_accuracy: 73.10%, Test_loss: 0.570153\n",
      "batch size: 128, fold: 2| Epoch 73: Train_accuracy: 87.07%, Train_loss: 0.436344, Test_accuracy: 73.28%, Test_loss: 0.565608\n",
      "batch size: 128, fold: 2| Epoch 74: Train_accuracy: 87.44%, Train_loss: 0.434496, Test_accuracy: 72.16%, Test_loss: 0.581959\n",
      "batch size: 128, fold: 2| Epoch 75: Train_accuracy: 87.87%, Train_loss: 0.429251, Test_accuracy: 72.99%, Test_loss: 0.559700\n",
      "batch size: 128, fold: 2| Epoch 76: Train_accuracy: 87.76%, Train_loss: 0.432988, Test_accuracy: 74.23%, Test_loss: 0.564486\n",
      "batch size: 128, fold: 2| Epoch 77: Train_accuracy: 88.15%, Train_loss: 0.426203, Test_accuracy: 73.46%, Test_loss: 0.561376\n",
      "batch size: 128, fold: 2| Epoch 78: Train_accuracy: 88.39%, Train_loss: 0.423504, Test_accuracy: 72.87%, Test_loss: 0.570602\n",
      "batch size: 128, fold: 2| Epoch 79: Train_accuracy: 88.51%, Train_loss: 0.424150, Test_accuracy: 72.93%, Test_loss: 0.571026\n",
      "batch size: 128, fold: 2| Epoch 80: Train_accuracy: 88.73%, Train_loss: 0.422102, Test_accuracy: 73.70%, Test_loss: 0.555873\n",
      "batch size: 128, fold: 2| Epoch 81: Train_accuracy: 89.22%, Train_loss: 0.416852, Test_accuracy: 73.99%, Test_loss: 0.564818\n",
      "batch size: 128, fold: 2| Epoch 82: Train_accuracy: 88.14%, Train_loss: 0.427937, Test_accuracy: 73.76%, Test_loss: 0.563633\n",
      "batch size: 128, fold: 2| Epoch 83: Train_accuracy: 88.36%, Train_loss: 0.425155, Test_accuracy: 71.80%, Test_loss: 0.584819\n",
      "batch size: 128, fold: 2| Epoch 84: Train_accuracy: 88.86%, Train_loss: 0.421844, Test_accuracy: 72.69%, Test_loss: 0.583781\n",
      "batch size: 128, fold: 2| Epoch 85: Train_accuracy: 89.19%, Train_loss: 0.418345, Test_accuracy: 71.27%, Test_loss: 0.581791\n",
      "batch size: 128, fold: 2| Epoch 86: Train_accuracy: 88.71%, Train_loss: 0.422652, Test_accuracy: 73.87%, Test_loss: 0.558576\n",
      "batch size: 128, fold: 2| Epoch 87: Train_accuracy: 89.01%, Train_loss: 0.418829, Test_accuracy: 71.92%, Test_loss: 0.575246\n",
      "batch size: 128, fold: 2| Epoch 88: Train_accuracy: 88.49%, Train_loss: 0.423768, Test_accuracy: 72.81%, Test_loss: 0.582166\n",
      "batch size: 128, fold: 2| Epoch 89: Train_accuracy: 88.91%, Train_loss: 0.419027, Test_accuracy: 73.93%, Test_loss: 0.570445\n",
      "batch size: 128, fold: 2| Epoch 90: Train_accuracy: 89.14%, Train_loss: 0.418489, Test_accuracy: 72.99%, Test_loss: 0.570463\n",
      "batch size: 128, fold: 2| Epoch 91: Train_accuracy: 88.92%, Train_loss: 0.419963, Test_accuracy: 72.57%, Test_loss: 0.572996\n",
      "batch size: 128, fold: 2| Epoch 92: Train_accuracy: 88.95%, Train_loss: 0.419471, Test_accuracy: 72.63%, Test_loss: 0.571989\n",
      "batch size: 128, fold: 2| Epoch 93: Train_accuracy: 88.88%, Train_loss: 0.423135, Test_accuracy: 72.27%, Test_loss: 0.571826\n",
      "batch size: 128, fold: 2| Epoch 94: Train_accuracy: 89.87%, Train_loss: 0.412614, Test_accuracy: 71.03%, Test_loss: 0.590427\n",
      "batch size: 128, fold: 2| Epoch 95: Train_accuracy: 88.86%, Train_loss: 0.419769, Test_accuracy: 72.16%, Test_loss: 0.586234\n",
      "batch size: 128, fold: 2| Epoch 96: Train_accuracy: 89.47%, Train_loss: 0.415280, Test_accuracy: 74.11%, Test_loss: 0.560324\n",
      "batch size: 128, fold: 2| Epoch 97: Train_accuracy: 89.53%, Train_loss: 0.415207, Test_accuracy: 73.40%, Test_loss: 0.562953\n",
      "batch size: 128, fold: 2| Epoch 98: Train_accuracy: 89.36%, Train_loss: 0.416118, Test_accuracy: 73.05%, Test_loss: 0.570686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128, fold: 2| Epoch 99: Train_accuracy: 88.99%, Train_loss: 0.419360, Test_accuracy: 73.87%, Test_loss: 0.559786\n",
      "batch size: 128, fold: 2| Epoch 100: Train_accuracy: 89.90%, Train_loss: 0.409887, Test_accuracy: 73.46%, Test_loss: 0.571357\n",
      "batch size: 128, fold: 3| Epoch 1: Train_accuracy: 53.56%, Train_loss: 0.689022, Test_accuracy: 57.11%, Test_loss: 0.683424\n",
      "batch size: 128, fold: 3| Epoch 2: Train_accuracy: 58.30%, Train_loss: 0.673580, Test_accuracy: 57.35%, Test_loss: 0.676802\n",
      "batch size: 128, fold: 3| Epoch 3: Train_accuracy: 61.07%, Train_loss: 0.657974, Test_accuracy: 59.60%, Test_loss: 0.668348\n",
      "batch size: 128, fold: 3| Epoch 4: Train_accuracy: 62.98%, Train_loss: 0.645639, Test_accuracy: 59.06%, Test_loss: 0.665839\n",
      "batch size: 128, fold: 3| Epoch 5: Train_accuracy: 64.55%, Train_loss: 0.633473, Test_accuracy: 59.54%, Test_loss: 0.659876\n",
      "batch size: 128, fold: 3| Epoch 6: Train_accuracy: 65.74%, Train_loss: 0.625974, Test_accuracy: 59.95%, Test_loss: 0.662002\n",
      "batch size: 128, fold: 3| Epoch 7: Train_accuracy: 67.34%, Train_loss: 0.614853, Test_accuracy: 63.15%, Test_loss: 0.641872\n",
      "batch size: 128, fold: 3| Epoch 8: Train_accuracy: 69.00%, Train_loss: 0.602166, Test_accuracy: 63.68%, Test_loss: 0.643327\n",
      "batch size: 128, fold: 3| Epoch 9: Train_accuracy: 69.31%, Train_loss: 0.595967, Test_accuracy: 65.05%, Test_loss: 0.628591\n",
      "batch size: 128, fold: 3| Epoch 10: Train_accuracy: 70.94%, Train_loss: 0.584888, Test_accuracy: 63.45%, Test_loss: 0.640613\n",
      "batch size: 128, fold: 3| Epoch 11: Train_accuracy: 71.94%, Train_loss: 0.577378, Test_accuracy: 63.57%, Test_loss: 0.650214\n",
      "batch size: 128, fold: 3| Epoch 12: Train_accuracy: 71.92%, Train_loss: 0.575143, Test_accuracy: 66.00%, Test_loss: 0.623931\n",
      "batch size: 128, fold: 3| Epoch 13: Train_accuracy: 73.19%, Train_loss: 0.565227, Test_accuracy: 63.80%, Test_loss: 0.650657\n",
      "batch size: 128, fold: 3| Epoch 14: Train_accuracy: 72.77%, Train_loss: 0.566824, Test_accuracy: 66.23%, Test_loss: 0.631307\n",
      "batch size: 128, fold: 3| Epoch 15: Train_accuracy: 74.91%, Train_loss: 0.552814, Test_accuracy: 67.77%, Test_loss: 0.618867\n",
      "batch size: 128, fold: 3| Epoch 16: Train_accuracy: 74.26%, Train_loss: 0.554197, Test_accuracy: 66.29%, Test_loss: 0.626012\n",
      "batch size: 128, fold: 3| Epoch 17: Train_accuracy: 75.60%, Train_loss: 0.544692, Test_accuracy: 67.00%, Test_loss: 0.615776\n",
      "batch size: 128, fold: 3| Epoch 18: Train_accuracy: 76.15%, Train_loss: 0.539710, Test_accuracy: 66.47%, Test_loss: 0.632353\n",
      "batch size: 128, fold: 3| Epoch 19: Train_accuracy: 76.48%, Train_loss: 0.537886, Test_accuracy: 67.00%, Test_loss: 0.623561\n",
      "batch size: 128, fold: 3| Epoch 20: Train_accuracy: 77.03%, Train_loss: 0.532710, Test_accuracy: 65.64%, Test_loss: 0.623732\n",
      "batch size: 128, fold: 3| Epoch 21: Train_accuracy: 77.25%, Train_loss: 0.529507, Test_accuracy: 67.36%, Test_loss: 0.615565\n",
      "batch size: 128, fold: 3| Epoch 22: Train_accuracy: 77.22%, Train_loss: 0.530153, Test_accuracy: 67.36%, Test_loss: 0.612053\n",
      "batch size: 128, fold: 3| Epoch 23: Train_accuracy: 79.11%, Train_loss: 0.513954, Test_accuracy: 66.53%, Test_loss: 0.617935\n",
      "batch size: 128, fold: 3| Epoch 24: Train_accuracy: 79.35%, Train_loss: 0.513148, Test_accuracy: 67.77%, Test_loss: 0.612064\n",
      "batch size: 128, fold: 3| Epoch 25: Train_accuracy: 78.48%, Train_loss: 0.516150, Test_accuracy: 68.19%, Test_loss: 0.609553\n",
      "batch size: 128, fold: 3| Epoch 26: Train_accuracy: 79.90%, Train_loss: 0.508193, Test_accuracy: 68.60%, Test_loss: 0.603924\n",
      "batch size: 128, fold: 3| Epoch 27: Train_accuracy: 79.69%, Train_loss: 0.504896, Test_accuracy: 67.06%, Test_loss: 0.616680\n",
      "batch size: 128, fold: 3| Epoch 28: Train_accuracy: 80.28%, Train_loss: 0.500490, Test_accuracy: 69.55%, Test_loss: 0.600717\n",
      "batch size: 128, fold: 3| Epoch 29: Train_accuracy: 81.37%, Train_loss: 0.491942, Test_accuracy: 67.65%, Test_loss: 0.618732\n",
      "batch size: 128, fold: 3| Epoch 30: Train_accuracy: 80.94%, Train_loss: 0.497103, Test_accuracy: 67.06%, Test_loss: 0.616971\n",
      "batch size: 128, fold: 3| Epoch 31: Train_accuracy: 81.22%, Train_loss: 0.494012, Test_accuracy: 70.32%, Test_loss: 0.601616\n",
      "batch size: 128, fold: 3| Epoch 32: Train_accuracy: 81.47%, Train_loss: 0.492699, Test_accuracy: 69.37%, Test_loss: 0.597000\n",
      "batch size: 128, fold: 3| Epoch 33: Train_accuracy: 81.74%, Train_loss: 0.488008, Test_accuracy: 67.65%, Test_loss: 0.612660\n",
      "batch size: 128, fold: 3| Epoch 34: Train_accuracy: 82.37%, Train_loss: 0.482600, Test_accuracy: 68.90%, Test_loss: 0.601859\n",
      "batch size: 128, fold: 3| Epoch 35: Train_accuracy: 82.12%, Train_loss: 0.483966, Test_accuracy: 68.31%, Test_loss: 0.607314\n",
      "batch size: 128, fold: 3| Epoch 36: Train_accuracy: 82.21%, Train_loss: 0.483487, Test_accuracy: 70.50%, Test_loss: 0.585514\n",
      "batch size: 128, fold: 3| Epoch 37: Train_accuracy: 83.23%, Train_loss: 0.475269, Test_accuracy: 71.03%, Test_loss: 0.593584\n",
      "batch size: 128, fold: 3| Epoch 38: Train_accuracy: 83.26%, Train_loss: 0.477087, Test_accuracy: 69.02%, Test_loss: 0.612816\n",
      "batch size: 128, fold: 3| Epoch 39: Train_accuracy: 82.61%, Train_loss: 0.479890, Test_accuracy: 68.13%, Test_loss: 0.606288\n",
      "batch size: 128, fold: 3| Epoch 40: Train_accuracy: 82.86%, Train_loss: 0.476826, Test_accuracy: 70.02%, Test_loss: 0.596806\n",
      "batch size: 128, fold: 3| Epoch 41: Train_accuracy: 83.69%, Train_loss: 0.470422, Test_accuracy: 70.14%, Test_loss: 0.597887\n",
      "batch size: 128, fold: 3| Epoch 42: Train_accuracy: 83.31%, Train_loss: 0.474265, Test_accuracy: 69.61%, Test_loss: 0.603560\n",
      "batch size: 128, fold: 3| Epoch 43: Train_accuracy: 83.79%, Train_loss: 0.470214, Test_accuracy: 68.72%, Test_loss: 0.613175\n",
      "batch size: 128, fold: 3| Epoch 44: Train_accuracy: 83.51%, Train_loss: 0.470433, Test_accuracy: 70.26%, Test_loss: 0.594937\n",
      "batch size: 128, fold: 3| Epoch 45: Train_accuracy: 84.80%, Train_loss: 0.461188, Test_accuracy: 69.25%, Test_loss: 0.595501\n",
      "batch size: 128, fold: 3| Epoch 46: Train_accuracy: 84.77%, Train_loss: 0.459197, Test_accuracy: 70.50%, Test_loss: 0.604003\n",
      "batch size: 128, fold: 3| Epoch 47: Train_accuracy: 84.03%, Train_loss: 0.468161, Test_accuracy: 71.74%, Test_loss: 0.582193\n",
      "batch size: 128, fold: 3| Epoch 48: Train_accuracy: 84.74%, Train_loss: 0.460287, Test_accuracy: 70.08%, Test_loss: 0.601828\n",
      "batch size: 128, fold: 3| Epoch 49: Train_accuracy: 84.70%, Train_loss: 0.460426, Test_accuracy: 70.26%, Test_loss: 0.599026\n",
      "batch size: 128, fold: 3| Epoch 50: Train_accuracy: 85.34%, Train_loss: 0.453895, Test_accuracy: 71.21%, Test_loss: 0.583613\n",
      "batch size: 128, fold: 3| Epoch 51: Train_accuracy: 84.85%, Train_loss: 0.457636, Test_accuracy: 69.96%, Test_loss: 0.598460\n",
      "batch size: 128, fold: 3| Epoch 52: Train_accuracy: 84.73%, Train_loss: 0.458011, Test_accuracy: 68.84%, Test_loss: 0.609685\n",
      "batch size: 128, fold: 3| Epoch 53: Train_accuracy: 86.24%, Train_loss: 0.449103, Test_accuracy: 70.02%, Test_loss: 0.585749\n",
      "batch size: 128, fold: 3| Epoch 54: Train_accuracy: 85.60%, Train_loss: 0.452271, Test_accuracy: 69.96%, Test_loss: 0.595964\n",
      "batch size: 128, fold: 3| Epoch 55: Train_accuracy: 85.39%, Train_loss: 0.453956, Test_accuracy: 69.73%, Test_loss: 0.595464\n",
      "batch size: 128, fold: 3| Epoch 56: Train_accuracy: 85.57%, Train_loss: 0.451683, Test_accuracy: 71.03%, Test_loss: 0.585273\n",
      "batch size: 128, fold: 3| Epoch 57: Train_accuracy: 85.96%, Train_loss: 0.448547, Test_accuracy: 72.87%, Test_loss: 0.562327\n",
      "batch size: 128, fold: 3| Epoch 58: Train_accuracy: 86.09%, Train_loss: 0.448451, Test_accuracy: 71.21%, Test_loss: 0.585748\n",
      "batch size: 128, fold: 3| Epoch 59: Train_accuracy: 86.54%, Train_loss: 0.445270, Test_accuracy: 70.02%, Test_loss: 0.600103\n",
      "batch size: 128, fold: 3| Epoch 60: Train_accuracy: 85.90%, Train_loss: 0.449119, Test_accuracy: 71.74%, Test_loss: 0.588301\n",
      "batch size: 128, fold: 3| Epoch 61: Train_accuracy: 86.82%, Train_loss: 0.442465, Test_accuracy: 70.20%, Test_loss: 0.600186\n",
      "batch size: 128, fold: 3| Epoch 62: Train_accuracy: 86.24%, Train_loss: 0.446243, Test_accuracy: 70.44%, Test_loss: 0.590504\n",
      "batch size: 128, fold: 3| Epoch 63: Train_accuracy: 86.34%, Train_loss: 0.444791, Test_accuracy: 73.40%, Test_loss: 0.572528\n",
      "batch size: 128, fold: 3| Epoch 64: Train_accuracy: 86.83%, Train_loss: 0.440810, Test_accuracy: 70.68%, Test_loss: 0.588173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128, fold: 3| Epoch 65: Train_accuracy: 86.79%, Train_loss: 0.442130, Test_accuracy: 70.26%, Test_loss: 0.594153\n",
      "batch size: 128, fold: 3| Epoch 66: Train_accuracy: 86.89%, Train_loss: 0.440156, Test_accuracy: 69.02%, Test_loss: 0.608981\n",
      "batch size: 128, fold: 3| Epoch 67: Train_accuracy: 87.16%, Train_loss: 0.438085, Test_accuracy: 72.63%, Test_loss: 0.572725\n",
      "batch size: 128, fold: 3| Epoch 68: Train_accuracy: 86.95%, Train_loss: 0.438937, Test_accuracy: 70.44%, Test_loss: 0.606373\n",
      "batch size: 128, fold: 3| Epoch 69: Train_accuracy: 87.22%, Train_loss: 0.436400, Test_accuracy: 70.97%, Test_loss: 0.594286\n",
      "batch size: 128, fold: 3| Epoch 70: Train_accuracy: 86.96%, Train_loss: 0.438087, Test_accuracy: 71.50%, Test_loss: 0.582456\n",
      "batch size: 128, fold: 3| Epoch 71: Train_accuracy: 87.01%, Train_loss: 0.437847, Test_accuracy: 71.80%, Test_loss: 0.583780\n",
      "batch size: 128, fold: 3| Epoch 72: Train_accuracy: 87.66%, Train_loss: 0.433981, Test_accuracy: 70.85%, Test_loss: 0.596704\n",
      "batch size: 128, fold: 3| Epoch 73: Train_accuracy: 87.41%, Train_loss: 0.436305, Test_accuracy: 70.97%, Test_loss: 0.593950\n",
      "batch size: 128, fold: 3| Epoch 74: Train_accuracy: 87.57%, Train_loss: 0.432696, Test_accuracy: 72.10%, Test_loss: 0.571381\n",
      "batch size: 128, fold: 3| Epoch 75: Train_accuracy: 87.97%, Train_loss: 0.429259, Test_accuracy: 71.92%, Test_loss: 0.590345\n",
      "batch size: 128, fold: 3| Epoch 76: Train_accuracy: 87.47%, Train_loss: 0.435271, Test_accuracy: 70.85%, Test_loss: 0.592830\n",
      "batch size: 128, fold: 3| Epoch 77: Train_accuracy: 87.60%, Train_loss: 0.433141, Test_accuracy: 71.56%, Test_loss: 0.584001\n",
      "batch size: 128, fold: 3| Epoch 78: Train_accuracy: 88.02%, Train_loss: 0.430707, Test_accuracy: 71.56%, Test_loss: 0.596226\n",
      "batch size: 128, fold: 3| Epoch 79: Train_accuracy: 87.96%, Train_loss: 0.430220, Test_accuracy: 72.10%, Test_loss: 0.578315\n",
      "batch size: 128, fold: 3| Epoch 80: Train_accuracy: 88.05%, Train_loss: 0.428642, Test_accuracy: 72.81%, Test_loss: 0.580223\n",
      "batch size: 128, fold: 3| Epoch 81: Train_accuracy: 88.14%, Train_loss: 0.427774, Test_accuracy: 69.85%, Test_loss: 0.591354\n",
      "batch size: 128, fold: 3| Epoch 82: Train_accuracy: 88.28%, Train_loss: 0.427759, Test_accuracy: 70.91%, Test_loss: 0.586821\n",
      "batch size: 128, fold: 3| Epoch 83: Train_accuracy: 87.94%, Train_loss: 0.430498, Test_accuracy: 71.03%, Test_loss: 0.582036\n",
      "batch size: 128, fold: 3| Epoch 84: Train_accuracy: 87.97%, Train_loss: 0.429112, Test_accuracy: 72.33%, Test_loss: 0.582343\n",
      "batch size: 128, fold: 3| Epoch 85: Train_accuracy: 88.39%, Train_loss: 0.425030, Test_accuracy: 71.56%, Test_loss: 0.591094\n",
      "batch size: 128, fold: 3| Epoch 86: Train_accuracy: 87.91%, Train_loss: 0.430110, Test_accuracy: 70.97%, Test_loss: 0.588745\n",
      "batch size: 128, fold: 3| Epoch 87: Train_accuracy: 88.37%, Train_loss: 0.425499, Test_accuracy: 71.62%, Test_loss: 0.591122\n",
      "batch size: 128, fold: 3| Epoch 88: Train_accuracy: 88.58%, Train_loss: 0.425506, Test_accuracy: 71.45%, Test_loss: 0.586591\n",
      "batch size: 128, fold: 3| Epoch 89: Train_accuracy: 88.58%, Train_loss: 0.424789, Test_accuracy: 72.33%, Test_loss: 0.581754\n",
      "batch size: 128, fold: 3| Epoch 90: Train_accuracy: 88.96%, Train_loss: 0.420527, Test_accuracy: 72.45%, Test_loss: 0.573348\n",
      "batch size: 128, fold: 3| Epoch 91: Train_accuracy: 88.39%, Train_loss: 0.424325, Test_accuracy: 72.99%, Test_loss: 0.573492\n",
      "batch size: 128, fold: 3| Epoch 92: Train_accuracy: 88.95%, Train_loss: 0.419581, Test_accuracy: 71.33%, Test_loss: 0.582667\n",
      "batch size: 128, fold: 3| Epoch 93: Train_accuracy: 88.76%, Train_loss: 0.422196, Test_accuracy: 71.50%, Test_loss: 0.586255\n",
      "batch size: 128, fold: 3| Epoch 94: Train_accuracy: 88.16%, Train_loss: 0.423922, Test_accuracy: 72.16%, Test_loss: 0.581438\n",
      "batch size: 128, fold: 3| Epoch 95: Train_accuracy: 89.02%, Train_loss: 0.419222, Test_accuracy: 71.50%, Test_loss: 0.579611\n",
      "batch size: 128, fold: 3| Epoch 96: Train_accuracy: 89.78%, Train_loss: 0.413670, Test_accuracy: 70.44%, Test_loss: 0.587852\n",
      "batch size: 128, fold: 3| Epoch 97: Train_accuracy: 89.20%, Train_loss: 0.417876, Test_accuracy: 71.33%, Test_loss: 0.586794\n",
      "batch size: 128, fold: 3| Epoch 98: Train_accuracy: 89.20%, Train_loss: 0.417442, Test_accuracy: 71.15%, Test_loss: 0.585519\n",
      "batch size: 128, fold: 3| Epoch 99: Train_accuracy: 88.85%, Train_loss: 0.420367, Test_accuracy: 71.62%, Test_loss: 0.580241\n",
      "batch size: 128, fold: 3| Epoch 100: Train_accuracy: 89.53%, Train_loss: 0.414670, Test_accuracy: 71.45%, Test_loss: 0.589445\n",
      "batch size: 128, fold: 4| Epoch 1: Train_accuracy: 54.58%, Train_loss: 0.687768, Test_accuracy: 55.63%, Test_loss: 0.682879\n",
      "batch size: 128, fold: 4| Epoch 2: Train_accuracy: 58.78%, Train_loss: 0.671070, Test_accuracy: 58.35%, Test_loss: 0.680240\n",
      "batch size: 128, fold: 4| Epoch 3: Train_accuracy: 60.85%, Train_loss: 0.658566, Test_accuracy: 60.25%, Test_loss: 0.665155\n",
      "batch size: 128, fold: 4| Epoch 4: Train_accuracy: 62.69%, Train_loss: 0.646439, Test_accuracy: 59.18%, Test_loss: 0.668642\n",
      "batch size: 128, fold: 4| Epoch 5: Train_accuracy: 64.39%, Train_loss: 0.637608, Test_accuracy: 62.56%, Test_loss: 0.660298\n",
      "batch size: 128, fold: 4| Epoch 6: Train_accuracy: 66.30%, Train_loss: 0.623081, Test_accuracy: 61.26%, Test_loss: 0.656337\n",
      "batch size: 128, fold: 4| Epoch 7: Train_accuracy: 67.32%, Train_loss: 0.613968, Test_accuracy: 61.61%, Test_loss: 0.659431\n",
      "batch size: 128, fold: 4| Epoch 8: Train_accuracy: 68.67%, Train_loss: 0.601994, Test_accuracy: 61.43%, Test_loss: 0.661573\n",
      "batch size: 128, fold: 4| Epoch 9: Train_accuracy: 70.23%, Train_loss: 0.594550, Test_accuracy: 61.79%, Test_loss: 0.654988\n",
      "batch size: 128, fold: 4| Epoch 10: Train_accuracy: 70.40%, Train_loss: 0.589526, Test_accuracy: 63.33%, Test_loss: 0.654747\n",
      "batch size: 128, fold: 4| Epoch 11: Train_accuracy: 71.75%, Train_loss: 0.580594, Test_accuracy: 63.57%, Test_loss: 0.644155\n",
      "batch size: 128, fold: 4| Epoch 12: Train_accuracy: 72.48%, Train_loss: 0.573483, Test_accuracy: 65.05%, Test_loss: 0.636056\n",
      "batch size: 128, fold: 4| Epoch 13: Train_accuracy: 73.41%, Train_loss: 0.563692, Test_accuracy: 62.56%, Test_loss: 0.659402\n",
      "batch size: 128, fold: 4| Epoch 14: Train_accuracy: 74.29%, Train_loss: 0.557764, Test_accuracy: 63.09%, Test_loss: 0.649951\n",
      "batch size: 128, fold: 4| Epoch 15: Train_accuracy: 74.08%, Train_loss: 0.557676, Test_accuracy: 65.34%, Test_loss: 0.635831\n",
      "batch size: 128, fold: 4| Epoch 16: Train_accuracy: 74.52%, Train_loss: 0.553656, Test_accuracy: 66.59%, Test_loss: 0.630254\n",
      "batch size: 128, fold: 4| Epoch 17: Train_accuracy: 76.08%, Train_loss: 0.542544, Test_accuracy: 65.58%, Test_loss: 0.630522\n",
      "batch size: 128, fold: 4| Epoch 18: Train_accuracy: 76.67%, Train_loss: 0.535380, Test_accuracy: 66.41%, Test_loss: 0.630390\n",
      "batch size: 128, fold: 4| Epoch 19: Train_accuracy: 77.19%, Train_loss: 0.532589, Test_accuracy: 67.12%, Test_loss: 0.623409\n",
      "batch size: 128, fold: 4| Epoch 20: Train_accuracy: 77.44%, Train_loss: 0.530227, Test_accuracy: 66.47%, Test_loss: 0.630339\n",
      "batch size: 128, fold: 4| Epoch 21: Train_accuracy: 77.20%, Train_loss: 0.529675, Test_accuracy: 66.17%, Test_loss: 0.624591\n",
      "batch size: 128, fold: 4| Epoch 22: Train_accuracy: 78.39%, Train_loss: 0.521489, Test_accuracy: 66.59%, Test_loss: 0.624031\n",
      "batch size: 128, fold: 4| Epoch 23: Train_accuracy: 78.15%, Train_loss: 0.523380, Test_accuracy: 66.53%, Test_loss: 0.624290\n",
      "batch size: 128, fold: 4| Epoch 24: Train_accuracy: 78.94%, Train_loss: 0.514981, Test_accuracy: 67.36%, Test_loss: 0.615805\n",
      "batch size: 128, fold: 4| Epoch 25: Train_accuracy: 78.92%, Train_loss: 0.514693, Test_accuracy: 66.41%, Test_loss: 0.637486\n",
      "batch size: 128, fold: 4| Epoch 26: Train_accuracy: 79.83%, Train_loss: 0.510008, Test_accuracy: 66.88%, Test_loss: 0.619130\n",
      "batch size: 128, fold: 4| Epoch 27: Train_accuracy: 79.45%, Train_loss: 0.510429, Test_accuracy: 66.65%, Test_loss: 0.623934\n",
      "batch size: 128, fold: 4| Epoch 28: Train_accuracy: 80.34%, Train_loss: 0.500586, Test_accuracy: 66.59%, Test_loss: 0.632767\n",
      "batch size: 128, fold: 4| Epoch 29: Train_accuracy: 80.82%, Train_loss: 0.497864, Test_accuracy: 67.06%, Test_loss: 0.614740\n",
      "batch size: 128, fold: 4| Epoch 30: Train_accuracy: 81.68%, Train_loss: 0.492017, Test_accuracy: 69.19%, Test_loss: 0.611904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128, fold: 4| Epoch 31: Train_accuracy: 81.42%, Train_loss: 0.493381, Test_accuracy: 67.24%, Test_loss: 0.623022\n",
      "batch size: 128, fold: 4| Epoch 32: Train_accuracy: 81.81%, Train_loss: 0.487752, Test_accuracy: 68.13%, Test_loss: 0.613385\n",
      "batch size: 128, fold: 4| Epoch 33: Train_accuracy: 81.97%, Train_loss: 0.487010, Test_accuracy: 68.36%, Test_loss: 0.604615\n",
      "batch size: 128, fold: 4| Epoch 34: Train_accuracy: 82.62%, Train_loss: 0.482246, Test_accuracy: 68.96%, Test_loss: 0.608553\n",
      "batch size: 128, fold: 4| Epoch 35: Train_accuracy: 81.54%, Train_loss: 0.487605, Test_accuracy: 69.25%, Test_loss: 0.608076\n",
      "batch size: 128, fold: 4| Epoch 36: Train_accuracy: 83.00%, Train_loss: 0.479208, Test_accuracy: 67.65%, Test_loss: 0.605155\n",
      "batch size: 128, fold: 4| Epoch 37: Train_accuracy: 82.71%, Train_loss: 0.479729, Test_accuracy: 66.82%, Test_loss: 0.625143\n",
      "batch size: 128, fold: 4| Epoch 38: Train_accuracy: 83.22%, Train_loss: 0.476459, Test_accuracy: 69.73%, Test_loss: 0.605239\n",
      "batch size: 128, fold: 4| Epoch 39: Train_accuracy: 82.70%, Train_loss: 0.478532, Test_accuracy: 69.37%, Test_loss: 0.597909\n",
      "batch size: 128, fold: 4| Epoch 40: Train_accuracy: 83.79%, Train_loss: 0.472391, Test_accuracy: 69.37%, Test_loss: 0.608992\n",
      "batch size: 128, fold: 4| Epoch 41: Train_accuracy: 83.34%, Train_loss: 0.471753, Test_accuracy: 67.95%, Test_loss: 0.619410\n",
      "batch size: 128, fold: 4| Epoch 42: Train_accuracy: 84.57%, Train_loss: 0.463917, Test_accuracy: 69.49%, Test_loss: 0.594356\n",
      "batch size: 128, fold: 4| Epoch 43: Train_accuracy: 84.21%, Train_loss: 0.466812, Test_accuracy: 69.91%, Test_loss: 0.600668\n",
      "batch size: 128, fold: 4| Epoch 44: Train_accuracy: 84.31%, Train_loss: 0.466054, Test_accuracy: 69.96%, Test_loss: 0.591608\n",
      "batch size: 128, fold: 4| Epoch 45: Train_accuracy: 84.22%, Train_loss: 0.466509, Test_accuracy: 69.73%, Test_loss: 0.599503\n",
      "batch size: 128, fold: 4| Epoch 46: Train_accuracy: 84.74%, Train_loss: 0.462103, Test_accuracy: 67.89%, Test_loss: 0.622133\n",
      "batch size: 128, fold: 4| Epoch 47: Train_accuracy: 84.67%, Train_loss: 0.461384, Test_accuracy: 69.73%, Test_loss: 0.601762\n",
      "batch size: 128, fold: 4| Epoch 48: Train_accuracy: 85.32%, Train_loss: 0.455342, Test_accuracy: 69.02%, Test_loss: 0.608078\n",
      "batch size: 128, fold: 4| Epoch 49: Train_accuracy: 85.05%, Train_loss: 0.457443, Test_accuracy: 68.90%, Test_loss: 0.609148\n",
      "batch size: 128, fold: 4| Epoch 50: Train_accuracy: 85.41%, Train_loss: 0.453275, Test_accuracy: 68.48%, Test_loss: 0.610213\n",
      "batch size: 128, fold: 4| Epoch 51: Train_accuracy: 84.97%, Train_loss: 0.459107, Test_accuracy: 69.67%, Test_loss: 0.610796\n",
      "batch size: 128, fold: 4| Epoch 52: Train_accuracy: 84.95%, Train_loss: 0.458343, Test_accuracy: 70.02%, Test_loss: 0.606693\n",
      "batch size: 128, fold: 4| Epoch 53: Train_accuracy: 85.26%, Train_loss: 0.455969, Test_accuracy: 69.25%, Test_loss: 0.602662\n",
      "batch size: 128, fold: 4| Epoch 54: Train_accuracy: 85.51%, Train_loss: 0.452904, Test_accuracy: 69.14%, Test_loss: 0.602831\n",
      "batch size: 128, fold: 4| Epoch 55: Train_accuracy: 85.51%, Train_loss: 0.454424, Test_accuracy: 68.78%, Test_loss: 0.610266\n",
      "batch size: 128, fold: 4| Epoch 56: Train_accuracy: 85.31%, Train_loss: 0.454744, Test_accuracy: 69.43%, Test_loss: 0.607111\n",
      "batch size: 128, fold: 4| Epoch 57: Train_accuracy: 85.01%, Train_loss: 0.456205, Test_accuracy: 70.44%, Test_loss: 0.599815\n",
      "batch size: 128, fold: 4| Epoch 58: Train_accuracy: 85.77%, Train_loss: 0.449970, Test_accuracy: 68.90%, Test_loss: 0.602832\n",
      "batch size: 128, fold: 4| Epoch 59: Train_accuracy: 86.21%, Train_loss: 0.443960, Test_accuracy: 70.91%, Test_loss: 0.580327\n",
      "batch size: 128, fold: 4| Epoch 60: Train_accuracy: 86.49%, Train_loss: 0.445219, Test_accuracy: 70.02%, Test_loss: 0.599494\n",
      "batch size: 128, fold: 4| Epoch 61: Train_accuracy: 86.67%, Train_loss: 0.442953, Test_accuracy: 69.49%, Test_loss: 0.590879\n",
      "batch size: 128, fold: 4| Epoch 62: Train_accuracy: 86.09%, Train_loss: 0.446999, Test_accuracy: 69.49%, Test_loss: 0.611832\n",
      "batch size: 128, fold: 4| Epoch 63: Train_accuracy: 86.68%, Train_loss: 0.442303, Test_accuracy: 69.85%, Test_loss: 0.592426\n",
      "batch size: 128, fold: 4| Epoch 64: Train_accuracy: 86.54%, Train_loss: 0.442091, Test_accuracy: 70.20%, Test_loss: 0.600841\n",
      "batch size: 128, fold: 4| Epoch 65: Train_accuracy: 86.86%, Train_loss: 0.440975, Test_accuracy: 69.91%, Test_loss: 0.599025\n",
      "batch size: 128, fold: 4| Epoch 66: Train_accuracy: 86.99%, Train_loss: 0.437923, Test_accuracy: 70.62%, Test_loss: 0.593853\n",
      "batch size: 128, fold: 4| Epoch 67: Train_accuracy: 86.76%, Train_loss: 0.440368, Test_accuracy: 71.50%, Test_loss: 0.586631\n",
      "batch size: 128, fold: 4| Epoch 68: Train_accuracy: 86.89%, Train_loss: 0.439416, Test_accuracy: 69.55%, Test_loss: 0.611154\n",
      "batch size: 128, fold: 4| Epoch 69: Train_accuracy: 87.54%, Train_loss: 0.432367, Test_accuracy: 70.02%, Test_loss: 0.604120\n",
      "batch size: 128, fold: 4| Epoch 70: Train_accuracy: 87.07%, Train_loss: 0.437711, Test_accuracy: 70.56%, Test_loss: 0.610371\n",
      "batch size: 128, fold: 4| Epoch 71: Train_accuracy: 87.36%, Train_loss: 0.434147, Test_accuracy: 72.22%, Test_loss: 0.583970\n",
      "batch size: 128, fold: 4| Epoch 72: Train_accuracy: 87.88%, Train_loss: 0.430259, Test_accuracy: 69.49%, Test_loss: 0.595843\n",
      "batch size: 128, fold: 4| Epoch 73: Train_accuracy: 87.81%, Train_loss: 0.431889, Test_accuracy: 69.67%, Test_loss: 0.600743\n",
      "batch size: 128, fold: 4| Epoch 74: Train_accuracy: 87.93%, Train_loss: 0.430371, Test_accuracy: 69.31%, Test_loss: 0.609010\n",
      "batch size: 128, fold: 4| Epoch 75: Train_accuracy: 87.57%, Train_loss: 0.433909, Test_accuracy: 70.79%, Test_loss: 0.592279\n",
      "batch size: 128, fold: 4| Epoch 76: Train_accuracy: 87.97%, Train_loss: 0.427449, Test_accuracy: 70.91%, Test_loss: 0.597663\n",
      "batch size: 128, fold: 4| Epoch 77: Train_accuracy: 87.63%, Train_loss: 0.430597, Test_accuracy: 70.50%, Test_loss: 0.598438\n",
      "batch size: 128, fold: 4| Epoch 78: Train_accuracy: 87.79%, Train_loss: 0.430225, Test_accuracy: 70.20%, Test_loss: 0.605487\n",
      "batch size: 128, fold: 4| Epoch 79: Train_accuracy: 88.11%, Train_loss: 0.430853, Test_accuracy: 69.73%, Test_loss: 0.607148\n",
      "batch size: 128, fold: 4| Epoch 80: Train_accuracy: 88.11%, Train_loss: 0.428166, Test_accuracy: 71.09%, Test_loss: 0.594270\n",
      "batch size: 128, fold: 4| Epoch 81: Train_accuracy: 87.90%, Train_loss: 0.429056, Test_accuracy: 70.38%, Test_loss: 0.598350\n",
      "batch size: 128, fold: 4| Epoch 82: Train_accuracy: 88.16%, Train_loss: 0.425718, Test_accuracy: 69.08%, Test_loss: 0.612882\n",
      "batch size: 128, fold: 4| Epoch 83: Train_accuracy: 87.59%, Train_loss: 0.433611, Test_accuracy: 68.13%, Test_loss: 0.610098\n",
      "batch size: 128, fold: 4| Epoch 84: Train_accuracy: 88.80%, Train_loss: 0.422027, Test_accuracy: 69.79%, Test_loss: 0.613916\n",
      "batch size: 128, fold: 4| Epoch 85: Train_accuracy: 88.24%, Train_loss: 0.427419, Test_accuracy: 70.73%, Test_loss: 0.597397\n",
      "batch size: 128, fold: 4| Epoch 86: Train_accuracy: 88.74%, Train_loss: 0.422832, Test_accuracy: 70.56%, Test_loss: 0.597482\n",
      "batch size: 128, fold: 4| Epoch 87: Train_accuracy: 88.25%, Train_loss: 0.426290, Test_accuracy: 71.15%, Test_loss: 0.588367\n",
      "batch size: 128, fold: 4| Epoch 88: Train_accuracy: 88.89%, Train_loss: 0.420377, Test_accuracy: 68.72%, Test_loss: 0.613685\n",
      "batch size: 128, fold: 4| Epoch 89: Train_accuracy: 89.29%, Train_loss: 0.416003, Test_accuracy: 70.50%, Test_loss: 0.595147\n",
      "batch size: 128, fold: 4| Epoch 90: Train_accuracy: 89.01%, Train_loss: 0.418986, Test_accuracy: 71.86%, Test_loss: 0.587520\n",
      "batch size: 128, fold: 4| Epoch 91: Train_accuracy: 89.36%, Train_loss: 0.417041, Test_accuracy: 70.91%, Test_loss: 0.589219\n",
      "batch size: 128, fold: 4| Epoch 92: Train_accuracy: 88.34%, Train_loss: 0.424418, Test_accuracy: 70.38%, Test_loss: 0.596105\n",
      "batch size: 128, fold: 4| Epoch 93: Train_accuracy: 88.70%, Train_loss: 0.421639, Test_accuracy: 69.55%, Test_loss: 0.605393\n",
      "batch size: 128, fold: 4| Epoch 94: Train_accuracy: 89.33%, Train_loss: 0.416512, Test_accuracy: 71.03%, Test_loss: 0.592067\n",
      "batch size: 128, fold: 4| Epoch 95: Train_accuracy: 88.85%, Train_loss: 0.420075, Test_accuracy: 70.32%, Test_loss: 0.591496\n",
      "batch size: 128, fold: 4| Epoch 96: Train_accuracy: 89.26%, Train_loss: 0.416706, Test_accuracy: 71.86%, Test_loss: 0.588773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128, fold: 4| Epoch 97: Train_accuracy: 89.57%, Train_loss: 0.414400, Test_accuracy: 70.85%, Test_loss: 0.594297\n",
      "batch size: 128, fold: 4| Epoch 98: Train_accuracy: 89.56%, Train_loss: 0.415545, Test_accuracy: 70.38%, Test_loss: 0.589819\n",
      "batch size: 128, fold: 4| Epoch 99: Train_accuracy: 89.48%, Train_loss: 0.414234, Test_accuracy: 70.85%, Test_loss: 0.588767\n",
      "batch size: 128, fold: 4| Epoch 100: Train_accuracy: 89.47%, Train_loss: 0.412746, Test_accuracy: 70.79%, Test_loss: 0.590480\n",
      "batch size: 128, fold: 5| Epoch 1: Train_accuracy: 53.91%, Train_loss: 0.688707, Test_accuracy: 55.72%, Test_loss: 0.684010\n",
      "batch size: 128, fold: 5| Epoch 2: Train_accuracy: 58.53%, Train_loss: 0.672748, Test_accuracy: 58.45%, Test_loss: 0.673861\n",
      "batch size: 128, fold: 5| Epoch 3: Train_accuracy: 60.63%, Train_loss: 0.662631, Test_accuracy: 59.63%, Test_loss: 0.672808\n",
      "batch size: 128, fold: 5| Epoch 4: Train_accuracy: 63.24%, Train_loss: 0.649476, Test_accuracy: 61.23%, Test_loss: 0.654019\n",
      "batch size: 128, fold: 5| Epoch 5: Train_accuracy: 64.53%, Train_loss: 0.637844, Test_accuracy: 62.00%, Test_loss: 0.655059\n",
      "batch size: 128, fold: 5| Epoch 6: Train_accuracy: 65.52%, Train_loss: 0.628476, Test_accuracy: 63.01%, Test_loss: 0.650842\n",
      "batch size: 128, fold: 5| Epoch 7: Train_accuracy: 67.06%, Train_loss: 0.616376, Test_accuracy: 62.42%, Test_loss: 0.651136\n",
      "batch size: 128, fold: 5| Epoch 8: Train_accuracy: 68.57%, Train_loss: 0.607162, Test_accuracy: 64.85%, Test_loss: 0.638630\n",
      "batch size: 128, fold: 5| Epoch 9: Train_accuracy: 68.99%, Train_loss: 0.600854, Test_accuracy: 64.49%, Test_loss: 0.638087\n",
      "batch size: 128, fold: 5| Epoch 10: Train_accuracy: 69.67%, Train_loss: 0.595568, Test_accuracy: 64.20%, Test_loss: 0.639095\n",
      "batch size: 128, fold: 5| Epoch 11: Train_accuracy: 71.03%, Train_loss: 0.584319, Test_accuracy: 66.33%, Test_loss: 0.621872\n",
      "batch size: 128, fold: 5| Epoch 12: Train_accuracy: 72.50%, Train_loss: 0.571721, Test_accuracy: 65.09%, Test_loss: 0.634709\n",
      "batch size: 128, fold: 5| Epoch 13: Train_accuracy: 73.00%, Train_loss: 0.568293, Test_accuracy: 64.20%, Test_loss: 0.637928\n",
      "batch size: 128, fold: 5| Epoch 14: Train_accuracy: 73.03%, Train_loss: 0.566892, Test_accuracy: 64.43%, Test_loss: 0.635933\n",
      "batch size: 128, fold: 5| Epoch 15: Train_accuracy: 74.59%, Train_loss: 0.556417, Test_accuracy: 66.51%, Test_loss: 0.625300\n",
      "batch size: 128, fold: 5| Epoch 16: Train_accuracy: 74.88%, Train_loss: 0.551661, Test_accuracy: 65.80%, Test_loss: 0.626742\n",
      "batch size: 128, fold: 5| Epoch 17: Train_accuracy: 75.28%, Train_loss: 0.549471, Test_accuracy: 65.92%, Test_loss: 0.625416\n",
      "batch size: 128, fold: 5| Epoch 18: Train_accuracy: 74.69%, Train_loss: 0.549375, Test_accuracy: 66.69%, Test_loss: 0.626003\n",
      "batch size: 128, fold: 5| Epoch 19: Train_accuracy: 76.39%, Train_loss: 0.540080, Test_accuracy: 66.27%, Test_loss: 0.620723\n",
      "batch size: 128, fold: 5| Epoch 20: Train_accuracy: 77.03%, Train_loss: 0.533526, Test_accuracy: 67.75%, Test_loss: 0.605833\n",
      "batch size: 128, fold: 5| Epoch 21: Train_accuracy: 77.25%, Train_loss: 0.530139, Test_accuracy: 66.45%, Test_loss: 0.619479\n",
      "batch size: 128, fold: 5| Epoch 22: Train_accuracy: 78.29%, Train_loss: 0.522904, Test_accuracy: 67.28%, Test_loss: 0.611017\n",
      "batch size: 128, fold: 5| Epoch 23: Train_accuracy: 77.96%, Train_loss: 0.520828, Test_accuracy: 68.29%, Test_loss: 0.610253\n",
      "batch size: 128, fold: 5| Epoch 24: Train_accuracy: 78.04%, Train_loss: 0.521308, Test_accuracy: 67.99%, Test_loss: 0.613021\n",
      "batch size: 128, fold: 5| Epoch 25: Train_accuracy: 79.03%, Train_loss: 0.515709, Test_accuracy: 69.59%, Test_loss: 0.594309\n",
      "batch size: 128, fold: 5| Epoch 26: Train_accuracy: 80.02%, Train_loss: 0.504476, Test_accuracy: 69.29%, Test_loss: 0.603920\n",
      "batch size: 128, fold: 5| Epoch 27: Train_accuracy: 80.07%, Train_loss: 0.504382, Test_accuracy: 68.29%, Test_loss: 0.607457\n",
      "batch size: 128, fold: 5| Epoch 28: Train_accuracy: 79.75%, Train_loss: 0.505559, Test_accuracy: 70.60%, Test_loss: 0.597421\n",
      "batch size: 128, fold: 5| Epoch 29: Train_accuracy: 79.68%, Train_loss: 0.507149, Test_accuracy: 70.30%, Test_loss: 0.589169\n",
      "batch size: 128, fold: 5| Epoch 30: Train_accuracy: 79.40%, Train_loss: 0.509486, Test_accuracy: 70.48%, Test_loss: 0.600345\n",
      "batch size: 128, fold: 5| Epoch 31: Train_accuracy: 81.10%, Train_loss: 0.494829, Test_accuracy: 69.18%, Test_loss: 0.603336\n",
      "batch size: 128, fold: 5| Epoch 32: Train_accuracy: 81.68%, Train_loss: 0.490469, Test_accuracy: 70.36%, Test_loss: 0.587644\n",
      "batch size: 128, fold: 5| Epoch 33: Train_accuracy: 81.86%, Train_loss: 0.488924, Test_accuracy: 70.95%, Test_loss: 0.583505\n",
      "batch size: 128, fold: 5| Epoch 34: Train_accuracy: 82.81%, Train_loss: 0.481569, Test_accuracy: 70.07%, Test_loss: 0.594554\n",
      "batch size: 128, fold: 5| Epoch 35: Train_accuracy: 81.64%, Train_loss: 0.487268, Test_accuracy: 70.42%, Test_loss: 0.596778\n",
      "batch size: 128, fold: 5| Epoch 36: Train_accuracy: 82.24%, Train_loss: 0.484164, Test_accuracy: 69.41%, Test_loss: 0.594889\n",
      "batch size: 128, fold: 5| Epoch 37: Train_accuracy: 82.82%, Train_loss: 0.478604, Test_accuracy: 70.12%, Test_loss: 0.592120\n",
      "batch size: 128, fold: 5| Epoch 38: Train_accuracy: 82.85%, Train_loss: 0.478802, Test_accuracy: 68.88%, Test_loss: 0.600714\n",
      "batch size: 128, fold: 5| Epoch 39: Train_accuracy: 83.06%, Train_loss: 0.474074, Test_accuracy: 71.19%, Test_loss: 0.583029\n",
      "batch size: 128, fold: 5| Epoch 40: Train_accuracy: 83.06%, Train_loss: 0.475228, Test_accuracy: 69.24%, Test_loss: 0.592943\n",
      "batch size: 128, fold: 5| Epoch 41: Train_accuracy: 83.43%, Train_loss: 0.475744, Test_accuracy: 69.89%, Test_loss: 0.604033\n",
      "batch size: 128, fold: 5| Epoch 42: Train_accuracy: 83.83%, Train_loss: 0.471217, Test_accuracy: 69.18%, Test_loss: 0.602500\n",
      "batch size: 128, fold: 5| Epoch 43: Train_accuracy: 83.83%, Train_loss: 0.469135, Test_accuracy: 70.66%, Test_loss: 0.582865\n",
      "batch size: 128, fold: 5| Epoch 44: Train_accuracy: 84.26%, Train_loss: 0.466088, Test_accuracy: 71.25%, Test_loss: 0.588159\n",
      "batch size: 128, fold: 5| Epoch 45: Train_accuracy: 83.52%, Train_loss: 0.470822, Test_accuracy: 71.49%, Test_loss: 0.583910\n",
      "batch size: 128, fold: 5| Epoch 46: Train_accuracy: 84.20%, Train_loss: 0.465893, Test_accuracy: 70.84%, Test_loss: 0.583651\n",
      "batch size: 128, fold: 5| Epoch 47: Train_accuracy: 84.75%, Train_loss: 0.461912, Test_accuracy: 71.25%, Test_loss: 0.583114\n",
      "batch size: 128, fold: 5| Epoch 48: Train_accuracy: 83.81%, Train_loss: 0.467058, Test_accuracy: 70.84%, Test_loss: 0.589108\n",
      "batch size: 128, fold: 5| Epoch 49: Train_accuracy: 83.87%, Train_loss: 0.466397, Test_accuracy: 70.78%, Test_loss: 0.590415\n",
      "batch size: 128, fold: 5| Epoch 50: Train_accuracy: 84.35%, Train_loss: 0.463978, Test_accuracy: 71.07%, Test_loss: 0.588755\n",
      "batch size: 128, fold: 5| Epoch 51: Train_accuracy: 85.00%, Train_loss: 0.457867, Test_accuracy: 70.72%, Test_loss: 0.586269\n",
      "batch size: 128, fold: 5| Epoch 52: Train_accuracy: 84.82%, Train_loss: 0.457968, Test_accuracy: 71.37%, Test_loss: 0.582849\n",
      "batch size: 128, fold: 5| Epoch 53: Train_accuracy: 85.55%, Train_loss: 0.453374, Test_accuracy: 70.72%, Test_loss: 0.591174\n",
      "batch size: 128, fold: 5| Epoch 54: Train_accuracy: 85.16%, Train_loss: 0.455218, Test_accuracy: 72.32%, Test_loss: 0.575134\n",
      "batch size: 128, fold: 5| Epoch 55: Train_accuracy: 86.14%, Train_loss: 0.448821, Test_accuracy: 72.14%, Test_loss: 0.585655\n",
      "batch size: 128, fold: 5| Epoch 56: Train_accuracy: 85.65%, Train_loss: 0.450356, Test_accuracy: 72.50%, Test_loss: 0.570103\n",
      "batch size: 128, fold: 5| Epoch 57: Train_accuracy: 85.92%, Train_loss: 0.450013, Test_accuracy: 71.61%, Test_loss: 0.587428\n",
      "batch size: 128, fold: 5| Epoch 58: Train_accuracy: 86.49%, Train_loss: 0.442271, Test_accuracy: 73.03%, Test_loss: 0.569288\n",
      "batch size: 128, fold: 5| Epoch 59: Train_accuracy: 85.90%, Train_loss: 0.448648, Test_accuracy: 71.01%, Test_loss: 0.583495\n",
      "batch size: 128, fold: 5| Epoch 60: Train_accuracy: 85.94%, Train_loss: 0.447144, Test_accuracy: 71.07%, Test_loss: 0.594325\n",
      "batch size: 128, fold: 5| Epoch 61: Train_accuracy: 86.15%, Train_loss: 0.446781, Test_accuracy: 71.01%, Test_loss: 0.589264\n",
      "batch size: 128, fold: 5| Epoch 62: Train_accuracy: 86.77%, Train_loss: 0.441505, Test_accuracy: 71.49%, Test_loss: 0.589210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128, fold: 5| Epoch 63: Train_accuracy: 86.30%, Train_loss: 0.444952, Test_accuracy: 72.14%, Test_loss: 0.587858\n",
      "batch size: 128, fold: 5| Epoch 64: Train_accuracy: 86.32%, Train_loss: 0.444698, Test_accuracy: 71.67%, Test_loss: 0.574691\n",
      "batch size: 128, fold: 5| Epoch 65: Train_accuracy: 86.74%, Train_loss: 0.440275, Test_accuracy: 72.02%, Test_loss: 0.584067\n",
      "batch size: 128, fold: 5| Epoch 66: Train_accuracy: 87.38%, Train_loss: 0.435718, Test_accuracy: 74.33%, Test_loss: 0.562879\n",
      "batch size: 128, fold: 5| Epoch 67: Train_accuracy: 87.25%, Train_loss: 0.437644, Test_accuracy: 71.67%, Test_loss: 0.584402\n",
      "batch size: 128, fold: 5| Epoch 68: Train_accuracy: 86.95%, Train_loss: 0.439472, Test_accuracy: 73.15%, Test_loss: 0.565450\n",
      "batch size: 128, fold: 5| Epoch 69: Train_accuracy: 87.32%, Train_loss: 0.434384, Test_accuracy: 70.30%, Test_loss: 0.596054\n",
      "batch size: 128, fold: 5| Epoch 70: Train_accuracy: 87.49%, Train_loss: 0.433220, Test_accuracy: 71.37%, Test_loss: 0.581220\n",
      "batch size: 128, fold: 5| Epoch 71: Train_accuracy: 87.94%, Train_loss: 0.429657, Test_accuracy: 72.38%, Test_loss: 0.583506\n",
      "batch size: 128, fold: 5| Epoch 72: Train_accuracy: 86.97%, Train_loss: 0.436996, Test_accuracy: 71.90%, Test_loss: 0.577484\n",
      "batch size: 128, fold: 5| Epoch 73: Train_accuracy: 86.70%, Train_loss: 0.441588, Test_accuracy: 71.25%, Test_loss: 0.585536\n",
      "batch size: 128, fold: 5| Epoch 74: Train_accuracy: 87.35%, Train_loss: 0.434015, Test_accuracy: 71.90%, Test_loss: 0.579871\n",
      "batch size: 128, fold: 5| Epoch 75: Train_accuracy: 86.80%, Train_loss: 0.436177, Test_accuracy: 70.48%, Test_loss: 0.598039\n",
      "batch size: 128, fold: 5| Epoch 76: Train_accuracy: 88.06%, Train_loss: 0.428636, Test_accuracy: 72.85%, Test_loss: 0.571687\n",
      "batch size: 128, fold: 5| Epoch 77: Train_accuracy: 88.34%, Train_loss: 0.427324, Test_accuracy: 73.38%, Test_loss: 0.567511\n",
      "batch size: 128, fold: 5| Epoch 78: Train_accuracy: 87.99%, Train_loss: 0.430578, Test_accuracy: 73.21%, Test_loss: 0.571825\n",
      "batch size: 128, fold: 5| Epoch 79: Train_accuracy: 88.09%, Train_loss: 0.427019, Test_accuracy: 69.95%, Test_loss: 0.599851\n",
      "batch size: 128, fold: 5| Epoch 80: Train_accuracy: 87.60%, Train_loss: 0.430475, Test_accuracy: 72.44%, Test_loss: 0.579769\n",
      "batch size: 128, fold: 5| Epoch 81: Train_accuracy: 87.65%, Train_loss: 0.430319, Test_accuracy: 71.72%, Test_loss: 0.587039\n",
      "batch size: 128, fold: 5| Epoch 82: Train_accuracy: 88.30%, Train_loss: 0.425793, Test_accuracy: 71.49%, Test_loss: 0.583746\n",
      "batch size: 128, fold: 5| Epoch 83: Train_accuracy: 88.73%, Train_loss: 0.422823, Test_accuracy: 70.01%, Test_loss: 0.598876\n",
      "batch size: 128, fold: 5| Epoch 84: Train_accuracy: 88.39%, Train_loss: 0.425188, Test_accuracy: 70.78%, Test_loss: 0.589964\n",
      "batch size: 128, fold: 5| Epoch 85: Train_accuracy: 88.21%, Train_loss: 0.426667, Test_accuracy: 71.37%, Test_loss: 0.585632\n",
      "batch size: 128, fold: 5| Epoch 86: Train_accuracy: 88.45%, Train_loss: 0.424637, Test_accuracy: 70.90%, Test_loss: 0.586893\n",
      "batch size: 128, fold: 5| Epoch 87: Train_accuracy: 88.68%, Train_loss: 0.421579, Test_accuracy: 73.62%, Test_loss: 0.564742\n",
      "batch size: 128, fold: 5| Epoch 88: Train_accuracy: 88.80%, Train_loss: 0.421493, Test_accuracy: 72.55%, Test_loss: 0.579999\n",
      "batch size: 128, fold: 5| Epoch 89: Train_accuracy: 88.54%, Train_loss: 0.424058, Test_accuracy: 72.02%, Test_loss: 0.580493\n",
      "batch size: 128, fold: 5| Epoch 90: Train_accuracy: 89.29%, Train_loss: 0.416396, Test_accuracy: 73.33%, Test_loss: 0.563803\n",
      "batch size: 128, fold: 5| Epoch 91: Train_accuracy: 88.83%, Train_loss: 0.421039, Test_accuracy: 71.67%, Test_loss: 0.585059\n",
      "batch size: 128, fold: 5| Epoch 92: Train_accuracy: 89.43%, Train_loss: 0.415978, Test_accuracy: 71.61%, Test_loss: 0.591123\n",
      "batch size: 128, fold: 5| Epoch 93: Train_accuracy: 89.38%, Train_loss: 0.415247, Test_accuracy: 71.78%, Test_loss: 0.583737\n",
      "batch size: 128, fold: 5| Epoch 94: Train_accuracy: 89.25%, Train_loss: 0.416276, Test_accuracy: 70.66%, Test_loss: 0.594180\n",
      "batch size: 128, fold: 5| Epoch 95: Train_accuracy: 89.06%, Train_loss: 0.417580, Test_accuracy: 72.02%, Test_loss: 0.573882\n",
      "batch size: 128, fold: 5| Epoch 96: Train_accuracy: 89.07%, Train_loss: 0.415930, Test_accuracy: 72.85%, Test_loss: 0.577891\n",
      "batch size: 128, fold: 5| Epoch 97: Train_accuracy: 89.77%, Train_loss: 0.411992, Test_accuracy: 71.96%, Test_loss: 0.584820\n",
      "batch size: 128, fold: 5| Epoch 98: Train_accuracy: 89.29%, Train_loss: 0.417236, Test_accuracy: 72.02%, Test_loss: 0.583545\n",
      "batch size: 128, fold: 5| Epoch 99: Train_accuracy: 89.48%, Train_loss: 0.414437, Test_accuracy: 70.84%, Test_loss: 0.591035\n",
      "batch size: 128, fold: 5| Epoch 100: Train_accuracy: 89.51%, Train_loss: 0.413598, Test_accuracy: 72.97%, Test_loss: 0.577458\n",
      "batch size: 256, fold: 1| Epoch 1: Train_accuracy: 53.33%, Train_loss: 0.690556, Test_accuracy: 56.28%, Test_loss: 0.685851\n",
      "batch size: 256, fold: 1| Epoch 2: Train_accuracy: 56.52%, Train_loss: 0.680976, Test_accuracy: 57.64%, Test_loss: 0.672136\n",
      "batch size: 256, fold: 1| Epoch 3: Train_accuracy: 59.15%, Train_loss: 0.670185, Test_accuracy: 61.67%, Test_loss: 0.659346\n",
      "batch size: 256, fold: 1| Epoch 4: Train_accuracy: 61.16%, Train_loss: 0.659899, Test_accuracy: 61.97%, Test_loss: 0.654014\n",
      "batch size: 256, fold: 1| Epoch 5: Train_accuracy: 62.86%, Train_loss: 0.649256, Test_accuracy: 61.43%, Test_loss: 0.654772\n",
      "batch size: 256, fold: 1| Epoch 6: Train_accuracy: 64.30%, Train_loss: 0.638360, Test_accuracy: 62.80%, Test_loss: 0.643456\n",
      "batch size: 256, fold: 1| Epoch 7: Train_accuracy: 64.89%, Train_loss: 0.633125, Test_accuracy: 63.27%, Test_loss: 0.642029\n",
      "batch size: 256, fold: 1| Epoch 8: Train_accuracy: 66.61%, Train_loss: 0.620638, Test_accuracy: 63.09%, Test_loss: 0.646217\n",
      "batch size: 256, fold: 1| Epoch 9: Train_accuracy: 67.95%, Train_loss: 0.610338, Test_accuracy: 64.10%, Test_loss: 0.640011\n",
      "batch size: 256, fold: 1| Epoch 10: Train_accuracy: 69.00%, Train_loss: 0.602471, Test_accuracy: 63.03%, Test_loss: 0.640620\n",
      "batch size: 256, fold: 1| Epoch 11: Train_accuracy: 69.37%, Train_loss: 0.599246, Test_accuracy: 64.87%, Test_loss: 0.633761\n",
      "batch size: 256, fold: 1| Epoch 12: Train_accuracy: 71.20%, Train_loss: 0.585484, Test_accuracy: 63.74%, Test_loss: 0.642195\n",
      "batch size: 256, fold: 1| Epoch 13: Train_accuracy: 71.66%, Train_loss: 0.579371, Test_accuracy: 65.40%, Test_loss: 0.629006\n",
      "batch size: 256, fold: 1| Epoch 14: Train_accuracy: 71.12%, Train_loss: 0.582105, Test_accuracy: 64.81%, Test_loss: 0.631383\n",
      "batch size: 256, fold: 1| Epoch 15: Train_accuracy: 72.97%, Train_loss: 0.571754, Test_accuracy: 66.11%, Test_loss: 0.623731\n",
      "batch size: 256, fold: 1| Epoch 16: Train_accuracy: 72.51%, Train_loss: 0.570605, Test_accuracy: 66.77%, Test_loss: 0.622177\n",
      "batch size: 256, fold: 1| Epoch 17: Train_accuracy: 72.51%, Train_loss: 0.570601, Test_accuracy: 65.58%, Test_loss: 0.632448\n",
      "batch size: 256, fold: 1| Epoch 18: Train_accuracy: 74.52%, Train_loss: 0.556442, Test_accuracy: 66.11%, Test_loss: 0.622517\n",
      "batch size: 256, fold: 1| Epoch 19: Train_accuracy: 74.92%, Train_loss: 0.550461, Test_accuracy: 64.99%, Test_loss: 0.630820\n",
      "batch size: 256, fold: 1| Epoch 20: Train_accuracy: 74.80%, Train_loss: 0.552605, Test_accuracy: 66.53%, Test_loss: 0.623750\n",
      "batch size: 256, fold: 1| Epoch 21: Train_accuracy: 75.75%, Train_loss: 0.542391, Test_accuracy: 66.94%, Test_loss: 0.613837\n",
      "batch size: 256, fold: 1| Epoch 22: Train_accuracy: 76.28%, Train_loss: 0.538497, Test_accuracy: 67.77%, Test_loss: 0.614948\n",
      "batch size: 256, fold: 1| Epoch 23: Train_accuracy: 77.16%, Train_loss: 0.529451, Test_accuracy: 67.54%, Test_loss: 0.612513\n",
      "batch size: 256, fold: 1| Epoch 24: Train_accuracy: 77.07%, Train_loss: 0.531358, Test_accuracy: 68.31%, Test_loss: 0.607682\n",
      "batch size: 256, fold: 1| Epoch 25: Train_accuracy: 77.68%, Train_loss: 0.525603, Test_accuracy: 67.42%, Test_loss: 0.613982\n",
      "batch size: 256, fold: 1| Epoch 26: Train_accuracy: 78.23%, Train_loss: 0.522393, Test_accuracy: 65.94%, Test_loss: 0.625300\n",
      "batch size: 256, fold: 1| Epoch 27: Train_accuracy: 78.05%, Train_loss: 0.523035, Test_accuracy: 66.65%, Test_loss: 0.615058\n",
      "batch size: 256, fold: 1| Epoch 28: Train_accuracy: 78.83%, Train_loss: 0.514188, Test_accuracy: 69.02%, Test_loss: 0.602591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 256, fold: 1| Epoch 29: Train_accuracy: 79.66%, Train_loss: 0.508504, Test_accuracy: 66.65%, Test_loss: 0.623367\n",
      "batch size: 256, fold: 1| Epoch 30: Train_accuracy: 79.34%, Train_loss: 0.512467, Test_accuracy: 67.77%, Test_loss: 0.618856\n",
      "batch size: 256, fold: 1| Epoch 31: Train_accuracy: 79.50%, Train_loss: 0.508030, Test_accuracy: 67.71%, Test_loss: 0.609863\n",
      "batch size: 256, fold: 1| Epoch 32: Train_accuracy: 80.43%, Train_loss: 0.503185, Test_accuracy: 69.49%, Test_loss: 0.596807\n",
      "batch size: 256, fold: 1| Epoch 33: Train_accuracy: 79.43%, Train_loss: 0.509211, Test_accuracy: 68.36%, Test_loss: 0.613111\n",
      "batch size: 256, fold: 1| Epoch 34: Train_accuracy: 80.73%, Train_loss: 0.497637, Test_accuracy: 69.49%, Test_loss: 0.603905\n",
      "batch size: 256, fold: 1| Epoch 35: Train_accuracy: 80.15%, Train_loss: 0.501955, Test_accuracy: 66.88%, Test_loss: 0.617318\n",
      "batch size: 256, fold: 1| Epoch 36: Train_accuracy: 80.54%, Train_loss: 0.499005, Test_accuracy: 67.48%, Test_loss: 0.618366\n",
      "batch size: 256, fold: 1| Epoch 37: Train_accuracy: 81.19%, Train_loss: 0.493517, Test_accuracy: 68.48%, Test_loss: 0.607594\n",
      "batch size: 256, fold: 1| Epoch 38: Train_accuracy: 82.03%, Train_loss: 0.487651, Test_accuracy: 69.19%, Test_loss: 0.605667\n",
      "batch size: 256, fold: 1| Epoch 39: Train_accuracy: 81.75%, Train_loss: 0.488700, Test_accuracy: 70.79%, Test_loss: 0.584860\n",
      "batch size: 256, fold: 1| Epoch 40: Train_accuracy: 82.02%, Train_loss: 0.485302, Test_accuracy: 69.08%, Test_loss: 0.606293\n",
      "batch size: 256, fold: 1| Epoch 41: Train_accuracy: 81.34%, Train_loss: 0.488314, Test_accuracy: 69.55%, Test_loss: 0.597482\n",
      "batch size: 256, fold: 1| Epoch 42: Train_accuracy: 82.58%, Train_loss: 0.480199, Test_accuracy: 70.26%, Test_loss: 0.596693\n",
      "batch size: 256, fold: 1| Epoch 43: Train_accuracy: 82.21%, Train_loss: 0.481699, Test_accuracy: 68.78%, Test_loss: 0.600218\n",
      "batch size: 256, fold: 1| Epoch 44: Train_accuracy: 82.24%, Train_loss: 0.485437, Test_accuracy: 69.25%, Test_loss: 0.602963\n",
      "batch size: 256, fold: 1| Epoch 45: Train_accuracy: 82.60%, Train_loss: 0.480903, Test_accuracy: 69.31%, Test_loss: 0.602885\n",
      "batch size: 256, fold: 1| Epoch 46: Train_accuracy: 83.74%, Train_loss: 0.471066, Test_accuracy: 71.33%, Test_loss: 0.588950\n",
      "batch size: 256, fold: 1| Epoch 47: Train_accuracy: 83.31%, Train_loss: 0.475184, Test_accuracy: 69.14%, Test_loss: 0.602560\n",
      "batch size: 256, fold: 1| Epoch 48: Train_accuracy: 83.41%, Train_loss: 0.472335, Test_accuracy: 70.38%, Test_loss: 0.589356\n",
      "batch size: 256, fold: 1| Epoch 49: Train_accuracy: 83.23%, Train_loss: 0.473706, Test_accuracy: 68.31%, Test_loss: 0.607734\n",
      "batch size: 256, fold: 1| Epoch 50: Train_accuracy: 83.69%, Train_loss: 0.469211, Test_accuracy: 70.26%, Test_loss: 0.592516\n",
      "batch size: 256, fold: 1| Epoch 51: Train_accuracy: 83.42%, Train_loss: 0.472941, Test_accuracy: 69.55%, Test_loss: 0.597156\n",
      "batch size: 256, fold: 1| Epoch 52: Train_accuracy: 83.88%, Train_loss: 0.467759, Test_accuracy: 69.96%, Test_loss: 0.596026\n",
      "batch size: 256, fold: 1| Epoch 53: Train_accuracy: 83.60%, Train_loss: 0.471067, Test_accuracy: 70.50%, Test_loss: 0.593770\n",
      "batch size: 256, fold: 1| Epoch 54: Train_accuracy: 84.49%, Train_loss: 0.463762, Test_accuracy: 70.20%, Test_loss: 0.598287\n",
      "batch size: 256, fold: 1| Epoch 55: Train_accuracy: 84.55%, Train_loss: 0.461466, Test_accuracy: 71.27%, Test_loss: 0.589640\n",
      "batch size: 256, fold: 1| Epoch 56: Train_accuracy: 84.64%, Train_loss: 0.463023, Test_accuracy: 70.91%, Test_loss: 0.590599\n",
      "batch size: 256, fold: 1| Epoch 57: Train_accuracy: 85.28%, Train_loss: 0.455884, Test_accuracy: 70.32%, Test_loss: 0.592195\n",
      "batch size: 256, fold: 1| Epoch 58: Train_accuracy: 84.70%, Train_loss: 0.462058, Test_accuracy: 69.91%, Test_loss: 0.600719\n",
      "batch size: 256, fold: 1| Epoch 59: Train_accuracy: 84.92%, Train_loss: 0.459805, Test_accuracy: 71.74%, Test_loss: 0.578910\n",
      "batch size: 256, fold: 1| Epoch 60: Train_accuracy: 85.54%, Train_loss: 0.455860, Test_accuracy: 70.73%, Test_loss: 0.586850\n",
      "batch size: 256, fold: 1| Epoch 61: Train_accuracy: 85.53%, Train_loss: 0.451572, Test_accuracy: 72.10%, Test_loss: 0.580068\n",
      "batch size: 256, fold: 1| Epoch 62: Train_accuracy: 85.78%, Train_loss: 0.451600, Test_accuracy: 70.26%, Test_loss: 0.591686\n",
      "batch size: 256, fold: 1| Epoch 63: Train_accuracy: 85.47%, Train_loss: 0.454650, Test_accuracy: 70.56%, Test_loss: 0.596004\n",
      "batch size: 256, fold: 1| Epoch 64: Train_accuracy: 86.19%, Train_loss: 0.448541, Test_accuracy: 70.26%, Test_loss: 0.593367\n",
      "batch size: 256, fold: 1| Epoch 65: Train_accuracy: 86.02%, Train_loss: 0.449904, Test_accuracy: 71.50%, Test_loss: 0.584992\n",
      "batch size: 256, fold: 1| Epoch 66: Train_accuracy: 85.44%, Train_loss: 0.454076, Test_accuracy: 71.09%, Test_loss: 0.586658\n",
      "batch size: 256, fold: 1| Epoch 67: Train_accuracy: 86.55%, Train_loss: 0.444345, Test_accuracy: 71.45%, Test_loss: 0.584858\n",
      "batch size: 256, fold: 1| Epoch 68: Train_accuracy: 85.62%, Train_loss: 0.451372, Test_accuracy: 71.74%, Test_loss: 0.577858\n",
      "batch size: 256, fold: 1| Epoch 69: Train_accuracy: 86.46%, Train_loss: 0.443850, Test_accuracy: 71.92%, Test_loss: 0.579185\n",
      "batch size: 256, fold: 1| Epoch 70: Train_accuracy: 86.28%, Train_loss: 0.446305, Test_accuracy: 72.10%, Test_loss: 0.585665\n",
      "batch size: 256, fold: 1| Epoch 71: Train_accuracy: 85.23%, Train_loss: 0.451836, Test_accuracy: 69.37%, Test_loss: 0.605360\n",
      "batch size: 256, fold: 1| Epoch 72: Train_accuracy: 86.43%, Train_loss: 0.441228, Test_accuracy: 71.03%, Test_loss: 0.586241\n",
      "batch size: 256, fold: 1| Epoch 73: Train_accuracy: 86.59%, Train_loss: 0.440993, Test_accuracy: 69.79%, Test_loss: 0.592597\n",
      "batch size: 256, fold: 1| Epoch 74: Train_accuracy: 86.91%, Train_loss: 0.440494, Test_accuracy: 72.16%, Test_loss: 0.577364\n",
      "batch size: 256, fold: 1| Epoch 75: Train_accuracy: 86.80%, Train_loss: 0.442450, Test_accuracy: 71.56%, Test_loss: 0.584689\n",
      "batch size: 256, fold: 1| Epoch 76: Train_accuracy: 87.07%, Train_loss: 0.439928, Test_accuracy: 71.33%, Test_loss: 0.584771\n",
      "batch size: 256, fold: 1| Epoch 77: Train_accuracy: 86.83%, Train_loss: 0.443083, Test_accuracy: 71.56%, Test_loss: 0.588179\n",
      "batch size: 256, fold: 1| Epoch 78: Train_accuracy: 87.01%, Train_loss: 0.441821, Test_accuracy: 71.45%, Test_loss: 0.581145\n",
      "batch size: 256, fold: 1| Epoch 79: Train_accuracy: 87.10%, Train_loss: 0.437253, Test_accuracy: 69.85%, Test_loss: 0.598542\n",
      "batch size: 256, fold: 1| Epoch 80: Train_accuracy: 87.35%, Train_loss: 0.434956, Test_accuracy: 71.45%, Test_loss: 0.584872\n",
      "batch size: 256, fold: 1| Epoch 81: Train_accuracy: 87.81%, Train_loss: 0.432271, Test_accuracy: 72.93%, Test_loss: 0.573693\n",
      "batch size: 256, fold: 1| Epoch 82: Train_accuracy: 87.51%, Train_loss: 0.435799, Test_accuracy: 71.50%, Test_loss: 0.585991\n",
      "batch size: 256, fold: 1| Epoch 83: Train_accuracy: 88.03%, Train_loss: 0.429130, Test_accuracy: 71.86%, Test_loss: 0.583142\n",
      "batch size: 256, fold: 1| Epoch 84: Train_accuracy: 88.02%, Train_loss: 0.431821, Test_accuracy: 71.80%, Test_loss: 0.576155\n",
      "batch size: 256, fold: 1| Epoch 85: Train_accuracy: 87.65%, Train_loss: 0.431479, Test_accuracy: 71.80%, Test_loss: 0.583639\n",
      "batch size: 256, fold: 1| Epoch 86: Train_accuracy: 87.99%, Train_loss: 0.429833, Test_accuracy: 71.56%, Test_loss: 0.576764\n",
      "batch size: 256, fold: 1| Epoch 87: Train_accuracy: 88.27%, Train_loss: 0.426301, Test_accuracy: 72.16%, Test_loss: 0.576916\n",
      "batch size: 256, fold: 1| Epoch 88: Train_accuracy: 87.99%, Train_loss: 0.431852, Test_accuracy: 71.56%, Test_loss: 0.583765\n",
      "batch size: 256, fold: 1| Epoch 89: Train_accuracy: 87.87%, Train_loss: 0.430570, Test_accuracy: 71.39%, Test_loss: 0.583668\n",
      "batch size: 256, fold: 1| Epoch 90: Train_accuracy: 88.18%, Train_loss: 0.426858, Test_accuracy: 71.56%, Test_loss: 0.584455\n",
      "batch size: 256, fold: 1| Epoch 91: Train_accuracy: 88.70%, Train_loss: 0.424048, Test_accuracy: 72.27%, Test_loss: 0.576016\n",
      "batch size: 256, fold: 1| Epoch 92: Train_accuracy: 88.15%, Train_loss: 0.429048, Test_accuracy: 71.80%, Test_loss: 0.583846\n",
      "batch size: 256, fold: 1| Epoch 93: Train_accuracy: 89.08%, Train_loss: 0.421016, Test_accuracy: 71.27%, Test_loss: 0.585720\n",
      "batch size: 256, fold: 1| Epoch 94: Train_accuracy: 88.05%, Train_loss: 0.428351, Test_accuracy: 71.86%, Test_loss: 0.581393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 256, fold: 1| Epoch 95: Train_accuracy: 87.65%, Train_loss: 0.432225, Test_accuracy: 71.27%, Test_loss: 0.586427\n",
      "batch size: 256, fold: 1| Epoch 96: Train_accuracy: 88.88%, Train_loss: 0.421854, Test_accuracy: 71.86%, Test_loss: 0.584815\n",
      "batch size: 256, fold: 1| Epoch 97: Train_accuracy: 88.98%, Train_loss: 0.422615, Test_accuracy: 72.04%, Test_loss: 0.583611\n",
      "batch size: 256, fold: 1| Epoch 98: Train_accuracy: 88.45%, Train_loss: 0.423725, Test_accuracy: 71.62%, Test_loss: 0.581902\n",
      "batch size: 256, fold: 1| Epoch 99: Train_accuracy: 89.16%, Train_loss: 0.420528, Test_accuracy: 72.27%, Test_loss: 0.584688\n",
      "batch size: 256, fold: 1| Epoch 100: Train_accuracy: 88.68%, Train_loss: 0.421413, Test_accuracy: 72.16%, Test_loss: 0.581504\n",
      "batch size: 256, fold: 2| Epoch 1: Train_accuracy: 54.50%, Train_loss: 0.689650, Test_accuracy: 55.98%, Test_loss: 0.686785\n",
      "batch size: 256, fold: 2| Epoch 2: Train_accuracy: 56.84%, Train_loss: 0.679495, Test_accuracy: 57.23%, Test_loss: 0.681394\n",
      "batch size: 256, fold: 2| Epoch 3: Train_accuracy: 60.32%, Train_loss: 0.666142, Test_accuracy: 58.65%, Test_loss: 0.671593\n",
      "batch size: 256, fold: 2| Epoch 4: Train_accuracy: 61.80%, Train_loss: 0.656294, Test_accuracy: 58.59%, Test_loss: 0.665501\n",
      "batch size: 256, fold: 2| Epoch 5: Train_accuracy: 63.75%, Train_loss: 0.645119, Test_accuracy: 58.35%, Test_loss: 0.673730\n",
      "batch size: 256, fold: 2| Epoch 6: Train_accuracy: 64.05%, Train_loss: 0.638425, Test_accuracy: 58.53%, Test_loss: 0.674696\n",
      "batch size: 256, fold: 2| Epoch 7: Train_accuracy: 64.95%, Train_loss: 0.628107, Test_accuracy: 60.72%, Test_loss: 0.666378\n",
      "batch size: 256, fold: 2| Epoch 8: Train_accuracy: 66.43%, Train_loss: 0.621913, Test_accuracy: 60.37%, Test_loss: 0.665750\n",
      "batch size: 256, fold: 2| Epoch 9: Train_accuracy: 67.49%, Train_loss: 0.612823, Test_accuracy: 61.20%, Test_loss: 0.652582\n",
      "batch size: 256, fold: 2| Epoch 10: Train_accuracy: 67.93%, Train_loss: 0.611304, Test_accuracy: 61.97%, Test_loss: 0.654832\n",
      "batch size: 256, fold: 2| Epoch 11: Train_accuracy: 69.17%, Train_loss: 0.603069, Test_accuracy: 60.60%, Test_loss: 0.665191\n",
      "batch size: 256, fold: 2| Epoch 12: Train_accuracy: 69.07%, Train_loss: 0.601293, Test_accuracy: 62.03%, Test_loss: 0.652819\n",
      "batch size: 256, fold: 2| Epoch 13: Train_accuracy: 70.75%, Train_loss: 0.585839, Test_accuracy: 63.27%, Test_loss: 0.649483\n",
      "batch size: 256, fold: 2| Epoch 14: Train_accuracy: 71.47%, Train_loss: 0.580893, Test_accuracy: 63.80%, Test_loss: 0.642027\n",
      "batch size: 256, fold: 2| Epoch 15: Train_accuracy: 72.23%, Train_loss: 0.578305, Test_accuracy: 64.04%, Test_loss: 0.650675\n",
      "batch size: 256, fold: 2| Epoch 16: Train_accuracy: 72.23%, Train_loss: 0.574323, Test_accuracy: 62.80%, Test_loss: 0.655111\n",
      "batch size: 256, fold: 2| Epoch 17: Train_accuracy: 73.25%, Train_loss: 0.565446, Test_accuracy: 64.93%, Test_loss: 0.634999\n",
      "batch size: 256, fold: 2| Epoch 18: Train_accuracy: 73.44%, Train_loss: 0.560592, Test_accuracy: 64.81%, Test_loss: 0.632771\n",
      "batch size: 256, fold: 2| Epoch 19: Train_accuracy: 74.37%, Train_loss: 0.556680, Test_accuracy: 66.82%, Test_loss: 0.623960\n",
      "batch size: 256, fold: 2| Epoch 20: Train_accuracy: 74.33%, Train_loss: 0.556673, Test_accuracy: 66.71%, Test_loss: 0.622375\n",
      "batch size: 256, fold: 2| Epoch 21: Train_accuracy: 75.35%, Train_loss: 0.549031, Test_accuracy: 66.77%, Test_loss: 0.623385\n",
      "batch size: 256, fold: 2| Epoch 22: Train_accuracy: 75.72%, Train_loss: 0.544652, Test_accuracy: 66.77%, Test_loss: 0.618429\n",
      "batch size: 256, fold: 2| Epoch 23: Train_accuracy: 76.52%, Train_loss: 0.541672, Test_accuracy: 66.23%, Test_loss: 0.619777\n",
      "batch size: 256, fold: 2| Epoch 24: Train_accuracy: 76.80%, Train_loss: 0.534152, Test_accuracy: 66.65%, Test_loss: 0.619718\n",
      "batch size: 256, fold: 2| Epoch 25: Train_accuracy: 77.71%, Train_loss: 0.525579, Test_accuracy: 68.13%, Test_loss: 0.614410\n",
      "batch size: 256, fold: 2| Epoch 26: Train_accuracy: 77.94%, Train_loss: 0.523505, Test_accuracy: 66.59%, Test_loss: 0.624949\n",
      "batch size: 256, fold: 2| Epoch 27: Train_accuracy: 77.69%, Train_loss: 0.525232, Test_accuracy: 67.42%, Test_loss: 0.619792\n",
      "batch size: 256, fold: 2| Epoch 28: Train_accuracy: 77.90%, Train_loss: 0.525170, Test_accuracy: 66.35%, Test_loss: 0.624957\n",
      "batch size: 256, fold: 2| Epoch 29: Train_accuracy: 78.23%, Train_loss: 0.523591, Test_accuracy: 67.18%, Test_loss: 0.616922\n",
      "batch size: 256, fold: 2| Epoch 30: Train_accuracy: 79.60%, Train_loss: 0.511697, Test_accuracy: 68.25%, Test_loss: 0.607608\n",
      "batch size: 256, fold: 2| Epoch 31: Train_accuracy: 80.03%, Train_loss: 0.508054, Test_accuracy: 68.19%, Test_loss: 0.607110\n",
      "batch size: 256, fold: 2| Epoch 32: Train_accuracy: 80.27%, Train_loss: 0.506384, Test_accuracy: 69.37%, Test_loss: 0.604505\n",
      "batch size: 256, fold: 2| Epoch 33: Train_accuracy: 79.57%, Train_loss: 0.507831, Test_accuracy: 68.19%, Test_loss: 0.614983\n",
      "batch size: 256, fold: 2| Epoch 34: Train_accuracy: 79.44%, Train_loss: 0.508862, Test_accuracy: 68.31%, Test_loss: 0.612646\n",
      "batch size: 256, fold: 2| Epoch 35: Train_accuracy: 80.48%, Train_loss: 0.499448, Test_accuracy: 69.55%, Test_loss: 0.597919\n",
      "batch size: 256, fold: 2| Epoch 36: Train_accuracy: 79.99%, Train_loss: 0.503212, Test_accuracy: 68.31%, Test_loss: 0.610162\n",
      "batch size: 256, fold: 2| Epoch 37: Train_accuracy: 81.42%, Train_loss: 0.494415, Test_accuracy: 68.19%, Test_loss: 0.610876\n",
      "batch size: 256, fold: 2| Epoch 38: Train_accuracy: 80.80%, Train_loss: 0.494646, Test_accuracy: 68.48%, Test_loss: 0.605940\n",
      "batch size: 256, fold: 2| Epoch 39: Train_accuracy: 81.72%, Train_loss: 0.490822, Test_accuracy: 68.78%, Test_loss: 0.606802\n",
      "batch size: 256, fold: 2| Epoch 40: Train_accuracy: 81.63%, Train_loss: 0.489774, Test_accuracy: 68.60%, Test_loss: 0.606614\n",
      "batch size: 256, fold: 2| Epoch 41: Train_accuracy: 81.82%, Train_loss: 0.488140, Test_accuracy: 69.25%, Test_loss: 0.603882\n",
      "batch size: 256, fold: 2| Epoch 42: Train_accuracy: 82.33%, Train_loss: 0.484654, Test_accuracy: 69.43%, Test_loss: 0.599856\n",
      "batch size: 256, fold: 2| Epoch 43: Train_accuracy: 81.90%, Train_loss: 0.484802, Test_accuracy: 70.38%, Test_loss: 0.595128\n",
      "batch size: 256, fold: 2| Epoch 44: Train_accuracy: 83.00%, Train_loss: 0.478311, Test_accuracy: 69.73%, Test_loss: 0.602371\n",
      "batch size: 256, fold: 2| Epoch 45: Train_accuracy: 82.80%, Train_loss: 0.481599, Test_accuracy: 69.25%, Test_loss: 0.604469\n",
      "batch size: 256, fold: 2| Epoch 46: Train_accuracy: 82.94%, Train_loss: 0.477701, Test_accuracy: 68.19%, Test_loss: 0.612222\n",
      "batch size: 256, fold: 2| Epoch 47: Train_accuracy: 82.34%, Train_loss: 0.481914, Test_accuracy: 69.73%, Test_loss: 0.597143\n",
      "batch size: 256, fold: 2| Epoch 48: Train_accuracy: 82.79%, Train_loss: 0.477655, Test_accuracy: 69.19%, Test_loss: 0.605076\n",
      "batch size: 256, fold: 2| Epoch 49: Train_accuracy: 83.08%, Train_loss: 0.477827, Test_accuracy: 71.21%, Test_loss: 0.594826\n",
      "batch size: 256, fold: 2| Epoch 50: Train_accuracy: 83.75%, Train_loss: 0.469643, Test_accuracy: 69.61%, Test_loss: 0.602998\n",
      "batch size: 256, fold: 2| Epoch 51: Train_accuracy: 83.40%, Train_loss: 0.472430, Test_accuracy: 71.56%, Test_loss: 0.589159\n",
      "batch size: 256, fold: 2| Epoch 52: Train_accuracy: 83.82%, Train_loss: 0.469352, Test_accuracy: 69.79%, Test_loss: 0.592018\n",
      "batch size: 256, fold: 2| Epoch 53: Train_accuracy: 84.85%, Train_loss: 0.463537, Test_accuracy: 69.49%, Test_loss: 0.598948\n",
      "batch size: 256, fold: 2| Epoch 54: Train_accuracy: 84.67%, Train_loss: 0.459396, Test_accuracy: 70.73%, Test_loss: 0.591955\n",
      "batch size: 256, fold: 2| Epoch 55: Train_accuracy: 84.40%, Train_loss: 0.466033, Test_accuracy: 70.79%, Test_loss: 0.581779\n",
      "batch size: 256, fold: 2| Epoch 56: Train_accuracy: 84.40%, Train_loss: 0.464012, Test_accuracy: 70.91%, Test_loss: 0.587862\n",
      "batch size: 256, fold: 2| Epoch 57: Train_accuracy: 83.84%, Train_loss: 0.469120, Test_accuracy: 69.61%, Test_loss: 0.599804\n",
      "batch size: 256, fold: 2| Epoch 58: Train_accuracy: 84.91%, Train_loss: 0.461374, Test_accuracy: 69.96%, Test_loss: 0.598412\n",
      "batch size: 256, fold: 2| Epoch 59: Train_accuracy: 85.17%, Train_loss: 0.457385, Test_accuracy: 72.99%, Test_loss: 0.577348\n",
      "batch size: 256, fold: 2| Epoch 60: Train_accuracy: 84.77%, Train_loss: 0.460517, Test_accuracy: 70.97%, Test_loss: 0.586877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 256, fold: 2| Epoch 61: Train_accuracy: 84.67%, Train_loss: 0.463817, Test_accuracy: 70.62%, Test_loss: 0.593292\n",
      "batch size: 256, fold: 2| Epoch 62: Train_accuracy: 84.99%, Train_loss: 0.459485, Test_accuracy: 69.91%, Test_loss: 0.599394\n",
      "batch size: 256, fold: 2| Epoch 63: Train_accuracy: 85.84%, Train_loss: 0.451664, Test_accuracy: 69.96%, Test_loss: 0.594863\n",
      "batch size: 256, fold: 2| Epoch 64: Train_accuracy: 85.81%, Train_loss: 0.451232, Test_accuracy: 70.62%, Test_loss: 0.594555\n",
      "batch size: 256, fold: 2| Epoch 65: Train_accuracy: 85.25%, Train_loss: 0.456343, Test_accuracy: 71.27%, Test_loss: 0.584214\n",
      "batch size: 256, fold: 2| Epoch 66: Train_accuracy: 86.02%, Train_loss: 0.449264, Test_accuracy: 71.21%, Test_loss: 0.586082\n",
      "batch size: 256, fold: 2| Epoch 67: Train_accuracy: 85.59%, Train_loss: 0.451252, Test_accuracy: 71.27%, Test_loss: 0.580223\n",
      "batch size: 256, fold: 2| Epoch 68: Train_accuracy: 86.03%, Train_loss: 0.448170, Test_accuracy: 70.38%, Test_loss: 0.597252\n",
      "batch size: 256, fold: 2| Epoch 69: Train_accuracy: 86.06%, Train_loss: 0.447111, Test_accuracy: 71.27%, Test_loss: 0.583957\n",
      "batch size: 256, fold: 2| Epoch 70: Train_accuracy: 86.45%, Train_loss: 0.444299, Test_accuracy: 70.32%, Test_loss: 0.597741\n",
      "batch size: 256, fold: 2| Epoch 71: Train_accuracy: 85.54%, Train_loss: 0.451914, Test_accuracy: 72.10%, Test_loss: 0.577847\n",
      "batch size: 256, fold: 2| Epoch 72: Train_accuracy: 86.12%, Train_loss: 0.447043, Test_accuracy: 69.43%, Test_loss: 0.603669\n",
      "batch size: 256, fold: 2| Epoch 73: Train_accuracy: 87.13%, Train_loss: 0.437861, Test_accuracy: 70.85%, Test_loss: 0.591377\n",
      "batch size: 256, fold: 2| Epoch 74: Train_accuracy: 86.40%, Train_loss: 0.443038, Test_accuracy: 72.16%, Test_loss: 0.578886\n",
      "batch size: 256, fold: 2| Epoch 75: Train_accuracy: 86.85%, Train_loss: 0.441127, Test_accuracy: 70.91%, Test_loss: 0.593861\n",
      "batch size: 256, fold: 2| Epoch 76: Train_accuracy: 86.49%, Train_loss: 0.442851, Test_accuracy: 71.45%, Test_loss: 0.581931\n",
      "batch size: 256, fold: 2| Epoch 77: Train_accuracy: 86.88%, Train_loss: 0.439693, Test_accuracy: 71.15%, Test_loss: 0.585362\n",
      "batch size: 256, fold: 2| Epoch 78: Train_accuracy: 87.17%, Train_loss: 0.440379, Test_accuracy: 71.15%, Test_loss: 0.593588\n",
      "batch size: 256, fold: 2| Epoch 79: Train_accuracy: 86.48%, Train_loss: 0.442298, Test_accuracy: 70.85%, Test_loss: 0.585482\n",
      "batch size: 256, fold: 2| Epoch 80: Train_accuracy: 87.13%, Train_loss: 0.439436, Test_accuracy: 71.68%, Test_loss: 0.575711\n",
      "batch size: 256, fold: 2| Epoch 81: Train_accuracy: 87.41%, Train_loss: 0.434816, Test_accuracy: 71.50%, Test_loss: 0.587507\n",
      "batch size: 256, fold: 2| Epoch 82: Train_accuracy: 87.68%, Train_loss: 0.433653, Test_accuracy: 71.68%, Test_loss: 0.578094\n",
      "batch size: 256, fold: 2| Epoch 83: Train_accuracy: 87.17%, Train_loss: 0.438135, Test_accuracy: 71.27%, Test_loss: 0.587194\n",
      "batch size: 256, fold: 2| Epoch 84: Train_accuracy: 87.26%, Train_loss: 0.434304, Test_accuracy: 71.50%, Test_loss: 0.582864\n",
      "batch size: 256, fold: 2| Epoch 85: Train_accuracy: 87.20%, Train_loss: 0.434786, Test_accuracy: 71.03%, Test_loss: 0.588388\n",
      "batch size: 256, fold: 2| Epoch 86: Train_accuracy: 87.69%, Train_loss: 0.434320, Test_accuracy: 72.75%, Test_loss: 0.576372\n",
      "batch size: 256, fold: 2| Epoch 87: Train_accuracy: 87.72%, Train_loss: 0.433827, Test_accuracy: 71.21%, Test_loss: 0.584451\n",
      "batch size: 256, fold: 2| Epoch 88: Train_accuracy: 87.01%, Train_loss: 0.437324, Test_accuracy: 73.10%, Test_loss: 0.568680\n",
      "batch size: 256, fold: 2| Epoch 89: Train_accuracy: 87.79%, Train_loss: 0.430426, Test_accuracy: 73.34%, Test_loss: 0.572625\n",
      "batch size: 256, fold: 2| Epoch 90: Train_accuracy: 88.19%, Train_loss: 0.429444, Test_accuracy: 70.32%, Test_loss: 0.589093\n",
      "batch size: 256, fold: 2| Epoch 91: Train_accuracy: 88.00%, Train_loss: 0.430938, Test_accuracy: 71.50%, Test_loss: 0.581076\n",
      "batch size: 256, fold: 2| Epoch 92: Train_accuracy: 88.25%, Train_loss: 0.428682, Test_accuracy: 71.98%, Test_loss: 0.582338\n",
      "batch size: 256, fold: 2| Epoch 93: Train_accuracy: 88.85%, Train_loss: 0.422621, Test_accuracy: 71.33%, Test_loss: 0.583566\n",
      "batch size: 256, fold: 2| Epoch 94: Train_accuracy: 88.45%, Train_loss: 0.425935, Test_accuracy: 72.22%, Test_loss: 0.576070\n",
      "batch size: 256, fold: 2| Epoch 95: Train_accuracy: 87.85%, Train_loss: 0.430493, Test_accuracy: 70.79%, Test_loss: 0.590544\n",
      "batch size: 256, fold: 2| Epoch 96: Train_accuracy: 88.56%, Train_loss: 0.425344, Test_accuracy: 71.33%, Test_loss: 0.580300\n",
      "batch size: 256, fold: 2| Epoch 97: Train_accuracy: 88.06%, Train_loss: 0.426624, Test_accuracy: 71.21%, Test_loss: 0.585312\n",
      "batch size: 256, fold: 2| Epoch 98: Train_accuracy: 88.77%, Train_loss: 0.423062, Test_accuracy: 71.98%, Test_loss: 0.580509\n",
      "batch size: 256, fold: 2| Epoch 99: Train_accuracy: 88.37%, Train_loss: 0.424586, Test_accuracy: 71.80%, Test_loss: 0.579331\n",
      "batch size: 256, fold: 2| Epoch 100: Train_accuracy: 88.56%, Train_loss: 0.424569, Test_accuracy: 71.56%, Test_loss: 0.581829\n",
      "batch size: 256, fold: 3| Epoch 1: Train_accuracy: 52.56%, Train_loss: 0.690313, Test_accuracy: 56.22%, Test_loss: 0.686503\n",
      "batch size: 256, fold: 3| Epoch 2: Train_accuracy: 57.37%, Train_loss: 0.678768, Test_accuracy: 58.59%, Test_loss: 0.679636\n",
      "batch size: 256, fold: 3| Epoch 3: Train_accuracy: 59.92%, Train_loss: 0.666139, Test_accuracy: 59.36%, Test_loss: 0.673344\n",
      "batch size: 256, fold: 3| Epoch 4: Train_accuracy: 61.15%, Train_loss: 0.656551, Test_accuracy: 59.30%, Test_loss: 0.667557\n",
      "batch size: 256, fold: 3| Epoch 5: Train_accuracy: 63.25%, Train_loss: 0.643331, Test_accuracy: 58.59%, Test_loss: 0.677677\n",
      "batch size: 256, fold: 3| Epoch 6: Train_accuracy: 64.43%, Train_loss: 0.636714, Test_accuracy: 60.43%, Test_loss: 0.657809\n",
      "batch size: 256, fold: 3| Epoch 7: Train_accuracy: 65.19%, Train_loss: 0.627508, Test_accuracy: 60.96%, Test_loss: 0.665621\n",
      "batch size: 256, fold: 3| Epoch 8: Train_accuracy: 66.72%, Train_loss: 0.619764, Test_accuracy: 62.62%, Test_loss: 0.658280\n",
      "batch size: 256, fold: 3| Epoch 9: Train_accuracy: 67.53%, Train_loss: 0.615741, Test_accuracy: 60.37%, Test_loss: 0.666203\n",
      "batch size: 256, fold: 3| Epoch 10: Train_accuracy: 68.23%, Train_loss: 0.612201, Test_accuracy: 62.68%, Test_loss: 0.651166\n",
      "batch size: 256, fold: 3| Epoch 11: Train_accuracy: 68.51%, Train_loss: 0.605153, Test_accuracy: 63.51%, Test_loss: 0.649196\n",
      "batch size: 256, fold: 3| Epoch 12: Train_accuracy: 70.05%, Train_loss: 0.592113, Test_accuracy: 63.57%, Test_loss: 0.646709\n",
      "batch size: 256, fold: 3| Epoch 13: Train_accuracy: 70.52%, Train_loss: 0.586882, Test_accuracy: 62.74%, Test_loss: 0.643580\n",
      "batch size: 256, fold: 3| Epoch 14: Train_accuracy: 71.46%, Train_loss: 0.581442, Test_accuracy: 64.99%, Test_loss: 0.639553\n",
      "batch size: 256, fold: 3| Epoch 15: Train_accuracy: 72.34%, Train_loss: 0.574657, Test_accuracy: 64.40%, Test_loss: 0.636971\n",
      "batch size: 256, fold: 3| Epoch 16: Train_accuracy: 72.42%, Train_loss: 0.576464, Test_accuracy: 63.68%, Test_loss: 0.652996\n",
      "batch size: 256, fold: 3| Epoch 17: Train_accuracy: 73.07%, Train_loss: 0.570767, Test_accuracy: 64.40%, Test_loss: 0.629321\n",
      "batch size: 256, fold: 3| Epoch 18: Train_accuracy: 73.96%, Train_loss: 0.557995, Test_accuracy: 63.45%, Test_loss: 0.649052\n",
      "batch size: 256, fold: 3| Epoch 19: Train_accuracy: 74.36%, Train_loss: 0.556751, Test_accuracy: 66.41%, Test_loss: 0.625638\n",
      "batch size: 256, fold: 3| Epoch 20: Train_accuracy: 73.52%, Train_loss: 0.559880, Test_accuracy: 66.41%, Test_loss: 0.624084\n",
      "batch size: 256, fold: 3| Epoch 21: Train_accuracy: 75.25%, Train_loss: 0.549896, Test_accuracy: 67.06%, Test_loss: 0.625027\n",
      "batch size: 256, fold: 3| Epoch 22: Train_accuracy: 75.11%, Train_loss: 0.546910, Test_accuracy: 65.58%, Test_loss: 0.637073\n",
      "batch size: 256, fold: 3| Epoch 23: Train_accuracy: 75.06%, Train_loss: 0.549587, Test_accuracy: 65.52%, Test_loss: 0.627862\n",
      "batch size: 256, fold: 3| Epoch 24: Train_accuracy: 75.62%, Train_loss: 0.541644, Test_accuracy: 66.59%, Test_loss: 0.623123\n",
      "batch size: 256, fold: 3| Epoch 25: Train_accuracy: 77.16%, Train_loss: 0.532684, Test_accuracy: 66.53%, Test_loss: 0.622889\n",
      "batch size: 256, fold: 3| Epoch 26: Train_accuracy: 76.45%, Train_loss: 0.536226, Test_accuracy: 69.08%, Test_loss: 0.608807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 256, fold: 3| Epoch 27: Train_accuracy: 77.00%, Train_loss: 0.529778, Test_accuracy: 65.88%, Test_loss: 0.629019\n",
      "batch size: 256, fold: 3| Epoch 28: Train_accuracy: 77.88%, Train_loss: 0.524504, Test_accuracy: 67.06%, Test_loss: 0.618877\n",
      "batch size: 256, fold: 3| Epoch 29: Train_accuracy: 78.48%, Train_loss: 0.520528, Test_accuracy: 66.41%, Test_loss: 0.619737\n",
      "batch size: 256, fold: 3| Epoch 30: Train_accuracy: 78.91%, Train_loss: 0.518436, Test_accuracy: 67.36%, Test_loss: 0.617974\n",
      "batch size: 256, fold: 3| Epoch 31: Train_accuracy: 78.27%, Train_loss: 0.518439, Test_accuracy: 67.54%, Test_loss: 0.616580\n",
      "batch size: 256, fold: 3| Epoch 32: Train_accuracy: 79.16%, Train_loss: 0.512109, Test_accuracy: 67.18%, Test_loss: 0.614662\n",
      "batch size: 256, fold: 3| Epoch 33: Train_accuracy: 79.50%, Train_loss: 0.506620, Test_accuracy: 69.55%, Test_loss: 0.608260\n",
      "batch size: 256, fold: 3| Epoch 34: Train_accuracy: 79.66%, Train_loss: 0.508842, Test_accuracy: 66.88%, Test_loss: 0.619975\n",
      "batch size: 256, fold: 3| Epoch 35: Train_accuracy: 79.94%, Train_loss: 0.503478, Test_accuracy: 67.12%, Test_loss: 0.617210\n",
      "batch size: 256, fold: 3| Epoch 36: Train_accuracy: 81.03%, Train_loss: 0.497505, Test_accuracy: 66.82%, Test_loss: 0.622843\n",
      "batch size: 256, fold: 3| Epoch 37: Train_accuracy: 81.03%, Train_loss: 0.498292, Test_accuracy: 67.65%, Test_loss: 0.618312\n",
      "batch size: 256, fold: 3| Epoch 38: Train_accuracy: 81.54%, Train_loss: 0.492221, Test_accuracy: 68.36%, Test_loss: 0.612967\n",
      "batch size: 256, fold: 3| Epoch 39: Train_accuracy: 81.00%, Train_loss: 0.495098, Test_accuracy: 66.59%, Test_loss: 0.625744\n",
      "batch size: 256, fold: 3| Epoch 40: Train_accuracy: 81.41%, Train_loss: 0.492415, Test_accuracy: 70.50%, Test_loss: 0.597904\n",
      "batch size: 256, fold: 3| Epoch 41: Train_accuracy: 82.21%, Train_loss: 0.485772, Test_accuracy: 69.14%, Test_loss: 0.602979\n",
      "batch size: 256, fold: 3| Epoch 42: Train_accuracy: 81.87%, Train_loss: 0.487711, Test_accuracy: 68.36%, Test_loss: 0.612231\n",
      "batch size: 256, fold: 3| Epoch 43: Train_accuracy: 82.03%, Train_loss: 0.485661, Test_accuracy: 71.62%, Test_loss: 0.582889\n",
      "batch size: 256, fold: 3| Epoch 44: Train_accuracy: 82.85%, Train_loss: 0.479855, Test_accuracy: 68.66%, Test_loss: 0.603906\n",
      "batch size: 256, fold: 3| Epoch 45: Train_accuracy: 82.65%, Train_loss: 0.481592, Test_accuracy: 69.31%, Test_loss: 0.606085\n",
      "batch size: 256, fold: 3| Epoch 46: Train_accuracy: 81.78%, Train_loss: 0.486512, Test_accuracy: 70.32%, Test_loss: 0.594387\n",
      "batch size: 256, fold: 3| Epoch 47: Train_accuracy: 82.67%, Train_loss: 0.476811, Test_accuracy: 69.61%, Test_loss: 0.602332\n",
      "batch size: 256, fold: 3| Epoch 48: Train_accuracy: 82.51%, Train_loss: 0.480568, Test_accuracy: 69.55%, Test_loss: 0.597664\n",
      "batch size: 256, fold: 3| Epoch 49: Train_accuracy: 83.51%, Train_loss: 0.472694, Test_accuracy: 69.79%, Test_loss: 0.599020\n",
      "batch size: 256, fold: 3| Epoch 50: Train_accuracy: 83.11%, Train_loss: 0.475955, Test_accuracy: 69.37%, Test_loss: 0.597811\n",
      "batch size: 256, fold: 3| Epoch 51: Train_accuracy: 83.85%, Train_loss: 0.467775, Test_accuracy: 68.78%, Test_loss: 0.599736\n",
      "batch size: 256, fold: 3| Epoch 52: Train_accuracy: 83.65%, Train_loss: 0.471948, Test_accuracy: 69.85%, Test_loss: 0.599423\n",
      "batch size: 256, fold: 3| Epoch 53: Train_accuracy: 83.94%, Train_loss: 0.466684, Test_accuracy: 70.26%, Test_loss: 0.594231\n",
      "batch size: 256, fold: 3| Epoch 54: Train_accuracy: 83.50%, Train_loss: 0.470921, Test_accuracy: 68.84%, Test_loss: 0.605344\n",
      "batch size: 256, fold: 3| Epoch 55: Train_accuracy: 83.23%, Train_loss: 0.471746, Test_accuracy: 70.20%, Test_loss: 0.598383\n",
      "batch size: 256, fold: 3| Epoch 56: Train_accuracy: 84.19%, Train_loss: 0.467124, Test_accuracy: 70.44%, Test_loss: 0.595832\n",
      "batch size: 256, fold: 3| Epoch 57: Train_accuracy: 84.49%, Train_loss: 0.462579, Test_accuracy: 69.73%, Test_loss: 0.599356\n",
      "batch size: 256, fold: 3| Epoch 58: Train_accuracy: 84.59%, Train_loss: 0.460336, Test_accuracy: 69.31%, Test_loss: 0.596368\n",
      "batch size: 256, fold: 3| Epoch 59: Train_accuracy: 84.61%, Train_loss: 0.461752, Test_accuracy: 70.97%, Test_loss: 0.590621\n",
      "batch size: 256, fold: 3| Epoch 60: Train_accuracy: 85.14%, Train_loss: 0.458611, Test_accuracy: 69.85%, Test_loss: 0.601238\n",
      "batch size: 256, fold: 3| Epoch 61: Train_accuracy: 84.92%, Train_loss: 0.458312, Test_accuracy: 70.79%, Test_loss: 0.594088\n",
      "batch size: 256, fold: 3| Epoch 62: Train_accuracy: 85.48%, Train_loss: 0.451940, Test_accuracy: 69.19%, Test_loss: 0.606215\n",
      "batch size: 256, fold: 3| Epoch 63: Train_accuracy: 85.97%, Train_loss: 0.450029, Test_accuracy: 70.79%, Test_loss: 0.582589\n",
      "batch size: 256, fold: 3| Epoch 64: Train_accuracy: 85.53%, Train_loss: 0.454326, Test_accuracy: 70.02%, Test_loss: 0.595434\n",
      "batch size: 256, fold: 3| Epoch 65: Train_accuracy: 85.97%, Train_loss: 0.448351, Test_accuracy: 71.45%, Test_loss: 0.583515\n",
      "batch size: 256, fold: 3| Epoch 66: Train_accuracy: 85.51%, Train_loss: 0.450724, Test_accuracy: 71.98%, Test_loss: 0.587861\n",
      "batch size: 256, fold: 3| Epoch 67: Train_accuracy: 86.33%, Train_loss: 0.448425, Test_accuracy: 70.91%, Test_loss: 0.584348\n",
      "batch size: 256, fold: 3| Epoch 68: Train_accuracy: 85.96%, Train_loss: 0.448057, Test_accuracy: 70.85%, Test_loss: 0.586118\n",
      "batch size: 256, fold: 3| Epoch 69: Train_accuracy: 86.34%, Train_loss: 0.445729, Test_accuracy: 72.10%, Test_loss: 0.577399\n",
      "batch size: 256, fold: 3| Epoch 70: Train_accuracy: 85.97%, Train_loss: 0.449649, Test_accuracy: 70.02%, Test_loss: 0.595002\n",
      "batch size: 256, fold: 3| Epoch 71: Train_accuracy: 86.11%, Train_loss: 0.448808, Test_accuracy: 70.08%, Test_loss: 0.593873\n",
      "batch size: 256, fold: 3| Epoch 72: Train_accuracy: 85.99%, Train_loss: 0.449125, Test_accuracy: 71.62%, Test_loss: 0.587838\n",
      "batch size: 256, fold: 3| Epoch 73: Train_accuracy: 86.21%, Train_loss: 0.446624, Test_accuracy: 72.10%, Test_loss: 0.584521\n",
      "batch size: 256, fold: 3| Epoch 74: Train_accuracy: 86.77%, Train_loss: 0.443933, Test_accuracy: 71.45%, Test_loss: 0.585019\n",
      "batch size: 256, fold: 3| Epoch 75: Train_accuracy: 87.07%, Train_loss: 0.439732, Test_accuracy: 70.91%, Test_loss: 0.586980\n",
      "batch size: 256, fold: 3| Epoch 76: Train_accuracy: 86.89%, Train_loss: 0.439889, Test_accuracy: 69.91%, Test_loss: 0.594883\n",
      "batch size: 256, fold: 3| Epoch 77: Train_accuracy: 86.52%, Train_loss: 0.440874, Test_accuracy: 70.44%, Test_loss: 0.594222\n",
      "batch size: 256, fold: 3| Epoch 78: Train_accuracy: 86.92%, Train_loss: 0.439569, Test_accuracy: 70.38%, Test_loss: 0.591734\n",
      "batch size: 256, fold: 3| Epoch 79: Train_accuracy: 86.82%, Train_loss: 0.438606, Test_accuracy: 71.50%, Test_loss: 0.583334\n",
      "batch size: 256, fold: 3| Epoch 80: Train_accuracy: 87.69%, Train_loss: 0.433247, Test_accuracy: 72.63%, Test_loss: 0.575163\n",
      "batch size: 256, fold: 3| Epoch 81: Train_accuracy: 86.98%, Train_loss: 0.438915, Test_accuracy: 70.38%, Test_loss: 0.597991\n",
      "batch size: 256, fold: 3| Epoch 82: Train_accuracy: 88.00%, Train_loss: 0.430221, Test_accuracy: 70.68%, Test_loss: 0.592792\n",
      "batch size: 256, fold: 3| Epoch 83: Train_accuracy: 87.54%, Train_loss: 0.434011, Test_accuracy: 70.91%, Test_loss: 0.590218\n",
      "batch size: 256, fold: 3| Epoch 84: Train_accuracy: 87.29%, Train_loss: 0.435722, Test_accuracy: 71.09%, Test_loss: 0.586942\n",
      "batch size: 256, fold: 3| Epoch 85: Train_accuracy: 87.04%, Train_loss: 0.437694, Test_accuracy: 73.22%, Test_loss: 0.573604\n",
      "batch size: 256, fold: 3| Epoch 86: Train_accuracy: 87.63%, Train_loss: 0.431627, Test_accuracy: 72.45%, Test_loss: 0.577226\n",
      "batch size: 256, fold: 3| Epoch 87: Train_accuracy: 87.47%, Train_loss: 0.433409, Test_accuracy: 71.39%, Test_loss: 0.584593\n",
      "batch size: 256, fold: 3| Epoch 88: Train_accuracy: 87.76%, Train_loss: 0.431350, Test_accuracy: 70.68%, Test_loss: 0.592448\n",
      "batch size: 256, fold: 3| Epoch 89: Train_accuracy: 87.56%, Train_loss: 0.430614, Test_accuracy: 70.79%, Test_loss: 0.588776\n",
      "batch size: 256, fold: 3| Epoch 90: Train_accuracy: 88.15%, Train_loss: 0.426378, Test_accuracy: 72.16%, Test_loss: 0.581648\n",
      "batch size: 256, fold: 3| Epoch 91: Train_accuracy: 87.71%, Train_loss: 0.433039, Test_accuracy: 71.50%, Test_loss: 0.588487\n",
      "batch size: 256, fold: 3| Epoch 92: Train_accuracy: 88.09%, Train_loss: 0.429973, Test_accuracy: 71.39%, Test_loss: 0.590288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 256, fold: 3| Epoch 93: Train_accuracy: 87.87%, Train_loss: 0.429855, Test_accuracy: 73.64%, Test_loss: 0.565203\n",
      "batch size: 256, fold: 3| Epoch 94: Train_accuracy: 87.79%, Train_loss: 0.430762, Test_accuracy: 70.68%, Test_loss: 0.593894\n",
      "batch size: 256, fold: 3| Epoch 95: Train_accuracy: 87.84%, Train_loss: 0.431980, Test_accuracy: 71.68%, Test_loss: 0.578199\n",
      "batch size: 256, fold: 3| Epoch 96: Train_accuracy: 88.31%, Train_loss: 0.423869, Test_accuracy: 70.79%, Test_loss: 0.590616\n",
      "batch size: 256, fold: 3| Epoch 97: Train_accuracy: 88.22%, Train_loss: 0.427579, Test_accuracy: 71.92%, Test_loss: 0.584255\n",
      "batch size: 256, fold: 3| Epoch 98: Train_accuracy: 88.00%, Train_loss: 0.427335, Test_accuracy: 71.39%, Test_loss: 0.581686\n",
      "batch size: 256, fold: 3| Epoch 99: Train_accuracy: 88.58%, Train_loss: 0.423008, Test_accuracy: 71.98%, Test_loss: 0.584508\n",
      "batch size: 256, fold: 3| Epoch 100: Train_accuracy: 88.37%, Train_loss: 0.425715, Test_accuracy: 72.57%, Test_loss: 0.577550\n",
      "batch size: 256, fold: 4| Epoch 1: Train_accuracy: 53.16%, Train_loss: 0.690231, Test_accuracy: 54.68%, Test_loss: 0.686519\n",
      "batch size: 256, fold: 4| Epoch 2: Train_accuracy: 57.16%, Train_loss: 0.679789, Test_accuracy: 57.46%, Test_loss: 0.679720\n",
      "batch size: 256, fold: 4| Epoch 3: Train_accuracy: 59.75%, Train_loss: 0.667074, Test_accuracy: 58.18%, Test_loss: 0.674023\n",
      "batch size: 256, fold: 4| Epoch 4: Train_accuracy: 61.04%, Train_loss: 0.656633, Test_accuracy: 59.72%, Test_loss: 0.667687\n",
      "batch size: 256, fold: 4| Epoch 5: Train_accuracy: 63.47%, Train_loss: 0.644059, Test_accuracy: 59.36%, Test_loss: 0.663974\n",
      "batch size: 256, fold: 4| Epoch 6: Train_accuracy: 64.72%, Train_loss: 0.635939, Test_accuracy: 62.03%, Test_loss: 0.659832\n",
      "batch size: 256, fold: 4| Epoch 7: Train_accuracy: 65.98%, Train_loss: 0.627407, Test_accuracy: 58.83%, Test_loss: 0.674888\n",
      "batch size: 256, fold: 4| Epoch 8: Train_accuracy: 66.46%, Train_loss: 0.620986, Test_accuracy: 61.67%, Test_loss: 0.658669\n",
      "batch size: 256, fold: 4| Epoch 9: Train_accuracy: 67.96%, Train_loss: 0.611175, Test_accuracy: 62.74%, Test_loss: 0.649651\n",
      "batch size: 256, fold: 4| Epoch 10: Train_accuracy: 68.40%, Train_loss: 0.604220, Test_accuracy: 62.68%, Test_loss: 0.654312\n",
      "batch size: 256, fold: 4| Epoch 11: Train_accuracy: 69.19%, Train_loss: 0.599579, Test_accuracy: 63.33%, Test_loss: 0.650012\n",
      "batch size: 256, fold: 4| Epoch 12: Train_accuracy: 70.30%, Train_loss: 0.590224, Test_accuracy: 63.63%, Test_loss: 0.643051\n",
      "batch size: 256, fold: 4| Epoch 13: Train_accuracy: 72.32%, Train_loss: 0.579787, Test_accuracy: 62.09%, Test_loss: 0.655049\n",
      "batch size: 256, fold: 4| Epoch 14: Train_accuracy: 71.62%, Train_loss: 0.581846, Test_accuracy: 64.34%, Test_loss: 0.642407\n",
      "batch size: 256, fold: 4| Epoch 15: Train_accuracy: 72.40%, Train_loss: 0.574696, Test_accuracy: 64.69%, Test_loss: 0.641255\n",
      "batch size: 256, fold: 4| Epoch 16: Train_accuracy: 73.93%, Train_loss: 0.563294, Test_accuracy: 62.62%, Test_loss: 0.648786\n",
      "batch size: 256, fold: 4| Epoch 17: Train_accuracy: 73.81%, Train_loss: 0.561976, Test_accuracy: 64.40%, Test_loss: 0.637138\n",
      "batch size: 256, fold: 4| Epoch 18: Train_accuracy: 74.15%, Train_loss: 0.558258, Test_accuracy: 64.22%, Test_loss: 0.638301\n",
      "batch size: 256, fold: 4| Epoch 19: Train_accuracy: 75.29%, Train_loss: 0.552649, Test_accuracy: 65.58%, Test_loss: 0.636506\n",
      "batch size: 256, fold: 4| Epoch 20: Train_accuracy: 75.29%, Train_loss: 0.547100, Test_accuracy: 65.11%, Test_loss: 0.633626\n",
      "batch size: 256, fold: 4| Epoch 21: Train_accuracy: 76.05%, Train_loss: 0.540374, Test_accuracy: 64.81%, Test_loss: 0.644882\n",
      "batch size: 256, fold: 4| Epoch 22: Train_accuracy: 76.30%, Train_loss: 0.540163, Test_accuracy: 66.05%, Test_loss: 0.625106\n",
      "batch size: 256, fold: 4| Epoch 23: Train_accuracy: 76.82%, Train_loss: 0.536597, Test_accuracy: 66.17%, Test_loss: 0.623296\n",
      "batch size: 256, fold: 4| Epoch 24: Train_accuracy: 77.28%, Train_loss: 0.528928, Test_accuracy: 66.41%, Test_loss: 0.626428\n",
      "batch size: 256, fold: 4| Epoch 25: Train_accuracy: 76.48%, Train_loss: 0.533422, Test_accuracy: 66.05%, Test_loss: 0.632545\n",
      "batch size: 256, fold: 4| Epoch 26: Train_accuracy: 77.91%, Train_loss: 0.524863, Test_accuracy: 66.77%, Test_loss: 0.628157\n",
      "batch size: 256, fold: 4| Epoch 27: Train_accuracy: 79.31%, Train_loss: 0.517050, Test_accuracy: 66.29%, Test_loss: 0.634508\n",
      "batch size: 256, fold: 4| Epoch 28: Train_accuracy: 78.74%, Train_loss: 0.518585, Test_accuracy: 66.41%, Test_loss: 0.628238\n",
      "batch size: 256, fold: 4| Epoch 29: Train_accuracy: 78.85%, Train_loss: 0.517113, Test_accuracy: 66.23%, Test_loss: 0.624629\n",
      "batch size: 256, fold: 4| Epoch 30: Train_accuracy: 79.44%, Train_loss: 0.508554, Test_accuracy: 67.12%, Test_loss: 0.616995\n",
      "batch size: 256, fold: 4| Epoch 31: Train_accuracy: 80.05%, Train_loss: 0.506997, Test_accuracy: 67.77%, Test_loss: 0.613438\n",
      "batch size: 256, fold: 4| Epoch 32: Train_accuracy: 79.90%, Train_loss: 0.506257, Test_accuracy: 66.41%, Test_loss: 0.626384\n",
      "batch size: 256, fold: 4| Epoch 33: Train_accuracy: 80.55%, Train_loss: 0.502053, Test_accuracy: 68.48%, Test_loss: 0.612617\n",
      "batch size: 256, fold: 4| Epoch 34: Train_accuracy: 80.76%, Train_loss: 0.498641, Test_accuracy: 67.83%, Test_loss: 0.610137\n",
      "batch size: 256, fold: 4| Epoch 35: Train_accuracy: 80.88%, Train_loss: 0.497319, Test_accuracy: 66.65%, Test_loss: 0.618508\n",
      "batch size: 256, fold: 4| Epoch 36: Train_accuracy: 81.81%, Train_loss: 0.487082, Test_accuracy: 67.89%, Test_loss: 0.618028\n",
      "batch size: 256, fold: 4| Epoch 37: Train_accuracy: 81.32%, Train_loss: 0.490630, Test_accuracy: 67.12%, Test_loss: 0.618614\n",
      "batch size: 256, fold: 4| Epoch 38: Train_accuracy: 81.62%, Train_loss: 0.486952, Test_accuracy: 68.96%, Test_loss: 0.604585\n",
      "batch size: 256, fold: 4| Epoch 39: Train_accuracy: 82.36%, Train_loss: 0.487324, Test_accuracy: 69.14%, Test_loss: 0.602875\n",
      "batch size: 256, fold: 4| Epoch 40: Train_accuracy: 81.57%, Train_loss: 0.490021, Test_accuracy: 69.43%, Test_loss: 0.607856\n",
      "batch size: 256, fold: 4| Epoch 41: Train_accuracy: 82.57%, Train_loss: 0.481511, Test_accuracy: 68.60%, Test_loss: 0.609419\n",
      "batch size: 256, fold: 4| Epoch 42: Train_accuracy: 82.49%, Train_loss: 0.482827, Test_accuracy: 67.48%, Test_loss: 0.608078\n",
      "batch size: 256, fold: 4| Epoch 43: Train_accuracy: 82.88%, Train_loss: 0.476984, Test_accuracy: 68.42%, Test_loss: 0.611014\n",
      "batch size: 256, fold: 4| Epoch 44: Train_accuracy: 82.08%, Train_loss: 0.484674, Test_accuracy: 69.67%, Test_loss: 0.599605\n",
      "batch size: 256, fold: 4| Epoch 45: Train_accuracy: 83.25%, Train_loss: 0.475736, Test_accuracy: 67.83%, Test_loss: 0.617092\n",
      "batch size: 256, fold: 4| Epoch 46: Train_accuracy: 82.94%, Train_loss: 0.476540, Test_accuracy: 68.19%, Test_loss: 0.609320\n",
      "batch size: 256, fold: 4| Epoch 47: Train_accuracy: 82.79%, Train_loss: 0.477582, Test_accuracy: 70.79%, Test_loss: 0.594896\n",
      "batch size: 256, fold: 4| Epoch 48: Train_accuracy: 84.06%, Train_loss: 0.470864, Test_accuracy: 69.96%, Test_loss: 0.601169\n",
      "batch size: 256, fold: 4| Epoch 49: Train_accuracy: 83.69%, Train_loss: 0.467660, Test_accuracy: 68.90%, Test_loss: 0.608908\n",
      "batch size: 256, fold: 4| Epoch 50: Train_accuracy: 84.24%, Train_loss: 0.466608, Test_accuracy: 69.67%, Test_loss: 0.604070\n",
      "batch size: 256, fold: 4| Epoch 51: Train_accuracy: 83.94%, Train_loss: 0.467787, Test_accuracy: 69.19%, Test_loss: 0.598516\n",
      "batch size: 256, fold: 4| Epoch 52: Train_accuracy: 84.21%, Train_loss: 0.466861, Test_accuracy: 69.14%, Test_loss: 0.605187\n",
      "batch size: 256, fold: 4| Epoch 53: Train_accuracy: 84.57%, Train_loss: 0.461063, Test_accuracy: 70.56%, Test_loss: 0.591988\n",
      "batch size: 256, fold: 4| Epoch 54: Train_accuracy: 84.46%, Train_loss: 0.465356, Test_accuracy: 69.91%, Test_loss: 0.598664\n",
      "batch size: 256, fold: 4| Epoch 55: Train_accuracy: 85.14%, Train_loss: 0.458483, Test_accuracy: 69.02%, Test_loss: 0.609389\n",
      "batch size: 256, fold: 4| Epoch 56: Train_accuracy: 85.53%, Train_loss: 0.453760, Test_accuracy: 70.32%, Test_loss: 0.599837\n",
      "batch size: 256, fold: 4| Epoch 57: Train_accuracy: 84.61%, Train_loss: 0.461264, Test_accuracy: 70.20%, Test_loss: 0.599690\n",
      "batch size: 256, fold: 4| Epoch 58: Train_accuracy: 84.88%, Train_loss: 0.457248, Test_accuracy: 70.08%, Test_loss: 0.597550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 256, fold: 4| Epoch 59: Train_accuracy: 85.48%, Train_loss: 0.455093, Test_accuracy: 68.90%, Test_loss: 0.603625\n",
      "batch size: 256, fold: 4| Epoch 60: Train_accuracy: 85.05%, Train_loss: 0.457507, Test_accuracy: 69.67%, Test_loss: 0.597274\n",
      "batch size: 256, fold: 4| Epoch 61: Train_accuracy: 85.31%, Train_loss: 0.454769, Test_accuracy: 68.42%, Test_loss: 0.606512\n",
      "batch size: 256, fold: 4| Epoch 62: Train_accuracy: 85.54%, Train_loss: 0.454728, Test_accuracy: 70.38%, Test_loss: 0.598221\n",
      "batch size: 256, fold: 4| Epoch 63: Train_accuracy: 86.67%, Train_loss: 0.444305, Test_accuracy: 68.90%, Test_loss: 0.606744\n",
      "batch size: 256, fold: 4| Epoch 64: Train_accuracy: 85.85%, Train_loss: 0.447992, Test_accuracy: 70.26%, Test_loss: 0.595602\n",
      "batch size: 256, fold: 4| Epoch 65: Train_accuracy: 85.66%, Train_loss: 0.450467, Test_accuracy: 69.73%, Test_loss: 0.602786\n",
      "batch size: 256, fold: 4| Epoch 66: Train_accuracy: 86.12%, Train_loss: 0.447093, Test_accuracy: 69.79%, Test_loss: 0.597174\n",
      "batch size: 256, fold: 4| Epoch 67: Train_accuracy: 86.02%, Train_loss: 0.448869, Test_accuracy: 69.02%, Test_loss: 0.602254\n",
      "batch size: 256, fold: 4| Epoch 68: Train_accuracy: 85.68%, Train_loss: 0.452096, Test_accuracy: 69.73%, Test_loss: 0.608785\n",
      "batch size: 256, fold: 4| Epoch 69: Train_accuracy: 85.69%, Train_loss: 0.450423, Test_accuracy: 70.44%, Test_loss: 0.593268\n",
      "batch size: 256, fold: 4| Epoch 70: Train_accuracy: 86.91%, Train_loss: 0.439992, Test_accuracy: 69.25%, Test_loss: 0.600738\n",
      "batch size: 256, fold: 4| Epoch 71: Train_accuracy: 86.86%, Train_loss: 0.441006, Test_accuracy: 71.21%, Test_loss: 0.588357\n",
      "batch size: 256, fold: 4| Epoch 72: Train_accuracy: 86.37%, Train_loss: 0.448249, Test_accuracy: 70.20%, Test_loss: 0.598698\n",
      "batch size: 256, fold: 4| Epoch 73: Train_accuracy: 86.03%, Train_loss: 0.448914, Test_accuracy: 69.85%, Test_loss: 0.601996\n",
      "batch size: 256, fold: 4| Epoch 74: Train_accuracy: 86.99%, Train_loss: 0.438251, Test_accuracy: 68.19%, Test_loss: 0.606149\n",
      "batch size: 256, fold: 4| Epoch 75: Train_accuracy: 87.11%, Train_loss: 0.437830, Test_accuracy: 70.32%, Test_loss: 0.595580\n",
      "batch size: 256, fold: 4| Epoch 76: Train_accuracy: 87.25%, Train_loss: 0.436068, Test_accuracy: 70.79%, Test_loss: 0.592496\n",
      "batch size: 256, fold: 4| Epoch 77: Train_accuracy: 87.32%, Train_loss: 0.436862, Test_accuracy: 70.91%, Test_loss: 0.585038\n",
      "batch size: 256, fold: 4| Epoch 78: Train_accuracy: 88.03%, Train_loss: 0.432264, Test_accuracy: 68.13%, Test_loss: 0.613603\n",
      "batch size: 256, fold: 4| Epoch 79: Train_accuracy: 87.62%, Train_loss: 0.431456, Test_accuracy: 70.50%, Test_loss: 0.596658\n",
      "batch size: 256, fold: 4| Epoch 80: Train_accuracy: 86.94%, Train_loss: 0.439770, Test_accuracy: 69.55%, Test_loss: 0.598450\n",
      "batch size: 256, fold: 4| Epoch 81: Train_accuracy: 87.44%, Train_loss: 0.432700, Test_accuracy: 70.97%, Test_loss: 0.593322\n",
      "batch size: 256, fold: 4| Epoch 82: Train_accuracy: 87.36%, Train_loss: 0.434378, Test_accuracy: 70.02%, Test_loss: 0.597633\n",
      "batch size: 256, fold: 4| Epoch 83: Train_accuracy: 87.48%, Train_loss: 0.434565, Test_accuracy: 69.31%, Test_loss: 0.605703\n",
      "batch size: 256, fold: 4| Epoch 84: Train_accuracy: 87.66%, Train_loss: 0.429702, Test_accuracy: 70.50%, Test_loss: 0.596719\n",
      "batch size: 256, fold: 4| Epoch 85: Train_accuracy: 88.15%, Train_loss: 0.428265, Test_accuracy: 69.08%, Test_loss: 0.606861\n",
      "batch size: 256, fold: 4| Epoch 86: Train_accuracy: 88.46%, Train_loss: 0.425806, Test_accuracy: 70.79%, Test_loss: 0.583657\n",
      "batch size: 256, fold: 4| Epoch 87: Train_accuracy: 88.27%, Train_loss: 0.428240, Test_accuracy: 71.33%, Test_loss: 0.593518\n",
      "batch size: 256, fold: 4| Epoch 88: Train_accuracy: 87.84%, Train_loss: 0.432262, Test_accuracy: 69.73%, Test_loss: 0.600064\n",
      "batch size: 256, fold: 4| Epoch 89: Train_accuracy: 87.82%, Train_loss: 0.430082, Test_accuracy: 69.37%, Test_loss: 0.606507\n",
      "batch size: 256, fold: 4| Epoch 90: Train_accuracy: 88.33%, Train_loss: 0.427064, Test_accuracy: 70.56%, Test_loss: 0.599332\n",
      "batch size: 256, fold: 4| Epoch 91: Train_accuracy: 88.45%, Train_loss: 0.426205, Test_accuracy: 68.66%, Test_loss: 0.606022\n",
      "batch size: 256, fold: 4| Epoch 92: Train_accuracy: 87.71%, Train_loss: 0.434269, Test_accuracy: 69.37%, Test_loss: 0.604194\n",
      "batch size: 256, fold: 4| Epoch 93: Train_accuracy: 88.40%, Train_loss: 0.424329, Test_accuracy: 68.84%, Test_loss: 0.609698\n",
      "batch size: 256, fold: 4| Epoch 94: Train_accuracy: 88.24%, Train_loss: 0.425908, Test_accuracy: 69.49%, Test_loss: 0.603791\n",
      "batch size: 256, fold: 4| Epoch 95: Train_accuracy: 88.51%, Train_loss: 0.423480, Test_accuracy: 70.44%, Test_loss: 0.596824\n",
      "batch size: 256, fold: 4| Epoch 96: Train_accuracy: 89.33%, Train_loss: 0.417542, Test_accuracy: 68.72%, Test_loss: 0.600349\n",
      "batch size: 256, fold: 4| Epoch 97: Train_accuracy: 88.71%, Train_loss: 0.422648, Test_accuracy: 70.20%, Test_loss: 0.591652\n",
      "batch size: 256, fold: 4| Epoch 98: Train_accuracy: 88.62%, Train_loss: 0.424845, Test_accuracy: 69.67%, Test_loss: 0.599778\n",
      "batch size: 256, fold: 4| Epoch 99: Train_accuracy: 89.26%, Train_loss: 0.418798, Test_accuracy: 70.68%, Test_loss: 0.597195\n",
      "batch size: 256, fold: 4| Epoch 100: Train_accuracy: 88.95%, Train_loss: 0.421432, Test_accuracy: 69.37%, Test_loss: 0.605430\n",
      "batch size: 256, fold: 5| Epoch 1: Train_accuracy: 53.41%, Train_loss: 0.688873, Test_accuracy: 56.14%, Test_loss: 0.683354\n",
      "batch size: 256, fold: 5| Epoch 2: Train_accuracy: 57.79%, Train_loss: 0.677949, Test_accuracy: 56.14%, Test_loss: 0.675792\n",
      "batch size: 256, fold: 5| Epoch 3: Train_accuracy: 60.19%, Train_loss: 0.665294, Test_accuracy: 58.27%, Test_loss: 0.670876\n",
      "batch size: 256, fold: 5| Epoch 4: Train_accuracy: 61.92%, Train_loss: 0.656277, Test_accuracy: 58.80%, Test_loss: 0.665960\n",
      "batch size: 256, fold: 5| Epoch 5: Train_accuracy: 63.03%, Train_loss: 0.646724, Test_accuracy: 60.46%, Test_loss: 0.659482\n",
      "batch size: 256, fold: 5| Epoch 6: Train_accuracy: 64.69%, Train_loss: 0.637145, Test_accuracy: 59.69%, Test_loss: 0.659621\n",
      "batch size: 256, fold: 5| Epoch 7: Train_accuracy: 65.92%, Train_loss: 0.629022, Test_accuracy: 61.35%, Test_loss: 0.652219\n",
      "batch size: 256, fold: 5| Epoch 8: Train_accuracy: 65.57%, Train_loss: 0.628075, Test_accuracy: 62.24%, Test_loss: 0.652848\n",
      "batch size: 256, fold: 5| Epoch 9: Train_accuracy: 67.98%, Train_loss: 0.614418, Test_accuracy: 61.06%, Test_loss: 0.658595\n",
      "batch size: 256, fold: 5| Epoch 10: Train_accuracy: 68.02%, Train_loss: 0.608464, Test_accuracy: 62.24%, Test_loss: 0.648144\n",
      "batch size: 256, fold: 5| Epoch 11: Train_accuracy: 68.35%, Train_loss: 0.606210, Test_accuracy: 62.95%, Test_loss: 0.648464\n",
      "batch size: 256, fold: 5| Epoch 12: Train_accuracy: 70.19%, Train_loss: 0.597727, Test_accuracy: 64.02%, Test_loss: 0.634845\n",
      "batch size: 256, fold: 5| Epoch 13: Train_accuracy: 70.32%, Train_loss: 0.590834, Test_accuracy: 64.97%, Test_loss: 0.643138\n",
      "batch size: 256, fold: 5| Epoch 14: Train_accuracy: 71.55%, Train_loss: 0.581115, Test_accuracy: 63.31%, Test_loss: 0.641110\n",
      "batch size: 256, fold: 5| Epoch 15: Train_accuracy: 71.99%, Train_loss: 0.578942, Test_accuracy: 65.92%, Test_loss: 0.622265\n",
      "batch size: 256, fold: 5| Epoch 16: Train_accuracy: 72.91%, Train_loss: 0.569479, Test_accuracy: 65.09%, Test_loss: 0.635811\n",
      "batch size: 256, fold: 5| Epoch 17: Train_accuracy: 73.49%, Train_loss: 0.561711, Test_accuracy: 65.03%, Test_loss: 0.634179\n",
      "batch size: 256, fold: 5| Epoch 18: Train_accuracy: 74.51%, Train_loss: 0.557223, Test_accuracy: 65.15%, Test_loss: 0.631167\n",
      "batch size: 256, fold: 5| Epoch 19: Train_accuracy: 74.26%, Train_loss: 0.558297, Test_accuracy: 64.55%, Test_loss: 0.628594\n",
      "batch size: 256, fold: 5| Epoch 20: Train_accuracy: 74.99%, Train_loss: 0.550562, Test_accuracy: 66.45%, Test_loss: 0.623388\n",
      "batch size: 256, fold: 5| Epoch 21: Train_accuracy: 75.00%, Train_loss: 0.550603, Test_accuracy: 64.67%, Test_loss: 0.633249\n",
      "batch size: 256, fold: 5| Epoch 22: Train_accuracy: 75.87%, Train_loss: 0.543982, Test_accuracy: 65.92%, Test_loss: 0.620694\n",
      "batch size: 256, fold: 5| Epoch 23: Train_accuracy: 76.42%, Train_loss: 0.537008, Test_accuracy: 66.21%, Test_loss: 0.625973\n",
      "batch size: 256, fold: 5| Epoch 24: Train_accuracy: 77.00%, Train_loss: 0.533979, Test_accuracy: 66.63%, Test_loss: 0.621110\n",
      "batch size: 256, fold: 5| Epoch 25: Train_accuracy: 77.44%, Train_loss: 0.528736, Test_accuracy: 68.17%, Test_loss: 0.612912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 256, fold: 5| Epoch 26: Train_accuracy: 77.35%, Train_loss: 0.527356, Test_accuracy: 67.87%, Test_loss: 0.608456\n",
      "batch size: 256, fold: 5| Epoch 27: Train_accuracy: 77.70%, Train_loss: 0.529067, Test_accuracy: 65.74%, Test_loss: 0.629237\n",
      "batch size: 256, fold: 5| Epoch 28: Train_accuracy: 78.18%, Train_loss: 0.522715, Test_accuracy: 67.40%, Test_loss: 0.618799\n",
      "batch size: 256, fold: 5| Epoch 29: Train_accuracy: 78.58%, Train_loss: 0.519879, Test_accuracy: 67.93%, Test_loss: 0.612748\n",
      "batch size: 256, fold: 5| Epoch 30: Train_accuracy: 79.38%, Train_loss: 0.510577, Test_accuracy: 67.52%, Test_loss: 0.617333\n",
      "batch size: 256, fold: 5| Epoch 31: Train_accuracy: 79.40%, Train_loss: 0.511134, Test_accuracy: 67.40%, Test_loss: 0.612743\n",
      "batch size: 256, fold: 5| Epoch 32: Train_accuracy: 79.32%, Train_loss: 0.510762, Test_accuracy: 67.69%, Test_loss: 0.611876\n",
      "batch size: 256, fold: 5| Epoch 33: Train_accuracy: 80.12%, Train_loss: 0.505789, Test_accuracy: 69.12%, Test_loss: 0.603711\n",
      "batch size: 256, fold: 5| Epoch 34: Train_accuracy: 79.34%, Train_loss: 0.509273, Test_accuracy: 68.52%, Test_loss: 0.608024\n",
      "batch size: 256, fold: 5| Epoch 35: Train_accuracy: 80.21%, Train_loss: 0.504262, Test_accuracy: 68.82%, Test_loss: 0.603884\n",
      "batch size: 256, fold: 5| Epoch 36: Train_accuracy: 80.67%, Train_loss: 0.499520, Test_accuracy: 67.40%, Test_loss: 0.615968\n",
      "batch size: 256, fold: 5| Epoch 37: Train_accuracy: 80.98%, Train_loss: 0.495911, Test_accuracy: 67.34%, Test_loss: 0.615637\n",
      "batch size: 256, fold: 5| Epoch 38: Train_accuracy: 80.52%, Train_loss: 0.498676, Test_accuracy: 70.01%, Test_loss: 0.589308\n",
      "batch size: 256, fold: 5| Epoch 39: Train_accuracy: 81.53%, Train_loss: 0.490879, Test_accuracy: 67.93%, Test_loss: 0.608298\n",
      "batch size: 256, fold: 5| Epoch 40: Train_accuracy: 81.68%, Train_loss: 0.489303, Test_accuracy: 69.71%, Test_loss: 0.598594\n",
      "batch size: 256, fold: 5| Epoch 41: Train_accuracy: 81.62%, Train_loss: 0.491294, Test_accuracy: 69.59%, Test_loss: 0.598275\n",
      "batch size: 256, fold: 5| Epoch 42: Train_accuracy: 81.86%, Train_loss: 0.486759, Test_accuracy: 67.99%, Test_loss: 0.611399\n",
      "batch size: 256, fold: 5| Epoch 43: Train_accuracy: 81.64%, Train_loss: 0.490229, Test_accuracy: 69.83%, Test_loss: 0.598125\n",
      "batch size: 256, fold: 5| Epoch 44: Train_accuracy: 81.80%, Train_loss: 0.488559, Test_accuracy: 70.66%, Test_loss: 0.591356\n",
      "batch size: 256, fold: 5| Epoch 45: Train_accuracy: 82.11%, Train_loss: 0.483858, Test_accuracy: 68.70%, Test_loss: 0.605209\n",
      "batch size: 256, fold: 5| Epoch 46: Train_accuracy: 82.39%, Train_loss: 0.482888, Test_accuracy: 71.25%, Test_loss: 0.587983\n",
      "batch size: 256, fold: 5| Epoch 47: Train_accuracy: 82.61%, Train_loss: 0.481186, Test_accuracy: 69.65%, Test_loss: 0.595990\n",
      "batch size: 256, fold: 5| Epoch 48: Train_accuracy: 82.72%, Train_loss: 0.477441, Test_accuracy: 68.52%, Test_loss: 0.604762\n",
      "batch size: 256, fold: 5| Epoch 49: Train_accuracy: 83.68%, Train_loss: 0.471890, Test_accuracy: 68.82%, Test_loss: 0.604036\n",
      "batch size: 256, fold: 5| Epoch 50: Train_accuracy: 83.44%, Train_loss: 0.473969, Test_accuracy: 69.71%, Test_loss: 0.599586\n",
      "batch size: 256, fold: 5| Epoch 51: Train_accuracy: 83.71%, Train_loss: 0.469620, Test_accuracy: 68.35%, Test_loss: 0.608667\n",
      "batch size: 256, fold: 5| Epoch 52: Train_accuracy: 84.09%, Train_loss: 0.466957, Test_accuracy: 69.41%, Test_loss: 0.596118\n",
      "batch size: 256, fold: 5| Epoch 53: Train_accuracy: 84.27%, Train_loss: 0.466555, Test_accuracy: 71.49%, Test_loss: 0.586443\n",
      "batch size: 256, fold: 5| Epoch 54: Train_accuracy: 85.15%, Train_loss: 0.459919, Test_accuracy: 71.61%, Test_loss: 0.588059\n",
      "batch size: 256, fold: 5| Epoch 55: Train_accuracy: 84.06%, Train_loss: 0.468575, Test_accuracy: 70.66%, Test_loss: 0.586752\n",
      "batch size: 256, fold: 5| Epoch 56: Train_accuracy: 84.08%, Train_loss: 0.468285, Test_accuracy: 70.78%, Test_loss: 0.589943\n",
      "batch size: 256, fold: 5| Epoch 57: Train_accuracy: 84.08%, Train_loss: 0.466631, Test_accuracy: 69.12%, Test_loss: 0.598310\n",
      "batch size: 256, fold: 5| Epoch 58: Train_accuracy: 85.03%, Train_loss: 0.456695, Test_accuracy: 69.77%, Test_loss: 0.597096\n",
      "batch size: 256, fold: 5| Epoch 59: Train_accuracy: 84.40%, Train_loss: 0.461830, Test_accuracy: 69.83%, Test_loss: 0.592405\n",
      "batch size: 256, fold: 5| Epoch 60: Train_accuracy: 84.85%, Train_loss: 0.458393, Test_accuracy: 70.12%, Test_loss: 0.593162\n",
      "batch size: 256, fold: 5| Epoch 61: Train_accuracy: 85.29%, Train_loss: 0.455974, Test_accuracy: 69.89%, Test_loss: 0.597421\n",
      "batch size: 256, fold: 5| Epoch 62: Train_accuracy: 84.86%, Train_loss: 0.456424, Test_accuracy: 71.55%, Test_loss: 0.584781\n",
      "batch size: 256, fold: 5| Epoch 63: Train_accuracy: 85.35%, Train_loss: 0.451416, Test_accuracy: 69.59%, Test_loss: 0.590731\n",
      "batch size: 256, fold: 5| Epoch 64: Train_accuracy: 85.89%, Train_loss: 0.449682, Test_accuracy: 70.48%, Test_loss: 0.591204\n",
      "batch size: 256, fold: 5| Epoch 65: Train_accuracy: 85.60%, Train_loss: 0.451583, Test_accuracy: 70.12%, Test_loss: 0.596732\n",
      "batch size: 256, fold: 5| Epoch 66: Train_accuracy: 86.21%, Train_loss: 0.447523, Test_accuracy: 70.48%, Test_loss: 0.592051\n",
      "batch size: 256, fold: 5| Epoch 67: Train_accuracy: 85.90%, Train_loss: 0.448485, Test_accuracy: 72.08%, Test_loss: 0.578204\n",
      "batch size: 256, fold: 5| Epoch 68: Train_accuracy: 85.68%, Train_loss: 0.451758, Test_accuracy: 71.49%, Test_loss: 0.575737\n",
      "batch size: 256, fold: 5| Epoch 69: Train_accuracy: 85.89%, Train_loss: 0.448981, Test_accuracy: 72.32%, Test_loss: 0.574758\n",
      "batch size: 256, fold: 5| Epoch 70: Train_accuracy: 86.36%, Train_loss: 0.447212, Test_accuracy: 70.54%, Test_loss: 0.592583\n",
      "batch size: 256, fold: 5| Epoch 71: Train_accuracy: 86.77%, Train_loss: 0.441384, Test_accuracy: 70.72%, Test_loss: 0.583235\n",
      "batch size: 256, fold: 5| Epoch 72: Train_accuracy: 85.94%, Train_loss: 0.448567, Test_accuracy: 71.19%, Test_loss: 0.591278\n",
      "batch size: 256, fold: 5| Epoch 73: Train_accuracy: 86.34%, Train_loss: 0.445706, Test_accuracy: 71.67%, Test_loss: 0.583853\n",
      "batch size: 256, fold: 5| Epoch 74: Train_accuracy: 86.30%, Train_loss: 0.444628, Test_accuracy: 70.24%, Test_loss: 0.591954\n",
      "batch size: 256, fold: 5| Epoch 75: Train_accuracy: 86.88%, Train_loss: 0.440595, Test_accuracy: 71.67%, Test_loss: 0.577633\n",
      "batch size: 256, fold: 5| Epoch 76: Train_accuracy: 87.14%, Train_loss: 0.438230, Test_accuracy: 70.66%, Test_loss: 0.590697\n",
      "batch size: 256, fold: 5| Epoch 77: Train_accuracy: 87.22%, Train_loss: 0.436789, Test_accuracy: 71.25%, Test_loss: 0.587305\n",
      "batch size: 256, fold: 5| Epoch 78: Train_accuracy: 87.00%, Train_loss: 0.438185, Test_accuracy: 70.48%, Test_loss: 0.590591\n",
      "batch size: 256, fold: 5| Epoch 79: Train_accuracy: 87.50%, Train_loss: 0.435096, Test_accuracy: 70.18%, Test_loss: 0.595253\n",
      "batch size: 256, fold: 5| Epoch 80: Train_accuracy: 87.66%, Train_loss: 0.432522, Test_accuracy: 71.61%, Test_loss: 0.586017\n",
      "batch size: 256, fold: 5| Epoch 81: Train_accuracy: 87.16%, Train_loss: 0.436626, Test_accuracy: 69.77%, Test_loss: 0.600856\n",
      "batch size: 256, fold: 5| Epoch 82: Train_accuracy: 87.13%, Train_loss: 0.435311, Test_accuracy: 72.14%, Test_loss: 0.577824\n",
      "batch size: 256, fold: 5| Epoch 83: Train_accuracy: 87.69%, Train_loss: 0.431075, Test_accuracy: 73.80%, Test_loss: 0.565137\n",
      "batch size: 256, fold: 5| Epoch 84: Train_accuracy: 87.84%, Train_loss: 0.431316, Test_accuracy: 70.90%, Test_loss: 0.591640\n",
      "batch size: 256, fold: 5| Epoch 85: Train_accuracy: 88.06%, Train_loss: 0.431100, Test_accuracy: 71.13%, Test_loss: 0.581898\n",
      "batch size: 256, fold: 5| Epoch 86: Train_accuracy: 87.96%, Train_loss: 0.429880, Test_accuracy: 71.72%, Test_loss: 0.575456\n",
      "batch size: 256, fold: 5| Epoch 87: Train_accuracy: 88.15%, Train_loss: 0.426647, Test_accuracy: 70.60%, Test_loss: 0.589806\n",
      "batch size: 256, fold: 5| Epoch 88: Train_accuracy: 88.02%, Train_loss: 0.428066, Test_accuracy: 72.14%, Test_loss: 0.575467\n",
      "batch size: 256, fold: 5| Epoch 89: Train_accuracy: 88.30%, Train_loss: 0.428126, Test_accuracy: 71.37%, Test_loss: 0.586781\n",
      "batch size: 256, fold: 5| Epoch 90: Train_accuracy: 88.17%, Train_loss: 0.427272, Test_accuracy: 71.31%, Test_loss: 0.586069\n",
      "batch size: 256, fold: 5| Epoch 91: Train_accuracy: 88.26%, Train_loss: 0.425542, Test_accuracy: 71.19%, Test_loss: 0.587809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 256, fold: 5| Epoch 92: Train_accuracy: 88.28%, Train_loss: 0.426252, Test_accuracy: 71.49%, Test_loss: 0.582251\n",
      "batch size: 256, fold: 5| Epoch 93: Train_accuracy: 87.66%, Train_loss: 0.431663, Test_accuracy: 71.13%, Test_loss: 0.585203\n",
      "batch size: 256, fold: 5| Epoch 94: Train_accuracy: 88.94%, Train_loss: 0.422113, Test_accuracy: 71.72%, Test_loss: 0.579896\n",
      "batch size: 256, fold: 5| Epoch 95: Train_accuracy: 88.45%, Train_loss: 0.424433, Test_accuracy: 71.31%, Test_loss: 0.583474\n",
      "batch size: 256, fold: 5| Epoch 96: Train_accuracy: 88.24%, Train_loss: 0.426893, Test_accuracy: 72.61%, Test_loss: 0.575933\n",
      "batch size: 256, fold: 5| Epoch 97: Train_accuracy: 89.04%, Train_loss: 0.421331, Test_accuracy: 70.84%, Test_loss: 0.594138\n",
      "batch size: 256, fold: 5| Epoch 98: Train_accuracy: 88.64%, Train_loss: 0.422546, Test_accuracy: 71.72%, Test_loss: 0.581704\n",
      "batch size: 256, fold: 5| Epoch 99: Train_accuracy: 88.95%, Train_loss: 0.420290, Test_accuracy: 71.07%, Test_loss: 0.588741\n",
      "batch size: 256, fold: 5| Epoch 100: Train_accuracy: 88.74%, Train_loss: 0.421720, Test_accuracy: 72.91%, Test_loss: 0.570827\n",
      "batch size: 512, fold: 1| Epoch 1: Train_accuracy: 51.62%, Train_loss: 0.691200, Test_accuracy: 52.61%, Test_loss: 0.689560\n",
      "batch size: 512, fold: 1| Epoch 2: Train_accuracy: 55.43%, Train_loss: 0.686141, Test_accuracy: 57.82%, Test_loss: 0.682401\n",
      "batch size: 512, fold: 1| Epoch 3: Train_accuracy: 57.47%, Train_loss: 0.677038, Test_accuracy: 58.65%, Test_loss: 0.674879\n",
      "batch size: 512, fold: 1| Epoch 4: Train_accuracy: 58.57%, Train_loss: 0.670192, Test_accuracy: 61.20%, Test_loss: 0.660468\n",
      "batch size: 512, fold: 1| Epoch 5: Train_accuracy: 60.04%, Train_loss: 0.667383, Test_accuracy: 59.89%, Test_loss: 0.655992\n",
      "batch size: 512, fold: 1| Epoch 6: Train_accuracy: 61.62%, Train_loss: 0.655968, Test_accuracy: 60.72%, Test_loss: 0.656361\n",
      "batch size: 512, fold: 1| Epoch 7: Train_accuracy: 62.52%, Train_loss: 0.650597, Test_accuracy: 62.32%, Test_loss: 0.645906\n",
      "batch size: 512, fold: 1| Epoch 8: Train_accuracy: 63.24%, Train_loss: 0.646679, Test_accuracy: 63.09%, Test_loss: 0.647459\n",
      "batch size: 512, fold: 1| Epoch 9: Train_accuracy: 63.93%, Train_loss: 0.635976, Test_accuracy: 61.20%, Test_loss: 0.665566\n",
      "batch size: 512, fold: 1| Epoch 10: Train_accuracy: 65.44%, Train_loss: 0.630787, Test_accuracy: 63.03%, Test_loss: 0.652800\n",
      "batch size: 512, fold: 1| Epoch 11: Train_accuracy: 65.78%, Train_loss: 0.625086, Test_accuracy: 63.39%, Test_loss: 0.641418\n",
      "batch size: 512, fold: 1| Epoch 12: Train_accuracy: 67.16%, Train_loss: 0.613156, Test_accuracy: 65.11%, Test_loss: 0.635491\n",
      "batch size: 512, fold: 1| Epoch 13: Train_accuracy: 67.43%, Train_loss: 0.606380, Test_accuracy: 64.87%, Test_loss: 0.637903\n",
      "batch size: 512, fold: 1| Epoch 14: Train_accuracy: 68.92%, Train_loss: 0.603888, Test_accuracy: 62.44%, Test_loss: 0.653457\n",
      "batch size: 512, fold: 1| Epoch 15: Train_accuracy: 68.64%, Train_loss: 0.600635, Test_accuracy: 65.23%, Test_loss: 0.637169\n",
      "batch size: 512, fold: 1| Epoch 16: Train_accuracy: 69.25%, Train_loss: 0.596376, Test_accuracy: 65.58%, Test_loss: 0.623509\n",
      "batch size: 512, fold: 1| Epoch 17: Train_accuracy: 69.32%, Train_loss: 0.599310, Test_accuracy: 64.57%, Test_loss: 0.643229\n",
      "batch size: 512, fold: 1| Epoch 18: Train_accuracy: 71.06%, Train_loss: 0.586387, Test_accuracy: 64.22%, Test_loss: 0.636505\n",
      "batch size: 512, fold: 1| Epoch 19: Train_accuracy: 71.59%, Train_loss: 0.580227, Test_accuracy: 65.11%, Test_loss: 0.633249\n",
      "batch size: 512, fold: 1| Epoch 20: Train_accuracy: 72.08%, Train_loss: 0.572381, Test_accuracy: 65.28%, Test_loss: 0.639507\n",
      "batch size: 512, fold: 1| Epoch 21: Train_accuracy: 72.98%, Train_loss: 0.569099, Test_accuracy: 66.71%, Test_loss: 0.619412\n",
      "batch size: 512, fold: 1| Epoch 22: Train_accuracy: 73.96%, Train_loss: 0.559246, Test_accuracy: 67.59%, Test_loss: 0.620318\n",
      "batch size: 512, fold: 1| Epoch 23: Train_accuracy: 74.14%, Train_loss: 0.556649, Test_accuracy: 66.05%, Test_loss: 0.628528\n",
      "batch size: 512, fold: 1| Epoch 24: Train_accuracy: 74.88%, Train_loss: 0.553390, Test_accuracy: 66.17%, Test_loss: 0.628708\n",
      "batch size: 512, fold: 1| Epoch 25: Train_accuracy: 74.61%, Train_loss: 0.554817, Test_accuracy: 67.71%, Test_loss: 0.613743\n",
      "batch size: 512, fold: 1| Epoch 26: Train_accuracy: 74.98%, Train_loss: 0.550003, Test_accuracy: 66.23%, Test_loss: 0.624273\n",
      "batch size: 512, fold: 1| Epoch 27: Train_accuracy: 75.65%, Train_loss: 0.542987, Test_accuracy: 66.23%, Test_loss: 0.614686\n",
      "batch size: 512, fold: 1| Epoch 28: Train_accuracy: 76.02%, Train_loss: 0.544388, Test_accuracy: 67.24%, Test_loss: 0.606594\n",
      "batch size: 512, fold: 1| Epoch 29: Train_accuracy: 76.55%, Train_loss: 0.536705, Test_accuracy: 68.36%, Test_loss: 0.617083\n",
      "batch size: 512, fold: 1| Epoch 30: Train_accuracy: 76.91%, Train_loss: 0.533003, Test_accuracy: 66.53%, Test_loss: 0.626680\n",
      "batch size: 512, fold: 1| Epoch 31: Train_accuracy: 77.00%, Train_loss: 0.529910, Test_accuracy: 67.59%, Test_loss: 0.619158\n",
      "batch size: 512, fold: 1| Epoch 32: Train_accuracy: 77.48%, Train_loss: 0.525869, Test_accuracy: 66.11%, Test_loss: 0.613357\n",
      "batch size: 512, fold: 1| Epoch 33: Train_accuracy: 78.20%, Train_loss: 0.524054, Test_accuracy: 66.29%, Test_loss: 0.625250\n",
      "batch size: 512, fold: 1| Epoch 34: Train_accuracy: 78.12%, Train_loss: 0.522110, Test_accuracy: 68.07%, Test_loss: 0.604094\n",
      "batch size: 512, fold: 1| Epoch 35: Train_accuracy: 78.98%, Train_loss: 0.517118, Test_accuracy: 69.02%, Test_loss: 0.602077\n",
      "batch size: 512, fold: 1| Epoch 36: Train_accuracy: 79.59%, Train_loss: 0.511850, Test_accuracy: 68.48%, Test_loss: 0.607869\n",
      "batch size: 512, fold: 1| Epoch 37: Train_accuracy: 78.67%, Train_loss: 0.514241, Test_accuracy: 68.25%, Test_loss: 0.616819\n",
      "batch size: 512, fold: 1| Epoch 38: Train_accuracy: 79.40%, Train_loss: 0.509242, Test_accuracy: 67.42%, Test_loss: 0.607795\n",
      "batch size: 512, fold: 1| Epoch 39: Train_accuracy: 78.77%, Train_loss: 0.515982, Test_accuracy: 68.96%, Test_loss: 0.604962\n",
      "batch size: 512, fold: 1| Epoch 40: Train_accuracy: 80.15%, Train_loss: 0.507556, Test_accuracy: 67.06%, Test_loss: 0.619847\n",
      "batch size: 512, fold: 1| Epoch 41: Train_accuracy: 79.22%, Train_loss: 0.512246, Test_accuracy: 68.01%, Test_loss: 0.612288\n",
      "batch size: 512, fold: 1| Epoch 42: Train_accuracy: 80.25%, Train_loss: 0.505413, Test_accuracy: 69.37%, Test_loss: 0.599180\n",
      "batch size: 512, fold: 1| Epoch 43: Train_accuracy: 80.23%, Train_loss: 0.499715, Test_accuracy: 67.89%, Test_loss: 0.611846\n",
      "batch size: 512, fold: 1| Epoch 44: Train_accuracy: 80.30%, Train_loss: 0.505681, Test_accuracy: 68.13%, Test_loss: 0.606465\n",
      "batch size: 512, fold: 1| Epoch 45: Train_accuracy: 80.39%, Train_loss: 0.504433, Test_accuracy: 69.14%, Test_loss: 0.603666\n",
      "batch size: 512, fold: 1| Epoch 46: Train_accuracy: 80.70%, Train_loss: 0.496404, Test_accuracy: 68.36%, Test_loss: 0.601854\n",
      "batch size: 512, fold: 1| Epoch 47: Train_accuracy: 81.93%, Train_loss: 0.490216, Test_accuracy: 69.67%, Test_loss: 0.603510\n",
      "batch size: 512, fold: 1| Epoch 48: Train_accuracy: 81.34%, Train_loss: 0.488404, Test_accuracy: 69.61%, Test_loss: 0.600779\n",
      "batch size: 512, fold: 1| Epoch 49: Train_accuracy: 81.60%, Train_loss: 0.490917, Test_accuracy: 67.77%, Test_loss: 0.604002\n",
      "batch size: 512, fold: 1| Epoch 50: Train_accuracy: 82.08%, Train_loss: 0.485365, Test_accuracy: 68.01%, Test_loss: 0.611684\n",
      "batch size: 512, fold: 1| Epoch 51: Train_accuracy: 81.93%, Train_loss: 0.490810, Test_accuracy: 68.60%, Test_loss: 0.606620\n",
      "batch size: 512, fold: 1| Epoch 52: Train_accuracy: 82.64%, Train_loss: 0.481207, Test_accuracy: 69.79%, Test_loss: 0.595770\n",
      "batch size: 512, fold: 1| Epoch 53: Train_accuracy: 82.85%, Train_loss: 0.480203, Test_accuracy: 69.73%, Test_loss: 0.602785\n",
      "batch size: 512, fold: 1| Epoch 54: Train_accuracy: 82.58%, Train_loss: 0.482334, Test_accuracy: 70.44%, Test_loss: 0.583738\n",
      "batch size: 512, fold: 1| Epoch 55: Train_accuracy: 82.42%, Train_loss: 0.481015, Test_accuracy: 67.59%, Test_loss: 0.615712\n",
      "batch size: 512, fold: 1| Epoch 56: Train_accuracy: 82.45%, Train_loss: 0.481395, Test_accuracy: 69.96%, Test_loss: 0.593376\n",
      "batch size: 512, fold: 1| Epoch 57: Train_accuracy: 82.89%, Train_loss: 0.479729, Test_accuracy: 69.67%, Test_loss: 0.599306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 512, fold: 1| Epoch 58: Train_accuracy: 83.62%, Train_loss: 0.477419, Test_accuracy: 69.37%, Test_loss: 0.596159\n",
      "batch size: 512, fold: 1| Epoch 59: Train_accuracy: 83.47%, Train_loss: 0.474869, Test_accuracy: 67.77%, Test_loss: 0.594760\n",
      "batch size: 512, fold: 1| Epoch 60: Train_accuracy: 83.35%, Train_loss: 0.478115, Test_accuracy: 69.43%, Test_loss: 0.600109\n",
      "batch size: 512, fold: 1| Epoch 61: Train_accuracy: 83.57%, Train_loss: 0.469459, Test_accuracy: 69.85%, Test_loss: 0.583599\n",
      "batch size: 512, fold: 1| Epoch 62: Train_accuracy: 83.42%, Train_loss: 0.473122, Test_accuracy: 70.56%, Test_loss: 0.598058\n",
      "batch size: 512, fold: 1| Epoch 63: Train_accuracy: 84.09%, Train_loss: 0.468462, Test_accuracy: 70.97%, Test_loss: 0.584889\n",
      "batch size: 512, fold: 1| Epoch 64: Train_accuracy: 84.14%, Train_loss: 0.467379, Test_accuracy: 69.79%, Test_loss: 0.604777\n",
      "batch size: 512, fold: 1| Epoch 65: Train_accuracy: 84.22%, Train_loss: 0.466576, Test_accuracy: 69.55%, Test_loss: 0.592252\n",
      "batch size: 512, fold: 1| Epoch 66: Train_accuracy: 84.09%, Train_loss: 0.465771, Test_accuracy: 70.08%, Test_loss: 0.591545\n",
      "batch size: 512, fold: 1| Epoch 67: Train_accuracy: 83.44%, Train_loss: 0.469887, Test_accuracy: 70.91%, Test_loss: 0.586209\n",
      "batch size: 512, fold: 1| Epoch 68: Train_accuracy: 84.21%, Train_loss: 0.466882, Test_accuracy: 70.32%, Test_loss: 0.588741\n",
      "batch size: 512, fold: 1| Epoch 69: Train_accuracy: 84.49%, Train_loss: 0.464502, Test_accuracy: 70.32%, Test_loss: 0.593658\n",
      "batch size: 512, fold: 1| Epoch 70: Train_accuracy: 84.76%, Train_loss: 0.465297, Test_accuracy: 71.21%, Test_loss: 0.586978\n",
      "batch size: 512, fold: 1| Epoch 71: Train_accuracy: 84.40%, Train_loss: 0.468022, Test_accuracy: 70.02%, Test_loss: 0.598164\n",
      "batch size: 512, fold: 1| Epoch 72: Train_accuracy: 84.92%, Train_loss: 0.465658, Test_accuracy: 69.79%, Test_loss: 0.599056\n",
      "batch size: 512, fold: 1| Epoch 73: Train_accuracy: 84.92%, Train_loss: 0.458290, Test_accuracy: 70.79%, Test_loss: 0.593683\n",
      "batch size: 512, fold: 1| Epoch 74: Train_accuracy: 85.45%, Train_loss: 0.456403, Test_accuracy: 68.90%, Test_loss: 0.607877\n",
      "batch size: 512, fold: 1| Epoch 75: Train_accuracy: 84.91%, Train_loss: 0.459105, Test_accuracy: 69.91%, Test_loss: 0.603746\n",
      "batch size: 512, fold: 1| Epoch 76: Train_accuracy: 84.67%, Train_loss: 0.457869, Test_accuracy: 70.97%, Test_loss: 0.584007\n",
      "batch size: 512, fold: 1| Epoch 77: Train_accuracy: 85.07%, Train_loss: 0.456126, Test_accuracy: 70.62%, Test_loss: 0.582087\n",
      "batch size: 512, fold: 1| Epoch 78: Train_accuracy: 85.60%, Train_loss: 0.453488, Test_accuracy: 70.26%, Test_loss: 0.586749\n",
      "batch size: 512, fold: 1| Epoch 79: Train_accuracy: 86.30%, Train_loss: 0.447711, Test_accuracy: 70.85%, Test_loss: 0.589666\n",
      "batch size: 512, fold: 1| Epoch 80: Train_accuracy: 85.38%, Train_loss: 0.450185, Test_accuracy: 71.39%, Test_loss: 0.586538\n",
      "batch size: 512, fold: 1| Epoch 81: Train_accuracy: 85.79%, Train_loss: 0.449941, Test_accuracy: 71.27%, Test_loss: 0.593034\n",
      "batch size: 512, fold: 1| Epoch 82: Train_accuracy: 85.48%, Train_loss: 0.453165, Test_accuracy: 71.45%, Test_loss: 0.586810\n",
      "batch size: 512, fold: 1| Epoch 83: Train_accuracy: 86.19%, Train_loss: 0.444975, Test_accuracy: 71.56%, Test_loss: 0.585392\n",
      "batch size: 512, fold: 1| Epoch 84: Train_accuracy: 86.05%, Train_loss: 0.451264, Test_accuracy: 71.39%, Test_loss: 0.580568\n",
      "batch size: 512, fold: 1| Epoch 85: Train_accuracy: 86.31%, Train_loss: 0.445279, Test_accuracy: 70.02%, Test_loss: 0.596810\n",
      "batch size: 512, fold: 1| Epoch 86: Train_accuracy: 86.46%, Train_loss: 0.442115, Test_accuracy: 70.44%, Test_loss: 0.588742\n",
      "batch size: 512, fold: 1| Epoch 87: Train_accuracy: 86.19%, Train_loss: 0.447354, Test_accuracy: 72.33%, Test_loss: 0.582383\n",
      "batch size: 512, fold: 1| Epoch 88: Train_accuracy: 85.94%, Train_loss: 0.445001, Test_accuracy: 72.33%, Test_loss: 0.574485\n",
      "batch size: 512, fold: 1| Epoch 89: Train_accuracy: 86.58%, Train_loss: 0.445459, Test_accuracy: 71.27%, Test_loss: 0.606110\n",
      "batch size: 512, fold: 1| Epoch 90: Train_accuracy: 87.20%, Train_loss: 0.437287, Test_accuracy: 71.68%, Test_loss: 0.587674\n",
      "batch size: 512, fold: 1| Epoch 91: Train_accuracy: 86.71%, Train_loss: 0.444017, Test_accuracy: 70.73%, Test_loss: 0.587254\n",
      "batch size: 512, fold: 1| Epoch 92: Train_accuracy: 86.51%, Train_loss: 0.442663, Test_accuracy: 71.09%, Test_loss: 0.584988\n",
      "batch size: 512, fold: 1| Epoch 93: Train_accuracy: 86.46%, Train_loss: 0.443416, Test_accuracy: 71.74%, Test_loss: 0.578036\n",
      "batch size: 512, fold: 1| Epoch 94: Train_accuracy: 86.99%, Train_loss: 0.438450, Test_accuracy: 71.86%, Test_loss: 0.580788\n",
      "batch size: 512, fold: 1| Epoch 95: Train_accuracy: 86.80%, Train_loss: 0.440714, Test_accuracy: 71.15%, Test_loss: 0.586776\n",
      "batch size: 512, fold: 1| Epoch 96: Train_accuracy: 87.16%, Train_loss: 0.436238, Test_accuracy: 72.27%, Test_loss: 0.572027\n",
      "batch size: 512, fold: 1| Epoch 97: Train_accuracy: 87.10%, Train_loss: 0.437028, Test_accuracy: 70.91%, Test_loss: 0.599407\n",
      "batch size: 512, fold: 1| Epoch 98: Train_accuracy: 87.78%, Train_loss: 0.431698, Test_accuracy: 71.98%, Test_loss: 0.571716\n",
      "batch size: 512, fold: 1| Epoch 99: Train_accuracy: 87.72%, Train_loss: 0.432904, Test_accuracy: 70.26%, Test_loss: 0.581122\n",
      "batch size: 512, fold: 1| Epoch 100: Train_accuracy: 87.36%, Train_loss: 0.432680, Test_accuracy: 70.91%, Test_loss: 0.584356\n",
      "batch size: 512, fold: 2| Epoch 1: Train_accuracy: 51.41%, Train_loss: 0.691787, Test_accuracy: 52.25%, Test_loss: 0.690584\n",
      "batch size: 512, fold: 2| Epoch 2: Train_accuracy: 55.53%, Train_loss: 0.684421, Test_accuracy: 55.04%, Test_loss: 0.684184\n",
      "batch size: 512, fold: 2| Epoch 3: Train_accuracy: 57.65%, Train_loss: 0.677365, Test_accuracy: 57.58%, Test_loss: 0.679041\n",
      "batch size: 512, fold: 2| Epoch 4: Train_accuracy: 59.29%, Train_loss: 0.667719, Test_accuracy: 56.46%, Test_loss: 0.680190\n",
      "batch size: 512, fold: 2| Epoch 5: Train_accuracy: 60.58%, Train_loss: 0.661393, Test_accuracy: 58.71%, Test_loss: 0.671465\n",
      "batch size: 512, fold: 2| Epoch 6: Train_accuracy: 62.51%, Train_loss: 0.651486, Test_accuracy: 58.53%, Test_loss: 0.671966\n",
      "batch size: 512, fold: 2| Epoch 7: Train_accuracy: 62.64%, Train_loss: 0.644754, Test_accuracy: 59.12%, Test_loss: 0.671861\n",
      "batch size: 512, fold: 2| Epoch 8: Train_accuracy: 64.42%, Train_loss: 0.642101, Test_accuracy: 59.30%, Test_loss: 0.675336\n",
      "batch size: 512, fold: 2| Epoch 9: Train_accuracy: 65.31%, Train_loss: 0.634473, Test_accuracy: 59.24%, Test_loss: 0.682771\n",
      "batch size: 512, fold: 2| Epoch 10: Train_accuracy: 65.49%, Train_loss: 0.626460, Test_accuracy: 60.90%, Test_loss: 0.660431\n",
      "batch size: 512, fold: 2| Epoch 11: Train_accuracy: 66.45%, Train_loss: 0.623087, Test_accuracy: 61.32%, Test_loss: 0.658002\n",
      "batch size: 512, fold: 2| Epoch 12: Train_accuracy: 67.47%, Train_loss: 0.616743, Test_accuracy: 60.49%, Test_loss: 0.662388\n",
      "batch size: 512, fold: 2| Epoch 13: Train_accuracy: 67.58%, Train_loss: 0.616066, Test_accuracy: 63.15%, Test_loss: 0.651329\n",
      "batch size: 512, fold: 2| Epoch 14: Train_accuracy: 68.36%, Train_loss: 0.609764, Test_accuracy: 62.20%, Test_loss: 0.655123\n",
      "batch size: 512, fold: 2| Epoch 15: Train_accuracy: 68.79%, Train_loss: 0.610951, Test_accuracy: 63.27%, Test_loss: 0.638377\n",
      "batch size: 512, fold: 2| Epoch 16: Train_accuracy: 69.10%, Train_loss: 0.599962, Test_accuracy: 62.68%, Test_loss: 0.658038\n",
      "batch size: 512, fold: 2| Epoch 17: Train_accuracy: 69.10%, Train_loss: 0.598890, Test_accuracy: 62.03%, Test_loss: 0.657659\n",
      "batch size: 512, fold: 2| Epoch 18: Train_accuracy: 70.27%, Train_loss: 0.590203, Test_accuracy: 63.68%, Test_loss: 0.636522\n",
      "batch size: 512, fold: 2| Epoch 19: Train_accuracy: 72.12%, Train_loss: 0.577734, Test_accuracy: 64.51%, Test_loss: 0.633638\n",
      "batch size: 512, fold: 2| Epoch 20: Train_accuracy: 71.68%, Train_loss: 0.580216, Test_accuracy: 62.91%, Test_loss: 0.647597\n",
      "batch size: 512, fold: 2| Epoch 21: Train_accuracy: 72.86%, Train_loss: 0.572469, Test_accuracy: 64.69%, Test_loss: 0.645793\n",
      "batch size: 512, fold: 2| Epoch 22: Train_accuracy: 72.63%, Train_loss: 0.571416, Test_accuracy: 65.70%, Test_loss: 0.632837\n",
      "batch size: 512, fold: 2| Epoch 23: Train_accuracy: 73.37%, Train_loss: 0.567143, Test_accuracy: 63.68%, Test_loss: 0.632672\n",
      "batch size: 512, fold: 2| Epoch 24: Train_accuracy: 73.81%, Train_loss: 0.561835, Test_accuracy: 66.00%, Test_loss: 0.624419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 512, fold: 2| Epoch 25: Train_accuracy: 73.16%, Train_loss: 0.563357, Test_accuracy: 64.63%, Test_loss: 0.636561\n",
      "batch size: 512, fold: 2| Epoch 26: Train_accuracy: 73.81%, Train_loss: 0.556554, Test_accuracy: 66.82%, Test_loss: 0.624665\n",
      "batch size: 512, fold: 2| Epoch 27: Train_accuracy: 74.76%, Train_loss: 0.554212, Test_accuracy: 66.53%, Test_loss: 0.623699\n",
      "batch size: 512, fold: 2| Epoch 28: Train_accuracy: 75.06%, Train_loss: 0.553383, Test_accuracy: 66.41%, Test_loss: 0.629081\n",
      "batch size: 512, fold: 2| Epoch 29: Train_accuracy: 75.94%, Train_loss: 0.545013, Test_accuracy: 66.11%, Test_loss: 0.624774\n",
      "batch size: 512, fold: 2| Epoch 30: Train_accuracy: 75.80%, Train_loss: 0.543218, Test_accuracy: 66.47%, Test_loss: 0.625054\n",
      "batch size: 512, fold: 2| Epoch 31: Train_accuracy: 76.20%, Train_loss: 0.542849, Test_accuracy: 67.06%, Test_loss: 0.615045\n",
      "batch size: 512, fold: 2| Epoch 32: Train_accuracy: 74.88%, Train_loss: 0.546427, Test_accuracy: 65.05%, Test_loss: 0.635530\n",
      "batch size: 512, fold: 2| Epoch 33: Train_accuracy: 76.46%, Train_loss: 0.537264, Test_accuracy: 67.71%, Test_loss: 0.616455\n",
      "batch size: 512, fold: 2| Epoch 34: Train_accuracy: 77.26%, Train_loss: 0.533755, Test_accuracy: 66.82%, Test_loss: 0.618753\n",
      "batch size: 512, fold: 2| Epoch 35: Train_accuracy: 77.23%, Train_loss: 0.531523, Test_accuracy: 67.00%, Test_loss: 0.626367\n",
      "batch size: 512, fold: 2| Epoch 36: Train_accuracy: 76.95%, Train_loss: 0.533139, Test_accuracy: 67.12%, Test_loss: 0.618908\n",
      "batch size: 512, fold: 2| Epoch 37: Train_accuracy: 76.91%, Train_loss: 0.533308, Test_accuracy: 66.59%, Test_loss: 0.627747\n",
      "batch size: 512, fold: 2| Epoch 38: Train_accuracy: 77.22%, Train_loss: 0.527241, Test_accuracy: 68.36%, Test_loss: 0.604952\n",
      "batch size: 512, fold: 2| Epoch 39: Train_accuracy: 78.12%, Train_loss: 0.519187, Test_accuracy: 68.84%, Test_loss: 0.607418\n",
      "batch size: 512, fold: 2| Epoch 40: Train_accuracy: 78.06%, Train_loss: 0.520910, Test_accuracy: 68.19%, Test_loss: 0.605470\n",
      "batch size: 512, fold: 2| Epoch 41: Train_accuracy: 78.45%, Train_loss: 0.514666, Test_accuracy: 67.18%, Test_loss: 0.623697\n",
      "batch size: 512, fold: 2| Epoch 42: Train_accuracy: 78.79%, Train_loss: 0.512441, Test_accuracy: 68.78%, Test_loss: 0.608046\n",
      "batch size: 512, fold: 2| Epoch 43: Train_accuracy: 79.53%, Train_loss: 0.508938, Test_accuracy: 67.65%, Test_loss: 0.615480\n",
      "batch size: 512, fold: 2| Epoch 44: Train_accuracy: 79.31%, Train_loss: 0.511907, Test_accuracy: 70.79%, Test_loss: 0.588502\n",
      "batch size: 512, fold: 2| Epoch 45: Train_accuracy: 79.60%, Train_loss: 0.508965, Test_accuracy: 69.96%, Test_loss: 0.604064\n",
      "batch size: 512, fold: 2| Epoch 46: Train_accuracy: 79.96%, Train_loss: 0.507167, Test_accuracy: 68.54%, Test_loss: 0.608028\n",
      "batch size: 512, fold: 2| Epoch 47: Train_accuracy: 79.99%, Train_loss: 0.504957, Test_accuracy: 68.90%, Test_loss: 0.600598\n",
      "batch size: 512, fold: 2| Epoch 48: Train_accuracy: 80.23%, Train_loss: 0.504019, Test_accuracy: 68.36%, Test_loss: 0.601675\n",
      "batch size: 512, fold: 2| Epoch 49: Train_accuracy: 81.07%, Train_loss: 0.495603, Test_accuracy: 69.55%, Test_loss: 0.596739\n",
      "batch size: 512, fold: 2| Epoch 50: Train_accuracy: 80.05%, Train_loss: 0.505234, Test_accuracy: 69.79%, Test_loss: 0.596867\n",
      "batch size: 512, fold: 2| Epoch 51: Train_accuracy: 81.90%, Train_loss: 0.488876, Test_accuracy: 69.96%, Test_loss: 0.589129\n",
      "batch size: 512, fold: 2| Epoch 52: Train_accuracy: 81.29%, Train_loss: 0.495487, Test_accuracy: 69.85%, Test_loss: 0.600275\n",
      "batch size: 512, fold: 2| Epoch 53: Train_accuracy: 80.55%, Train_loss: 0.503307, Test_accuracy: 70.14%, Test_loss: 0.599192\n",
      "batch size: 512, fold: 2| Epoch 54: Train_accuracy: 81.13%, Train_loss: 0.494201, Test_accuracy: 69.25%, Test_loss: 0.600355\n",
      "batch size: 512, fold: 2| Epoch 55: Train_accuracy: 82.22%, Train_loss: 0.483510, Test_accuracy: 68.90%, Test_loss: 0.601900\n",
      "batch size: 512, fold: 2| Epoch 56: Train_accuracy: 81.66%, Train_loss: 0.488149, Test_accuracy: 68.66%, Test_loss: 0.599423\n",
      "batch size: 512, fold: 2| Epoch 57: Train_accuracy: 82.68%, Train_loss: 0.478796, Test_accuracy: 70.08%, Test_loss: 0.600975\n",
      "batch size: 512, fold: 2| Epoch 58: Train_accuracy: 81.96%, Train_loss: 0.483946, Test_accuracy: 69.19%, Test_loss: 0.598222\n",
      "batch size: 512, fold: 2| Epoch 59: Train_accuracy: 82.36%, Train_loss: 0.483997, Test_accuracy: 69.25%, Test_loss: 0.603830\n",
      "batch size: 512, fold: 2| Epoch 60: Train_accuracy: 82.80%, Train_loss: 0.480128, Test_accuracy: 69.73%, Test_loss: 0.581574\n",
      "batch size: 512, fold: 2| Epoch 61: Train_accuracy: 82.60%, Train_loss: 0.481497, Test_accuracy: 71.15%, Test_loss: 0.584125\n",
      "batch size: 512, fold: 2| Epoch 62: Train_accuracy: 82.91%, Train_loss: 0.478644, Test_accuracy: 69.02%, Test_loss: 0.598336\n",
      "batch size: 512, fold: 2| Epoch 63: Train_accuracy: 82.85%, Train_loss: 0.480002, Test_accuracy: 70.26%, Test_loss: 0.601808\n",
      "batch size: 512, fold: 2| Epoch 64: Train_accuracy: 83.25%, Train_loss: 0.472946, Test_accuracy: 71.50%, Test_loss: 0.582133\n",
      "batch size: 512, fold: 2| Epoch 65: Train_accuracy: 83.16%, Train_loss: 0.475757, Test_accuracy: 71.33%, Test_loss: 0.581498\n",
      "batch size: 512, fold: 2| Epoch 66: Train_accuracy: 84.02%, Train_loss: 0.471705, Test_accuracy: 69.91%, Test_loss: 0.596162\n",
      "batch size: 512, fold: 2| Epoch 67: Train_accuracy: 83.60%, Train_loss: 0.474269, Test_accuracy: 70.02%, Test_loss: 0.596990\n",
      "batch size: 512, fold: 2| Epoch 68: Train_accuracy: 83.96%, Train_loss: 0.471322, Test_accuracy: 69.67%, Test_loss: 0.592420\n",
      "batch size: 512, fold: 2| Epoch 69: Train_accuracy: 83.28%, Train_loss: 0.474572, Test_accuracy: 72.10%, Test_loss: 0.588913\n",
      "batch size: 512, fold: 2| Epoch 70: Train_accuracy: 83.44%, Train_loss: 0.475794, Test_accuracy: 69.49%, Test_loss: 0.597888\n",
      "batch size: 512, fold: 2| Epoch 71: Train_accuracy: 84.28%, Train_loss: 0.464779, Test_accuracy: 70.38%, Test_loss: 0.580720\n",
      "batch size: 512, fold: 2| Epoch 72: Train_accuracy: 84.39%, Train_loss: 0.466287, Test_accuracy: 70.73%, Test_loss: 0.591302\n",
      "batch size: 512, fold: 2| Epoch 73: Train_accuracy: 83.93%, Train_loss: 0.469961, Test_accuracy: 71.56%, Test_loss: 0.581766\n",
      "batch size: 512, fold: 2| Epoch 74: Train_accuracy: 84.34%, Train_loss: 0.463985, Test_accuracy: 70.73%, Test_loss: 0.595526\n",
      "batch size: 512, fold: 2| Epoch 75: Train_accuracy: 84.24%, Train_loss: 0.466587, Test_accuracy: 70.91%, Test_loss: 0.593509\n",
      "batch size: 512, fold: 2| Epoch 76: Train_accuracy: 84.17%, Train_loss: 0.466781, Test_accuracy: 70.73%, Test_loss: 0.596292\n",
      "batch size: 512, fold: 2| Epoch 77: Train_accuracy: 84.57%, Train_loss: 0.462383, Test_accuracy: 71.62%, Test_loss: 0.591579\n",
      "batch size: 512, fold: 2| Epoch 78: Train_accuracy: 85.02%, Train_loss: 0.457746, Test_accuracy: 70.73%, Test_loss: 0.591393\n",
      "batch size: 512, fold: 2| Epoch 79: Train_accuracy: 84.97%, Train_loss: 0.460676, Test_accuracy: 70.32%, Test_loss: 0.598246\n",
      "batch size: 512, fold: 2| Epoch 80: Train_accuracy: 84.40%, Train_loss: 0.461489, Test_accuracy: 71.03%, Test_loss: 0.589358\n",
      "batch size: 512, fold: 2| Epoch 81: Train_accuracy: 84.12%, Train_loss: 0.464111, Test_accuracy: 71.15%, Test_loss: 0.589320\n",
      "batch size: 512, fold: 2| Epoch 82: Train_accuracy: 85.01%, Train_loss: 0.454825, Test_accuracy: 71.86%, Test_loss: 0.580357\n",
      "batch size: 512, fold: 2| Epoch 83: Train_accuracy: 85.14%, Train_loss: 0.458150, Test_accuracy: 70.26%, Test_loss: 0.598706\n",
      "batch size: 512, fold: 2| Epoch 84: Train_accuracy: 85.39%, Train_loss: 0.457649, Test_accuracy: 70.56%, Test_loss: 0.578260\n",
      "batch size: 512, fold: 2| Epoch 85: Train_accuracy: 85.60%, Train_loss: 0.454546, Test_accuracy: 70.85%, Test_loss: 0.588203\n",
      "batch size: 512, fold: 2| Epoch 86: Train_accuracy: 85.37%, Train_loss: 0.451879, Test_accuracy: 71.45%, Test_loss: 0.583813\n",
      "batch size: 512, fold: 2| Epoch 87: Train_accuracy: 86.11%, Train_loss: 0.447870, Test_accuracy: 72.22%, Test_loss: 0.588814\n",
      "batch size: 512, fold: 2| Epoch 88: Train_accuracy: 85.47%, Train_loss: 0.453761, Test_accuracy: 72.39%, Test_loss: 0.570915\n",
      "batch size: 512, fold: 2| Epoch 89: Train_accuracy: 85.35%, Train_loss: 0.458260, Test_accuracy: 70.32%, Test_loss: 0.599098\n",
      "batch size: 512, fold: 2| Epoch 90: Train_accuracy: 85.94%, Train_loss: 0.450617, Test_accuracy: 71.21%, Test_loss: 0.578580\n",
      "batch size: 512, fold: 2| Epoch 91: Train_accuracy: 86.02%, Train_loss: 0.447080, Test_accuracy: 71.39%, Test_loss: 0.590931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 512, fold: 2| Epoch 92: Train_accuracy: 85.75%, Train_loss: 0.446233, Test_accuracy: 70.68%, Test_loss: 0.585579\n",
      "batch size: 512, fold: 2| Epoch 93: Train_accuracy: 85.96%, Train_loss: 0.444789, Test_accuracy: 71.98%, Test_loss: 0.573234\n",
      "batch size: 512, fold: 2| Epoch 94: Train_accuracy: 86.94%, Train_loss: 0.441337, Test_accuracy: 71.33%, Test_loss: 0.587217\n",
      "batch size: 512, fold: 2| Epoch 95: Train_accuracy: 86.48%, Train_loss: 0.449672, Test_accuracy: 70.73%, Test_loss: 0.585524\n",
      "batch size: 512, fold: 2| Epoch 96: Train_accuracy: 86.12%, Train_loss: 0.446777, Test_accuracy: 70.56%, Test_loss: 0.584944\n",
      "batch size: 512, fold: 2| Epoch 97: Train_accuracy: 86.61%, Train_loss: 0.443067, Test_accuracy: 71.21%, Test_loss: 0.589365\n",
      "batch size: 512, fold: 2| Epoch 98: Train_accuracy: 86.24%, Train_loss: 0.448022, Test_accuracy: 71.15%, Test_loss: 0.594761\n",
      "batch size: 512, fold: 2| Epoch 99: Train_accuracy: 86.55%, Train_loss: 0.442213, Test_accuracy: 71.33%, Test_loss: 0.592103\n",
      "batch size: 512, fold: 2| Epoch 100: Train_accuracy: 87.53%, Train_loss: 0.439143, Test_accuracy: 71.98%, Test_loss: 0.581468\n",
      "batch size: 512, fold: 3| Epoch 1: Train_accuracy: 52.18%, Train_loss: 0.691562, Test_accuracy: 52.90%, Test_loss: 0.690109\n",
      "batch size: 512, fold: 3| Epoch 2: Train_accuracy: 54.87%, Train_loss: 0.686407, Test_accuracy: 55.39%, Test_loss: 0.682155\n",
      "batch size: 512, fold: 3| Epoch 3: Train_accuracy: 57.50%, Train_loss: 0.677935, Test_accuracy: 55.57%, Test_loss: 0.682265\n",
      "batch size: 512, fold: 3| Epoch 4: Train_accuracy: 58.85%, Train_loss: 0.671197, Test_accuracy: 58.95%, Test_loss: 0.682981\n",
      "batch size: 512, fold: 3| Epoch 5: Train_accuracy: 60.38%, Train_loss: 0.665769, Test_accuracy: 58.35%, Test_loss: 0.668062\n",
      "batch size: 512, fold: 3| Epoch 6: Train_accuracy: 61.83%, Train_loss: 0.654882, Test_accuracy: 58.06%, Test_loss: 0.675348\n",
      "batch size: 512, fold: 3| Epoch 7: Train_accuracy: 63.26%, Train_loss: 0.646954, Test_accuracy: 59.48%, Test_loss: 0.667067\n",
      "batch size: 512, fold: 3| Epoch 8: Train_accuracy: 64.12%, Train_loss: 0.635195, Test_accuracy: 58.47%, Test_loss: 0.661911\n",
      "batch size: 512, fold: 3| Epoch 9: Train_accuracy: 64.69%, Train_loss: 0.635988, Test_accuracy: 61.20%, Test_loss: 0.659131\n",
      "batch size: 512, fold: 3| Epoch 10: Train_accuracy: 65.65%, Train_loss: 0.624650, Test_accuracy: 60.01%, Test_loss: 0.667100\n",
      "batch size: 512, fold: 3| Epoch 11: Train_accuracy: 66.43%, Train_loss: 0.622395, Test_accuracy: 62.09%, Test_loss: 0.656369\n",
      "batch size: 512, fold: 3| Epoch 12: Train_accuracy: 67.20%, Train_loss: 0.616698, Test_accuracy: 60.96%, Test_loss: 0.654672\n",
      "batch size: 512, fold: 3| Epoch 13: Train_accuracy: 68.61%, Train_loss: 0.605362, Test_accuracy: 63.80%, Test_loss: 0.649707\n",
      "batch size: 512, fold: 3| Epoch 14: Train_accuracy: 69.53%, Train_loss: 0.598145, Test_accuracy: 61.61%, Test_loss: 0.647106\n",
      "batch size: 512, fold: 3| Epoch 15: Train_accuracy: 70.00%, Train_loss: 0.594027, Test_accuracy: 64.93%, Test_loss: 0.641439\n",
      "batch size: 512, fold: 3| Epoch 16: Train_accuracy: 69.52%, Train_loss: 0.597202, Test_accuracy: 65.23%, Test_loss: 0.631358\n",
      "batch size: 512, fold: 3| Epoch 17: Train_accuracy: 70.88%, Train_loss: 0.589904, Test_accuracy: 61.97%, Test_loss: 0.645631\n",
      "batch size: 512, fold: 3| Epoch 18: Train_accuracy: 71.26%, Train_loss: 0.586506, Test_accuracy: 63.86%, Test_loss: 0.644974\n",
      "batch size: 512, fold: 3| Epoch 19: Train_accuracy: 71.89%, Train_loss: 0.577607, Test_accuracy: 64.40%, Test_loss: 0.635087\n",
      "batch size: 512, fold: 3| Epoch 20: Train_accuracy: 72.54%, Train_loss: 0.568727, Test_accuracy: 63.63%, Test_loss: 0.644735\n",
      "batch size: 512, fold: 3| Epoch 21: Train_accuracy: 73.35%, Train_loss: 0.563744, Test_accuracy: 64.81%, Test_loss: 0.628783\n",
      "batch size: 512, fold: 3| Epoch 22: Train_accuracy: 73.72%, Train_loss: 0.560223, Test_accuracy: 65.76%, Test_loss: 0.631773\n",
      "batch size: 512, fold: 3| Epoch 23: Train_accuracy: 74.31%, Train_loss: 0.559831, Test_accuracy: 64.93%, Test_loss: 0.639770\n",
      "batch size: 512, fold: 3| Epoch 24: Train_accuracy: 74.55%, Train_loss: 0.555992, Test_accuracy: 66.23%, Test_loss: 0.628525\n",
      "batch size: 512, fold: 3| Epoch 25: Train_accuracy: 74.82%, Train_loss: 0.554380, Test_accuracy: 65.58%, Test_loss: 0.625571\n",
      "batch size: 512, fold: 3| Epoch 26: Train_accuracy: 75.14%, Train_loss: 0.543495, Test_accuracy: 65.76%, Test_loss: 0.629419\n",
      "batch size: 512, fold: 3| Epoch 27: Train_accuracy: 75.51%, Train_loss: 0.543077, Test_accuracy: 65.40%, Test_loss: 0.617854\n",
      "batch size: 512, fold: 3| Epoch 28: Train_accuracy: 75.56%, Train_loss: 0.543369, Test_accuracy: 68.01%, Test_loss: 0.623714\n",
      "batch size: 512, fold: 3| Epoch 29: Train_accuracy: 75.96%, Train_loss: 0.539239, Test_accuracy: 65.52%, Test_loss: 0.617723\n",
      "batch size: 512, fold: 3| Epoch 30: Train_accuracy: 76.15%, Train_loss: 0.540969, Test_accuracy: 66.77%, Test_loss: 0.622193\n",
      "batch size: 512, fold: 3| Epoch 31: Train_accuracy: 76.45%, Train_loss: 0.536669, Test_accuracy: 65.46%, Test_loss: 0.635223\n",
      "batch size: 512, fold: 3| Epoch 32: Train_accuracy: 77.28%, Train_loss: 0.528453, Test_accuracy: 66.82%, Test_loss: 0.622017\n",
      "batch size: 512, fold: 3| Epoch 33: Train_accuracy: 77.13%, Train_loss: 0.531246, Test_accuracy: 67.54%, Test_loss: 0.619723\n",
      "batch size: 512, fold: 3| Epoch 34: Train_accuracy: 77.66%, Train_loss: 0.524785, Test_accuracy: 67.00%, Test_loss: 0.619091\n",
      "batch size: 512, fold: 3| Epoch 35: Train_accuracy: 78.20%, Train_loss: 0.523389, Test_accuracy: 66.94%, Test_loss: 0.623745\n",
      "batch size: 512, fold: 3| Epoch 36: Train_accuracy: 77.53%, Train_loss: 0.527018, Test_accuracy: 68.42%, Test_loss: 0.606883\n",
      "batch size: 512, fold: 3| Epoch 37: Train_accuracy: 77.94%, Train_loss: 0.519005, Test_accuracy: 68.13%, Test_loss: 0.619562\n",
      "batch size: 512, fold: 3| Epoch 38: Train_accuracy: 79.50%, Train_loss: 0.512353, Test_accuracy: 68.19%, Test_loss: 0.611721\n",
      "batch size: 512, fold: 3| Epoch 39: Train_accuracy: 79.56%, Train_loss: 0.510804, Test_accuracy: 67.95%, Test_loss: 0.610835\n",
      "batch size: 512, fold: 3| Epoch 40: Train_accuracy: 79.23%, Train_loss: 0.508287, Test_accuracy: 66.65%, Test_loss: 0.628576\n",
      "batch size: 512, fold: 3| Epoch 41: Train_accuracy: 78.92%, Train_loss: 0.514180, Test_accuracy: 68.25%, Test_loss: 0.608728\n",
      "batch size: 512, fold: 3| Epoch 42: Train_accuracy: 79.78%, Train_loss: 0.505463, Test_accuracy: 68.84%, Test_loss: 0.606843\n",
      "batch size: 512, fold: 3| Epoch 43: Train_accuracy: 79.84%, Train_loss: 0.504288, Test_accuracy: 69.14%, Test_loss: 0.609833\n",
      "batch size: 512, fold: 3| Epoch 44: Train_accuracy: 79.87%, Train_loss: 0.502492, Test_accuracy: 67.54%, Test_loss: 0.614676\n",
      "batch size: 512, fold: 3| Epoch 45: Train_accuracy: 80.54%, Train_loss: 0.500898, Test_accuracy: 69.19%, Test_loss: 0.596478\n",
      "batch size: 512, fold: 3| Epoch 46: Train_accuracy: 80.73%, Train_loss: 0.496214, Test_accuracy: 68.36%, Test_loss: 0.600388\n",
      "batch size: 512, fold: 3| Epoch 47: Train_accuracy: 81.74%, Train_loss: 0.495405, Test_accuracy: 70.02%, Test_loss: 0.594797\n",
      "batch size: 512, fold: 3| Epoch 48: Train_accuracy: 81.29%, Train_loss: 0.495270, Test_accuracy: 68.66%, Test_loss: 0.618412\n",
      "batch size: 512, fold: 3| Epoch 49: Train_accuracy: 81.54%, Train_loss: 0.491187, Test_accuracy: 67.77%, Test_loss: 0.605707\n",
      "batch size: 512, fold: 3| Epoch 50: Train_accuracy: 81.14%, Train_loss: 0.497064, Test_accuracy: 68.60%, Test_loss: 0.610285\n",
      "batch size: 512, fold: 3| Epoch 51: Train_accuracy: 82.14%, Train_loss: 0.490643, Test_accuracy: 68.42%, Test_loss: 0.603661\n",
      "batch size: 512, fold: 3| Epoch 52: Train_accuracy: 81.84%, Train_loss: 0.487842, Test_accuracy: 68.66%, Test_loss: 0.610530\n",
      "batch size: 512, fold: 3| Epoch 53: Train_accuracy: 82.51%, Train_loss: 0.483887, Test_accuracy: 67.48%, Test_loss: 0.615301\n",
      "batch size: 512, fold: 3| Epoch 54: Train_accuracy: 82.45%, Train_loss: 0.485399, Test_accuracy: 68.60%, Test_loss: 0.599054\n",
      "batch size: 512, fold: 3| Epoch 55: Train_accuracy: 82.58%, Train_loss: 0.482449, Test_accuracy: 70.02%, Test_loss: 0.593496\n",
      "batch size: 512, fold: 3| Epoch 56: Train_accuracy: 82.34%, Train_loss: 0.480803, Test_accuracy: 67.48%, Test_loss: 0.621343\n",
      "batch size: 512, fold: 3| Epoch 57: Train_accuracy: 82.97%, Train_loss: 0.476768, Test_accuracy: 70.02%, Test_loss: 0.598255\n",
      "batch size: 512, fold: 3| Epoch 58: Train_accuracy: 83.37%, Train_loss: 0.473473, Test_accuracy: 70.85%, Test_loss: 0.591944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 512, fold: 3| Epoch 59: Train_accuracy: 83.14%, Train_loss: 0.478079, Test_accuracy: 69.55%, Test_loss: 0.606548\n",
      "batch size: 512, fold: 3| Epoch 60: Train_accuracy: 83.08%, Train_loss: 0.475657, Test_accuracy: 71.50%, Test_loss: 0.590791\n",
      "batch size: 512, fold: 3| Epoch 61: Train_accuracy: 82.83%, Train_loss: 0.478618, Test_accuracy: 68.48%, Test_loss: 0.609621\n",
      "batch size: 512, fold: 3| Epoch 62: Train_accuracy: 82.97%, Train_loss: 0.474999, Test_accuracy: 70.14%, Test_loss: 0.601606\n",
      "batch size: 512, fold: 3| Epoch 63: Train_accuracy: 84.15%, Train_loss: 0.467341, Test_accuracy: 71.15%, Test_loss: 0.586476\n",
      "batch size: 512, fold: 3| Epoch 64: Train_accuracy: 83.41%, Train_loss: 0.474727, Test_accuracy: 70.85%, Test_loss: 0.600490\n",
      "batch size: 512, fold: 3| Epoch 65: Train_accuracy: 83.72%, Train_loss: 0.469432, Test_accuracy: 70.50%, Test_loss: 0.590755\n",
      "batch size: 512, fold: 3| Epoch 66: Train_accuracy: 84.77%, Train_loss: 0.464214, Test_accuracy: 70.20%, Test_loss: 0.596467\n",
      "batch size: 512, fold: 3| Epoch 67: Train_accuracy: 84.62%, Train_loss: 0.460230, Test_accuracy: 69.91%, Test_loss: 0.592245\n",
      "batch size: 512, fold: 3| Epoch 68: Train_accuracy: 85.11%, Train_loss: 0.460196, Test_accuracy: 69.08%, Test_loss: 0.600087\n",
      "batch size: 512, fold: 3| Epoch 69: Train_accuracy: 84.36%, Train_loss: 0.464336, Test_accuracy: 68.72%, Test_loss: 0.609474\n",
      "batch size: 512, fold: 3| Epoch 70: Train_accuracy: 84.83%, Train_loss: 0.460081, Test_accuracy: 68.84%, Test_loss: 0.599394\n",
      "batch size: 512, fold: 3| Epoch 71: Train_accuracy: 84.97%, Train_loss: 0.460802, Test_accuracy: 69.91%, Test_loss: 0.597751\n",
      "batch size: 512, fold: 3| Epoch 72: Train_accuracy: 85.19%, Train_loss: 0.463865, Test_accuracy: 68.78%, Test_loss: 0.615869\n",
      "batch size: 512, fold: 3| Epoch 73: Train_accuracy: 85.38%, Train_loss: 0.456464, Test_accuracy: 69.73%, Test_loss: 0.598871\n",
      "batch size: 512, fold: 3| Epoch 74: Train_accuracy: 85.14%, Train_loss: 0.457811, Test_accuracy: 70.02%, Test_loss: 0.594843\n",
      "batch size: 512, fold: 3| Epoch 75: Train_accuracy: 85.71%, Train_loss: 0.457303, Test_accuracy: 69.55%, Test_loss: 0.604151\n",
      "batch size: 512, fold: 3| Epoch 76: Train_accuracy: 84.49%, Train_loss: 0.460261, Test_accuracy: 69.67%, Test_loss: 0.597519\n",
      "batch size: 512, fold: 3| Epoch 77: Train_accuracy: 85.07%, Train_loss: 0.456534, Test_accuracy: 69.67%, Test_loss: 0.593453\n",
      "batch size: 512, fold: 3| Epoch 78: Train_accuracy: 85.84%, Train_loss: 0.450193, Test_accuracy: 69.96%, Test_loss: 0.588236\n",
      "batch size: 512, fold: 3| Epoch 79: Train_accuracy: 85.38%, Train_loss: 0.453723, Test_accuracy: 71.62%, Test_loss: 0.572892\n",
      "batch size: 512, fold: 3| Epoch 80: Train_accuracy: 85.65%, Train_loss: 0.451490, Test_accuracy: 70.56%, Test_loss: 0.590802\n",
      "batch size: 512, fold: 3| Epoch 81: Train_accuracy: 85.56%, Train_loss: 0.453602, Test_accuracy: 69.67%, Test_loss: 0.598599\n",
      "batch size: 512, fold: 3| Epoch 82: Train_accuracy: 85.54%, Train_loss: 0.453869, Test_accuracy: 70.44%, Test_loss: 0.590448\n",
      "batch size: 512, fold: 3| Epoch 83: Train_accuracy: 86.73%, Train_loss: 0.441292, Test_accuracy: 70.38%, Test_loss: 0.607491\n",
      "batch size: 512, fold: 3| Epoch 84: Train_accuracy: 85.94%, Train_loss: 0.448128, Test_accuracy: 71.09%, Test_loss: 0.582212\n",
      "batch size: 512, fold: 3| Epoch 85: Train_accuracy: 86.40%, Train_loss: 0.444733, Test_accuracy: 70.38%, Test_loss: 0.591765\n",
      "batch size: 512, fold: 3| Epoch 86: Train_accuracy: 87.05%, Train_loss: 0.438740, Test_accuracy: 71.21%, Test_loss: 0.597571\n",
      "batch size: 512, fold: 3| Epoch 87: Train_accuracy: 86.61%, Train_loss: 0.444321, Test_accuracy: 71.15%, Test_loss: 0.588352\n",
      "batch size: 512, fold: 3| Epoch 88: Train_accuracy: 86.79%, Train_loss: 0.439360, Test_accuracy: 71.27%, Test_loss: 0.584975\n",
      "batch size: 512, fold: 3| Epoch 89: Train_accuracy: 86.55%, Train_loss: 0.444840, Test_accuracy: 71.21%, Test_loss: 0.585933\n",
      "batch size: 512, fold: 3| Epoch 90: Train_accuracy: 86.95%, Train_loss: 0.438599, Test_accuracy: 70.62%, Test_loss: 0.587930\n",
      "batch size: 512, fold: 3| Epoch 91: Train_accuracy: 86.56%, Train_loss: 0.443851, Test_accuracy: 70.50%, Test_loss: 0.593308\n",
      "batch size: 512, fold: 3| Epoch 92: Train_accuracy: 85.81%, Train_loss: 0.448026, Test_accuracy: 72.45%, Test_loss: 0.585328\n",
      "batch size: 512, fold: 3| Epoch 93: Train_accuracy: 86.19%, Train_loss: 0.446713, Test_accuracy: 71.62%, Test_loss: 0.587986\n",
      "batch size: 512, fold: 3| Epoch 94: Train_accuracy: 86.62%, Train_loss: 0.443313, Test_accuracy: 70.62%, Test_loss: 0.589606\n",
      "batch size: 512, fold: 3| Epoch 95: Train_accuracy: 87.05%, Train_loss: 0.436513, Test_accuracy: 70.20%, Test_loss: 0.603050\n",
      "batch size: 512, fold: 3| Epoch 96: Train_accuracy: 86.95%, Train_loss: 0.441219, Test_accuracy: 70.79%, Test_loss: 0.596191\n",
      "batch size: 512, fold: 3| Epoch 97: Train_accuracy: 87.22%, Train_loss: 0.433608, Test_accuracy: 70.62%, Test_loss: 0.593516\n",
      "batch size: 512, fold: 3| Epoch 98: Train_accuracy: 87.60%, Train_loss: 0.434099, Test_accuracy: 70.73%, Test_loss: 0.583801\n",
      "batch size: 512, fold: 3| Epoch 99: Train_accuracy: 87.35%, Train_loss: 0.434942, Test_accuracy: 71.21%, Test_loss: 0.583323\n",
      "batch size: 512, fold: 3| Epoch 100: Train_accuracy: 88.05%, Train_loss: 0.428540, Test_accuracy: 71.92%, Test_loss: 0.574660\n",
      "batch size: 512, fold: 4| Epoch 1: Train_accuracy: 51.53%, Train_loss: 0.691383, Test_accuracy: 53.67%, Test_loss: 0.686670\n",
      "batch size: 512, fold: 4| Epoch 2: Train_accuracy: 56.66%, Train_loss: 0.683875, Test_accuracy: 56.58%, Test_loss: 0.682545\n",
      "batch size: 512, fold: 4| Epoch 3: Train_accuracy: 57.43%, Train_loss: 0.675400, Test_accuracy: 56.99%, Test_loss: 0.682386\n",
      "batch size: 512, fold: 4| Epoch 4: Train_accuracy: 58.57%, Train_loss: 0.668412, Test_accuracy: 57.46%, Test_loss: 0.675173\n",
      "batch size: 512, fold: 4| Epoch 5: Train_accuracy: 61.15%, Train_loss: 0.660719, Test_accuracy: 59.83%, Test_loss: 0.668791\n",
      "batch size: 512, fold: 4| Epoch 6: Train_accuracy: 62.32%, Train_loss: 0.652080, Test_accuracy: 59.48%, Test_loss: 0.670991\n",
      "batch size: 512, fold: 4| Epoch 7: Train_accuracy: 63.10%, Train_loss: 0.644626, Test_accuracy: 60.01%, Test_loss: 0.665161\n",
      "batch size: 512, fold: 4| Epoch 8: Train_accuracy: 63.90%, Train_loss: 0.638391, Test_accuracy: 60.72%, Test_loss: 0.666911\n",
      "batch size: 512, fold: 4| Epoch 9: Train_accuracy: 63.69%, Train_loss: 0.637071, Test_accuracy: 60.84%, Test_loss: 0.661684\n",
      "batch size: 512, fold: 4| Epoch 10: Train_accuracy: 65.72%, Train_loss: 0.627238, Test_accuracy: 61.37%, Test_loss: 0.664591\n",
      "batch size: 512, fold: 4| Epoch 11: Train_accuracy: 66.30%, Train_loss: 0.621566, Test_accuracy: 62.03%, Test_loss: 0.653202\n",
      "batch size: 512, fold: 4| Epoch 12: Train_accuracy: 67.31%, Train_loss: 0.617007, Test_accuracy: 62.50%, Test_loss: 0.654479\n",
      "batch size: 512, fold: 4| Epoch 13: Train_accuracy: 68.45%, Train_loss: 0.608752, Test_accuracy: 60.55%, Test_loss: 0.661586\n",
      "batch size: 512, fold: 4| Epoch 14: Train_accuracy: 68.80%, Train_loss: 0.604055, Test_accuracy: 61.37%, Test_loss: 0.651841\n",
      "batch size: 512, fold: 4| Epoch 15: Train_accuracy: 68.94%, Train_loss: 0.601161, Test_accuracy: 63.27%, Test_loss: 0.643302\n",
      "batch size: 512, fold: 4| Epoch 16: Train_accuracy: 69.69%, Train_loss: 0.596269, Test_accuracy: 61.37%, Test_loss: 0.658715\n",
      "batch size: 512, fold: 4| Epoch 17: Train_accuracy: 69.93%, Train_loss: 0.593936, Test_accuracy: 62.74%, Test_loss: 0.655362\n",
      "batch size: 512, fold: 4| Epoch 18: Train_accuracy: 71.26%, Train_loss: 0.582786, Test_accuracy: 62.09%, Test_loss: 0.651328\n",
      "batch size: 512, fold: 4| Epoch 19: Train_accuracy: 71.20%, Train_loss: 0.585387, Test_accuracy: 62.74%, Test_loss: 0.652172\n",
      "batch size: 512, fold: 4| Epoch 20: Train_accuracy: 72.43%, Train_loss: 0.573947, Test_accuracy: 63.98%, Test_loss: 0.641615\n",
      "batch size: 512, fold: 4| Epoch 21: Train_accuracy: 72.32%, Train_loss: 0.574560, Test_accuracy: 64.22%, Test_loss: 0.635387\n",
      "batch size: 512, fold: 4| Epoch 22: Train_accuracy: 72.69%, Train_loss: 0.569997, Test_accuracy: 62.32%, Test_loss: 0.646517\n",
      "batch size: 512, fold: 4| Epoch 23: Train_accuracy: 73.13%, Train_loss: 0.569228, Test_accuracy: 63.15%, Test_loss: 0.651055\n",
      "batch size: 512, fold: 4| Epoch 24: Train_accuracy: 74.46%, Train_loss: 0.558109, Test_accuracy: 63.09%, Test_loss: 0.643895\n",
      "batch size: 512, fold: 4| Epoch 25: Train_accuracy: 73.97%, Train_loss: 0.560306, Test_accuracy: 64.57%, Test_loss: 0.635809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 512, fold: 4| Epoch 26: Train_accuracy: 74.09%, Train_loss: 0.562843, Test_accuracy: 64.63%, Test_loss: 0.627480\n",
      "batch size: 512, fold: 4| Epoch 27: Train_accuracy: 75.40%, Train_loss: 0.549418, Test_accuracy: 65.70%, Test_loss: 0.634241\n",
      "batch size: 512, fold: 4| Epoch 28: Train_accuracy: 75.23%, Train_loss: 0.549205, Test_accuracy: 65.17%, Test_loss: 0.627646\n",
      "batch size: 512, fold: 4| Epoch 29: Train_accuracy: 76.15%, Train_loss: 0.541040, Test_accuracy: 65.28%, Test_loss: 0.638945\n",
      "batch size: 512, fold: 4| Epoch 30: Train_accuracy: 76.36%, Train_loss: 0.540422, Test_accuracy: 66.65%, Test_loss: 0.622065\n",
      "batch size: 512, fold: 4| Epoch 31: Train_accuracy: 76.31%, Train_loss: 0.537077, Test_accuracy: 65.76%, Test_loss: 0.635265\n",
      "batch size: 512, fold: 4| Epoch 32: Train_accuracy: 77.07%, Train_loss: 0.535068, Test_accuracy: 67.65%, Test_loss: 0.629181\n",
      "batch size: 512, fold: 4| Epoch 33: Train_accuracy: 77.74%, Train_loss: 0.526117, Test_accuracy: 66.88%, Test_loss: 0.619868\n",
      "batch size: 512, fold: 4| Epoch 34: Train_accuracy: 77.25%, Train_loss: 0.529874, Test_accuracy: 65.70%, Test_loss: 0.624647\n",
      "batch size: 512, fold: 4| Epoch 35: Train_accuracy: 78.21%, Train_loss: 0.525541, Test_accuracy: 67.42%, Test_loss: 0.613495\n",
      "batch size: 512, fold: 4| Epoch 36: Train_accuracy: 77.91%, Train_loss: 0.526464, Test_accuracy: 65.46%, Test_loss: 0.628955\n",
      "batch size: 512, fold: 4| Epoch 37: Train_accuracy: 77.57%, Train_loss: 0.525140, Test_accuracy: 65.94%, Test_loss: 0.632260\n",
      "batch size: 512, fold: 4| Epoch 38: Train_accuracy: 78.64%, Train_loss: 0.521295, Test_accuracy: 66.35%, Test_loss: 0.622720\n",
      "batch size: 512, fold: 4| Epoch 39: Train_accuracy: 78.95%, Train_loss: 0.512094, Test_accuracy: 67.00%, Test_loss: 0.610469\n",
      "batch size: 512, fold: 4| Epoch 40: Train_accuracy: 79.08%, Train_loss: 0.512443, Test_accuracy: 67.24%, Test_loss: 0.622141\n",
      "batch size: 512, fold: 4| Epoch 41: Train_accuracy: 78.89%, Train_loss: 0.514829, Test_accuracy: 66.35%, Test_loss: 0.630301\n",
      "batch size: 512, fold: 4| Epoch 42: Train_accuracy: 79.59%, Train_loss: 0.509015, Test_accuracy: 67.71%, Test_loss: 0.623247\n",
      "batch size: 512, fold: 4| Epoch 43: Train_accuracy: 79.77%, Train_loss: 0.507104, Test_accuracy: 67.95%, Test_loss: 0.605565\n",
      "batch size: 512, fold: 4| Epoch 44: Train_accuracy: 80.98%, Train_loss: 0.500038, Test_accuracy: 67.24%, Test_loss: 0.614091\n",
      "batch size: 512, fold: 4| Epoch 45: Train_accuracy: 80.46%, Train_loss: 0.500613, Test_accuracy: 68.66%, Test_loss: 0.610768\n",
      "batch size: 512, fold: 4| Epoch 46: Train_accuracy: 80.05%, Train_loss: 0.504087, Test_accuracy: 66.59%, Test_loss: 0.609966\n",
      "batch size: 512, fold: 4| Epoch 47: Train_accuracy: 79.81%, Train_loss: 0.508924, Test_accuracy: 65.82%, Test_loss: 0.625051\n",
      "batch size: 512, fold: 4| Epoch 48: Train_accuracy: 80.68%, Train_loss: 0.499203, Test_accuracy: 69.31%, Test_loss: 0.617480\n",
      "batch size: 512, fold: 4| Epoch 49: Train_accuracy: 81.03%, Train_loss: 0.493562, Test_accuracy: 68.19%, Test_loss: 0.611702\n",
      "batch size: 512, fold: 4| Epoch 50: Train_accuracy: 81.60%, Train_loss: 0.490503, Test_accuracy: 68.42%, Test_loss: 0.603465\n",
      "batch size: 512, fold: 4| Epoch 51: Train_accuracy: 81.54%, Train_loss: 0.491051, Test_accuracy: 67.36%, Test_loss: 0.622824\n",
      "batch size: 512, fold: 4| Epoch 52: Train_accuracy: 81.11%, Train_loss: 0.492628, Test_accuracy: 69.85%, Test_loss: 0.597343\n",
      "batch size: 512, fold: 4| Epoch 53: Train_accuracy: 81.60%, Train_loss: 0.495091, Test_accuracy: 68.42%, Test_loss: 0.628188\n",
      "batch size: 512, fold: 4| Epoch 54: Train_accuracy: 82.28%, Train_loss: 0.486228, Test_accuracy: 67.12%, Test_loss: 0.629137\n",
      "batch size: 512, fold: 4| Epoch 55: Train_accuracy: 82.28%, Train_loss: 0.488626, Test_accuracy: 67.77%, Test_loss: 0.618202\n",
      "batch size: 512, fold: 4| Epoch 56: Train_accuracy: 81.84%, Train_loss: 0.486803, Test_accuracy: 66.35%, Test_loss: 0.626322\n",
      "batch size: 512, fold: 4| Epoch 57: Train_accuracy: 81.88%, Train_loss: 0.484477, Test_accuracy: 69.14%, Test_loss: 0.612027\n",
      "batch size: 512, fold: 4| Epoch 58: Train_accuracy: 82.36%, Train_loss: 0.482050, Test_accuracy: 68.78%, Test_loss: 0.606656\n",
      "batch size: 512, fold: 4| Epoch 59: Train_accuracy: 82.30%, Train_loss: 0.485783, Test_accuracy: 69.91%, Test_loss: 0.605282\n",
      "batch size: 512, fold: 4| Epoch 60: Train_accuracy: 82.33%, Train_loss: 0.482130, Test_accuracy: 66.94%, Test_loss: 0.610571\n",
      "batch size: 512, fold: 4| Epoch 61: Train_accuracy: 82.88%, Train_loss: 0.479378, Test_accuracy: 69.91%, Test_loss: 0.606050\n",
      "batch size: 512, fold: 4| Epoch 62: Train_accuracy: 82.52%, Train_loss: 0.480283, Test_accuracy: 68.96%, Test_loss: 0.602106\n",
      "batch size: 512, fold: 4| Epoch 63: Train_accuracy: 83.34%, Train_loss: 0.472749, Test_accuracy: 69.14%, Test_loss: 0.610095\n",
      "batch size: 512, fold: 4| Epoch 64: Train_accuracy: 83.41%, Train_loss: 0.474335, Test_accuracy: 70.08%, Test_loss: 0.603335\n",
      "batch size: 512, fold: 4| Epoch 65: Train_accuracy: 83.01%, Train_loss: 0.476945, Test_accuracy: 69.14%, Test_loss: 0.601094\n",
      "batch size: 512, fold: 4| Epoch 66: Train_accuracy: 83.23%, Train_loss: 0.473454, Test_accuracy: 68.66%, Test_loss: 0.616448\n",
      "batch size: 512, fold: 4| Epoch 67: Train_accuracy: 83.53%, Train_loss: 0.469499, Test_accuracy: 68.72%, Test_loss: 0.613844\n",
      "batch size: 512, fold: 4| Epoch 68: Train_accuracy: 84.21%, Train_loss: 0.466834, Test_accuracy: 68.60%, Test_loss: 0.600958\n",
      "batch size: 512, fold: 4| Epoch 69: Train_accuracy: 84.43%, Train_loss: 0.463307, Test_accuracy: 68.54%, Test_loss: 0.610378\n",
      "batch size: 512, fold: 4| Epoch 70: Train_accuracy: 84.30%, Train_loss: 0.468190, Test_accuracy: 68.90%, Test_loss: 0.615214\n",
      "batch size: 512, fold: 4| Epoch 71: Train_accuracy: 83.69%, Train_loss: 0.470149, Test_accuracy: 67.89%, Test_loss: 0.614137\n",
      "batch size: 512, fold: 4| Epoch 72: Train_accuracy: 83.99%, Train_loss: 0.472038, Test_accuracy: 68.31%, Test_loss: 0.616626\n",
      "batch size: 512, fold: 4| Epoch 73: Train_accuracy: 84.65%, Train_loss: 0.464720, Test_accuracy: 70.14%, Test_loss: 0.600995\n",
      "batch size: 512, fold: 4| Epoch 74: Train_accuracy: 84.71%, Train_loss: 0.461425, Test_accuracy: 68.90%, Test_loss: 0.595562\n",
      "batch size: 512, fold: 4| Epoch 75: Train_accuracy: 85.37%, Train_loss: 0.455640, Test_accuracy: 71.03%, Test_loss: 0.608196\n",
      "batch size: 512, fold: 4| Epoch 76: Train_accuracy: 85.05%, Train_loss: 0.462751, Test_accuracy: 70.08%, Test_loss: 0.595124\n",
      "batch size: 512, fold: 4| Epoch 77: Train_accuracy: 84.95%, Train_loss: 0.461334, Test_accuracy: 68.25%, Test_loss: 0.611318\n",
      "batch size: 512, fold: 4| Epoch 78: Train_accuracy: 84.91%, Train_loss: 0.457552, Test_accuracy: 69.91%, Test_loss: 0.595284\n",
      "batch size: 512, fold: 4| Epoch 79: Train_accuracy: 85.44%, Train_loss: 0.456203, Test_accuracy: 69.37%, Test_loss: 0.601533\n",
      "batch size: 512, fold: 4| Epoch 80: Train_accuracy: 86.18%, Train_loss: 0.453052, Test_accuracy: 68.36%, Test_loss: 0.601095\n",
      "batch size: 512, fold: 4| Epoch 81: Train_accuracy: 85.28%, Train_loss: 0.455216, Test_accuracy: 70.44%, Test_loss: 0.584405\n",
      "batch size: 512, fold: 4| Epoch 82: Train_accuracy: 85.48%, Train_loss: 0.454486, Test_accuracy: 68.60%, Test_loss: 0.609590\n",
      "batch size: 512, fold: 4| Epoch 83: Train_accuracy: 85.42%, Train_loss: 0.452851, Test_accuracy: 71.33%, Test_loss: 0.572462\n",
      "batch size: 512, fold: 4| Epoch 84: Train_accuracy: 85.69%, Train_loss: 0.454913, Test_accuracy: 70.44%, Test_loss: 0.587942\n",
      "batch size: 512, fold: 4| Epoch 85: Train_accuracy: 86.00%, Train_loss: 0.451114, Test_accuracy: 69.91%, Test_loss: 0.596747\n",
      "batch size: 512, fold: 4| Epoch 86: Train_accuracy: 86.08%, Train_loss: 0.448389, Test_accuracy: 70.20%, Test_loss: 0.590565\n",
      "batch size: 512, fold: 4| Epoch 87: Train_accuracy: 85.54%, Train_loss: 0.449843, Test_accuracy: 71.50%, Test_loss: 0.581638\n",
      "batch size: 512, fold: 4| Epoch 88: Train_accuracy: 85.81%, Train_loss: 0.450528, Test_accuracy: 69.43%, Test_loss: 0.593936\n",
      "batch size: 512, fold: 4| Epoch 89: Train_accuracy: 86.28%, Train_loss: 0.448326, Test_accuracy: 70.20%, Test_loss: 0.598264\n",
      "batch size: 512, fold: 4| Epoch 90: Train_accuracy: 85.44%, Train_loss: 0.453979, Test_accuracy: 70.14%, Test_loss: 0.591822\n",
      "batch size: 512, fold: 4| Epoch 91: Train_accuracy: 86.09%, Train_loss: 0.449799, Test_accuracy: 70.02%, Test_loss: 0.596798\n",
      "batch size: 512, fold: 4| Epoch 92: Train_accuracy: 85.96%, Train_loss: 0.448578, Test_accuracy: 69.19%, Test_loss: 0.615706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 512, fold: 4| Epoch 93: Train_accuracy: 86.12%, Train_loss: 0.447875, Test_accuracy: 70.62%, Test_loss: 0.600942\n",
      "batch size: 512, fold: 4| Epoch 94: Train_accuracy: 86.34%, Train_loss: 0.443168, Test_accuracy: 69.14%, Test_loss: 0.596917\n",
      "batch size: 512, fold: 4| Epoch 95: Train_accuracy: 86.52%, Train_loss: 0.445554, Test_accuracy: 70.14%, Test_loss: 0.601617\n",
      "batch size: 512, fold: 4| Epoch 96: Train_accuracy: 86.54%, Train_loss: 0.443610, Test_accuracy: 70.38%, Test_loss: 0.592621\n",
      "batch size: 512, fold: 4| Epoch 97: Train_accuracy: 86.79%, Train_loss: 0.440505, Test_accuracy: 70.44%, Test_loss: 0.593873\n",
      "batch size: 512, fold: 4| Epoch 98: Train_accuracy: 87.68%, Train_loss: 0.434502, Test_accuracy: 70.85%, Test_loss: 0.599501\n",
      "batch size: 512, fold: 4| Epoch 99: Train_accuracy: 86.71%, Train_loss: 0.442055, Test_accuracy: 70.32%, Test_loss: 0.598165\n",
      "batch size: 512, fold: 4| Epoch 100: Train_accuracy: 87.11%, Train_loss: 0.436881, Test_accuracy: 70.08%, Test_loss: 0.601411\n",
      "batch size: 512, fold: 5| Epoch 1: Train_accuracy: 54.27%, Train_loss: 0.691614, Test_accuracy: 56.02%, Test_loss: 0.688038\n",
      "batch size: 512, fold: 5| Epoch 2: Train_accuracy: 56.58%, Train_loss: 0.684066, Test_accuracy: 56.73%, Test_loss: 0.683365\n",
      "batch size: 512, fold: 5| Epoch 3: Train_accuracy: 57.41%, Train_loss: 0.677405, Test_accuracy: 56.55%, Test_loss: 0.675234\n",
      "batch size: 512, fold: 5| Epoch 4: Train_accuracy: 59.33%, Train_loss: 0.668690, Test_accuracy: 55.60%, Test_loss: 0.672766\n",
      "batch size: 512, fold: 5| Epoch 5: Train_accuracy: 60.41%, Train_loss: 0.661624, Test_accuracy: 58.92%, Test_loss: 0.668258\n",
      "batch size: 512, fold: 5| Epoch 6: Train_accuracy: 62.01%, Train_loss: 0.655656, Test_accuracy: 59.34%, Test_loss: 0.668626\n",
      "batch size: 512, fold: 5| Epoch 7: Train_accuracy: 63.14%, Train_loss: 0.646317, Test_accuracy: 59.40%, Test_loss: 0.664199\n",
      "batch size: 512, fold: 5| Epoch 8: Train_accuracy: 63.89%, Train_loss: 0.641247, Test_accuracy: 59.81%, Test_loss: 0.659222\n",
      "batch size: 512, fold: 5| Epoch 9: Train_accuracy: 64.85%, Train_loss: 0.633908, Test_accuracy: 60.58%, Test_loss: 0.656639\n",
      "batch size: 512, fold: 5| Epoch 10: Train_accuracy: 65.36%, Train_loss: 0.632162, Test_accuracy: 62.42%, Test_loss: 0.653660\n",
      "batch size: 512, fold: 5| Epoch 11: Train_accuracy: 66.68%, Train_loss: 0.620075, Test_accuracy: 61.77%, Test_loss: 0.649348\n",
      "batch size: 512, fold: 5| Epoch 12: Train_accuracy: 67.68%, Train_loss: 0.613534, Test_accuracy: 63.13%, Test_loss: 0.645222\n",
      "batch size: 512, fold: 5| Epoch 13: Train_accuracy: 68.28%, Train_loss: 0.609154, Test_accuracy: 61.59%, Test_loss: 0.646771\n",
      "batch size: 512, fold: 5| Epoch 14: Train_accuracy: 68.81%, Train_loss: 0.603379, Test_accuracy: 62.95%, Test_loss: 0.652619\n",
      "batch size: 512, fold: 5| Epoch 15: Train_accuracy: 69.64%, Train_loss: 0.596637, Test_accuracy: 63.78%, Test_loss: 0.637055\n",
      "batch size: 512, fold: 5| Epoch 16: Train_accuracy: 70.28%, Train_loss: 0.591256, Test_accuracy: 63.60%, Test_loss: 0.636646\n",
      "batch size: 512, fold: 5| Epoch 17: Train_accuracy: 71.50%, Train_loss: 0.583570, Test_accuracy: 63.49%, Test_loss: 0.650201\n",
      "batch size: 512, fold: 5| Epoch 18: Train_accuracy: 71.52%, Train_loss: 0.585718, Test_accuracy: 65.68%, Test_loss: 0.636364\n",
      "batch size: 512, fold: 5| Epoch 19: Train_accuracy: 71.40%, Train_loss: 0.581732, Test_accuracy: 65.26%, Test_loss: 0.633809\n",
      "batch size: 512, fold: 5| Epoch 20: Train_accuracy: 72.57%, Train_loss: 0.572311, Test_accuracy: 65.68%, Test_loss: 0.630826\n",
      "batch size: 512, fold: 5| Epoch 21: Train_accuracy: 73.37%, Train_loss: 0.566213, Test_accuracy: 63.19%, Test_loss: 0.644639\n",
      "batch size: 512, fold: 5| Epoch 22: Train_accuracy: 73.62%, Train_loss: 0.559245, Test_accuracy: 65.68%, Test_loss: 0.637406\n",
      "batch size: 512, fold: 5| Epoch 23: Train_accuracy: 73.71%, Train_loss: 0.561576, Test_accuracy: 65.26%, Test_loss: 0.628639\n",
      "batch size: 512, fold: 5| Epoch 24: Train_accuracy: 73.84%, Train_loss: 0.558482, Test_accuracy: 65.15%, Test_loss: 0.630304\n",
      "batch size: 512, fold: 5| Epoch 25: Train_accuracy: 75.68%, Train_loss: 0.547171, Test_accuracy: 63.54%, Test_loss: 0.636363\n",
      "batch size: 512, fold: 5| Epoch 26: Train_accuracy: 75.50%, Train_loss: 0.547982, Test_accuracy: 66.92%, Test_loss: 0.613800\n",
      "batch size: 512, fold: 5| Epoch 27: Train_accuracy: 74.88%, Train_loss: 0.552362, Test_accuracy: 66.39%, Test_loss: 0.624656\n",
      "batch size: 512, fold: 5| Epoch 28: Train_accuracy: 74.87%, Train_loss: 0.549650, Test_accuracy: 65.50%, Test_loss: 0.628442\n",
      "batch size: 512, fold: 5| Epoch 29: Train_accuracy: 76.42%, Train_loss: 0.540562, Test_accuracy: 66.69%, Test_loss: 0.623743\n",
      "batch size: 512, fold: 5| Epoch 30: Train_accuracy: 76.16%, Train_loss: 0.539967, Test_accuracy: 67.04%, Test_loss: 0.618319\n",
      "batch size: 512, fold: 5| Epoch 31: Train_accuracy: 77.01%, Train_loss: 0.533426, Test_accuracy: 69.29%, Test_loss: 0.596059\n",
      "batch size: 512, fold: 5| Epoch 32: Train_accuracy: 77.09%, Train_loss: 0.531625, Test_accuracy: 67.58%, Test_loss: 0.606541\n",
      "batch size: 512, fold: 5| Epoch 33: Train_accuracy: 77.40%, Train_loss: 0.531944, Test_accuracy: 67.04%, Test_loss: 0.620210\n",
      "batch size: 512, fold: 5| Epoch 34: Train_accuracy: 78.30%, Train_loss: 0.520956, Test_accuracy: 68.76%, Test_loss: 0.609710\n",
      "batch size: 512, fold: 5| Epoch 35: Train_accuracy: 77.83%, Train_loss: 0.526289, Test_accuracy: 68.29%, Test_loss: 0.605657\n",
      "batch size: 512, fold: 5| Epoch 36: Train_accuracy: 77.75%, Train_loss: 0.525132, Test_accuracy: 67.58%, Test_loss: 0.616742\n",
      "batch size: 512, fold: 5| Epoch 37: Train_accuracy: 78.36%, Train_loss: 0.518255, Test_accuracy: 68.23%, Test_loss: 0.608836\n",
      "batch size: 512, fold: 5| Epoch 38: Train_accuracy: 78.41%, Train_loss: 0.520286, Test_accuracy: 68.23%, Test_loss: 0.600660\n",
      "batch size: 512, fold: 5| Epoch 39: Train_accuracy: 78.70%, Train_loss: 0.515123, Test_accuracy: 67.04%, Test_loss: 0.616736\n",
      "batch size: 512, fold: 5| Epoch 40: Train_accuracy: 79.41%, Train_loss: 0.509633, Test_accuracy: 68.35%, Test_loss: 0.610114\n",
      "batch size: 512, fold: 5| Epoch 41: Train_accuracy: 78.88%, Train_loss: 0.509424, Test_accuracy: 68.58%, Test_loss: 0.609442\n",
      "batch size: 512, fold: 5| Epoch 42: Train_accuracy: 79.87%, Train_loss: 0.504925, Test_accuracy: 67.22%, Test_loss: 0.615299\n",
      "batch size: 512, fold: 5| Epoch 43: Train_accuracy: 80.49%, Train_loss: 0.501220, Test_accuracy: 67.75%, Test_loss: 0.608584\n",
      "batch size: 512, fold: 5| Epoch 44: Train_accuracy: 80.35%, Train_loss: 0.508118, Test_accuracy: 68.82%, Test_loss: 0.603139\n",
      "batch size: 512, fold: 5| Epoch 45: Train_accuracy: 80.84%, Train_loss: 0.499317, Test_accuracy: 69.59%, Test_loss: 0.592661\n",
      "batch size: 512, fold: 5| Epoch 46: Train_accuracy: 80.58%, Train_loss: 0.500575, Test_accuracy: 67.99%, Test_loss: 0.600935\n",
      "batch size: 512, fold: 5| Epoch 47: Train_accuracy: 80.12%, Train_loss: 0.498371, Test_accuracy: 69.53%, Test_loss: 0.591650\n",
      "batch size: 512, fold: 5| Epoch 48: Train_accuracy: 81.09%, Train_loss: 0.498839, Test_accuracy: 69.65%, Test_loss: 0.598359\n",
      "batch size: 512, fold: 5| Epoch 49: Train_accuracy: 81.10%, Train_loss: 0.493790, Test_accuracy: 68.76%, Test_loss: 0.600752\n",
      "batch size: 512, fold: 5| Epoch 50: Train_accuracy: 81.75%, Train_loss: 0.490675, Test_accuracy: 69.06%, Test_loss: 0.607918\n",
      "batch size: 512, fold: 5| Epoch 51: Train_accuracy: 82.30%, Train_loss: 0.483392, Test_accuracy: 70.30%, Test_loss: 0.596299\n",
      "batch size: 512, fold: 5| Epoch 52: Train_accuracy: 82.60%, Train_loss: 0.489175, Test_accuracy: 70.18%, Test_loss: 0.589149\n",
      "batch size: 512, fold: 5| Epoch 53: Train_accuracy: 82.27%, Train_loss: 0.479842, Test_accuracy: 69.24%, Test_loss: 0.599701\n",
      "batch size: 512, fold: 5| Epoch 54: Train_accuracy: 82.17%, Train_loss: 0.484063, Test_accuracy: 69.24%, Test_loss: 0.599133\n",
      "batch size: 512, fold: 5| Epoch 55: Train_accuracy: 82.86%, Train_loss: 0.478407, Test_accuracy: 68.76%, Test_loss: 0.606704\n",
      "batch size: 512, fold: 5| Epoch 56: Train_accuracy: 82.05%, Train_loss: 0.483654, Test_accuracy: 69.00%, Test_loss: 0.609642\n",
      "batch size: 512, fold: 5| Epoch 57: Train_accuracy: 83.13%, Train_loss: 0.478302, Test_accuracy: 68.64%, Test_loss: 0.602346\n",
      "batch size: 512, fold: 5| Epoch 58: Train_accuracy: 82.58%, Train_loss: 0.481642, Test_accuracy: 68.17%, Test_loss: 0.601253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 512, fold: 5| Epoch 59: Train_accuracy: 83.84%, Train_loss: 0.469338, Test_accuracy: 69.65%, Test_loss: 0.606030\n",
      "batch size: 512, fold: 5| Epoch 60: Train_accuracy: 82.95%, Train_loss: 0.476032, Test_accuracy: 70.66%, Test_loss: 0.587421\n",
      "batch size: 512, fold: 5| Epoch 61: Train_accuracy: 82.75%, Train_loss: 0.476453, Test_accuracy: 70.12%, Test_loss: 0.600864\n",
      "batch size: 512, fold: 5| Epoch 62: Train_accuracy: 82.57%, Train_loss: 0.479850, Test_accuracy: 68.70%, Test_loss: 0.606920\n",
      "batch size: 512, fold: 5| Epoch 63: Train_accuracy: 82.43%, Train_loss: 0.479478, Test_accuracy: 69.29%, Test_loss: 0.597093\n",
      "batch size: 512, fold: 5| Epoch 64: Train_accuracy: 83.58%, Train_loss: 0.470988, Test_accuracy: 70.95%, Test_loss: 0.591375\n",
      "batch size: 512, fold: 5| Epoch 65: Train_accuracy: 84.21%, Train_loss: 0.469027, Test_accuracy: 70.60%, Test_loss: 0.591646\n",
      "batch size: 512, fold: 5| Epoch 66: Train_accuracy: 84.11%, Train_loss: 0.469458, Test_accuracy: 70.48%, Test_loss: 0.593249\n",
      "batch size: 512, fold: 5| Epoch 67: Train_accuracy: 84.30%, Train_loss: 0.464494, Test_accuracy: 70.95%, Test_loss: 0.590992\n",
      "batch size: 512, fold: 5| Epoch 68: Train_accuracy: 85.01%, Train_loss: 0.462793, Test_accuracy: 70.90%, Test_loss: 0.589965\n",
      "batch size: 512, fold: 5| Epoch 69: Train_accuracy: 84.91%, Train_loss: 0.459433, Test_accuracy: 69.65%, Test_loss: 0.580841\n",
      "batch size: 512, fold: 5| Epoch 70: Train_accuracy: 83.80%, Train_loss: 0.470242, Test_accuracy: 70.84%, Test_loss: 0.582698\n",
      "batch size: 512, fold: 5| Epoch 71: Train_accuracy: 84.76%, Train_loss: 0.464948, Test_accuracy: 70.42%, Test_loss: 0.587551\n",
      "batch size: 512, fold: 5| Epoch 72: Train_accuracy: 85.01%, Train_loss: 0.457835, Test_accuracy: 69.53%, Test_loss: 0.615713\n",
      "batch size: 512, fold: 5| Epoch 73: Train_accuracy: 83.84%, Train_loss: 0.463925, Test_accuracy: 70.01%, Test_loss: 0.598410\n",
      "batch size: 512, fold: 5| Epoch 74: Train_accuracy: 85.25%, Train_loss: 0.453947, Test_accuracy: 70.54%, Test_loss: 0.596937\n",
      "batch size: 512, fold: 5| Epoch 75: Train_accuracy: 85.10%, Train_loss: 0.457032, Test_accuracy: 71.13%, Test_loss: 0.580471\n",
      "batch size: 512, fold: 5| Epoch 76: Train_accuracy: 86.08%, Train_loss: 0.449403, Test_accuracy: 70.60%, Test_loss: 0.589124\n",
      "batch size: 512, fold: 5| Epoch 77: Train_accuracy: 84.82%, Train_loss: 0.457372, Test_accuracy: 71.78%, Test_loss: 0.583901\n",
      "batch size: 512, fold: 5| Epoch 78: Train_accuracy: 85.84%, Train_loss: 0.451495, Test_accuracy: 70.78%, Test_loss: 0.582086\n",
      "batch size: 512, fold: 5| Epoch 79: Train_accuracy: 85.78%, Train_loss: 0.452587, Test_accuracy: 69.95%, Test_loss: 0.594091\n",
      "batch size: 512, fold: 5| Epoch 80: Train_accuracy: 85.71%, Train_loss: 0.447365, Test_accuracy: 70.90%, Test_loss: 0.586623\n",
      "batch size: 512, fold: 5| Epoch 81: Train_accuracy: 86.27%, Train_loss: 0.448336, Test_accuracy: 70.24%, Test_loss: 0.602230\n",
      "batch size: 512, fold: 5| Epoch 82: Train_accuracy: 85.97%, Train_loss: 0.451436, Test_accuracy: 71.55%, Test_loss: 0.583807\n",
      "batch size: 512, fold: 5| Epoch 83: Train_accuracy: 86.37%, Train_loss: 0.447403, Test_accuracy: 72.26%, Test_loss: 0.577043\n",
      "batch size: 512, fold: 5| Epoch 84: Train_accuracy: 86.29%, Train_loss: 0.444650, Test_accuracy: 72.38%, Test_loss: 0.577358\n",
      "batch size: 512, fold: 5| Epoch 85: Train_accuracy: 86.30%, Train_loss: 0.446608, Test_accuracy: 72.79%, Test_loss: 0.570171\n",
      "batch size: 512, fold: 5| Epoch 86: Train_accuracy: 86.06%, Train_loss: 0.443511, Test_accuracy: 70.36%, Test_loss: 0.585447\n",
      "batch size: 512, fold: 5| Epoch 87: Train_accuracy: 86.51%, Train_loss: 0.446147, Test_accuracy: 71.78%, Test_loss: 0.594306\n",
      "batch size: 512, fold: 5| Epoch 88: Train_accuracy: 86.70%, Train_loss: 0.444346, Test_accuracy: 71.01%, Test_loss: 0.590947\n",
      "batch size: 512, fold: 5| Epoch 89: Train_accuracy: 85.65%, Train_loss: 0.448786, Test_accuracy: 71.67%, Test_loss: 0.581597\n",
      "batch size: 512, fold: 5| Epoch 90: Train_accuracy: 86.26%, Train_loss: 0.442205, Test_accuracy: 71.96%, Test_loss: 0.586239\n",
      "batch size: 512, fold: 5| Epoch 91: Train_accuracy: 86.55%, Train_loss: 0.442964, Test_accuracy: 70.72%, Test_loss: 0.587933\n",
      "batch size: 512, fold: 5| Epoch 92: Train_accuracy: 86.67%, Train_loss: 0.442437, Test_accuracy: 70.84%, Test_loss: 0.581432\n",
      "batch size: 512, fold: 5| Epoch 93: Train_accuracy: 87.14%, Train_loss: 0.441206, Test_accuracy: 71.31%, Test_loss: 0.578508\n",
      "batch size: 512, fold: 5| Epoch 94: Train_accuracy: 86.76%, Train_loss: 0.442888, Test_accuracy: 70.66%, Test_loss: 0.589366\n",
      "batch size: 512, fold: 5| Epoch 95: Train_accuracy: 86.73%, Train_loss: 0.440157, Test_accuracy: 71.19%, Test_loss: 0.570503\n",
      "batch size: 512, fold: 5| Epoch 96: Train_accuracy: 87.84%, Train_loss: 0.431628, Test_accuracy: 70.95%, Test_loss: 0.589387\n",
      "batch size: 512, fold: 5| Epoch 97: Train_accuracy: 88.18%, Train_loss: 0.429670, Test_accuracy: 72.14%, Test_loss: 0.568355\n",
      "batch size: 512, fold: 5| Epoch 98: Train_accuracy: 88.15%, Train_loss: 0.428169, Test_accuracy: 70.72%, Test_loss: 0.591745\n",
      "batch size: 512, fold: 5| Epoch 99: Train_accuracy: 87.86%, Train_loss: 0.430241, Test_accuracy: 70.01%, Test_loss: 0.596571\n",
      "batch size: 512, fold: 5| Epoch 100: Train_accuracy: 87.09%, Train_loss: 0.440866, Test_accuracy: 72.67%, Test_loss: 0.568352\n",
      "batch size: 1024, fold: 1| Epoch 1: Train_accuracy: 50.97%, Train_loss: 0.692579, Test_accuracy: 52.49%, Test_loss: 0.690796\n",
      "batch size: 1024, fold: 1| Epoch 2: Train_accuracy: 53.99%, Train_loss: 0.689043, Test_accuracy: 56.52%, Test_loss: 0.686960\n",
      "batch size: 1024, fold: 1| Epoch 3: Train_accuracy: 55.67%, Train_loss: 0.685058, Test_accuracy: 57.70%, Test_loss: 0.681089\n",
      "batch size: 1024, fold: 1| Epoch 4: Train_accuracy: 56.91%, Train_loss: 0.679209, Test_accuracy: 58.06%, Test_loss: 0.673196\n",
      "batch size: 1024, fold: 1| Epoch 5: Train_accuracy: 58.02%, Train_loss: 0.673334, Test_accuracy: 58.12%, Test_loss: 0.670867\n",
      "batch size: 1024, fold: 1| Epoch 6: Train_accuracy: 59.69%, Train_loss: 0.668541, Test_accuracy: 59.36%, Test_loss: 0.663001\n",
      "batch size: 1024, fold: 1| Epoch 7: Train_accuracy: 60.44%, Train_loss: 0.661483, Test_accuracy: 61.61%, Test_loss: 0.657301\n",
      "batch size: 1024, fold: 1| Epoch 8: Train_accuracy: 61.93%, Train_loss: 0.656522, Test_accuracy: 60.72%, Test_loss: 0.656180\n",
      "batch size: 1024, fold: 1| Epoch 9: Train_accuracy: 62.66%, Train_loss: 0.649862, Test_accuracy: 62.38%, Test_loss: 0.654047\n",
      "batch size: 1024, fold: 1| Epoch 10: Train_accuracy: 63.99%, Train_loss: 0.640807, Test_accuracy: 62.14%, Test_loss: 0.647639\n",
      "batch size: 1024, fold: 1| Epoch 11: Train_accuracy: 64.14%, Train_loss: 0.635635, Test_accuracy: 61.61%, Test_loss: 0.651776\n",
      "batch size: 1024, fold: 1| Epoch 12: Train_accuracy: 65.19%, Train_loss: 0.630182, Test_accuracy: 62.14%, Test_loss: 0.649670\n",
      "batch size: 1024, fold: 1| Epoch 13: Train_accuracy: 65.62%, Train_loss: 0.628448, Test_accuracy: 62.32%, Test_loss: 0.644600\n",
      "batch size: 1024, fold: 1| Epoch 14: Train_accuracy: 66.76%, Train_loss: 0.617281, Test_accuracy: 63.98%, Test_loss: 0.641699\n",
      "batch size: 1024, fold: 1| Epoch 15: Train_accuracy: 67.65%, Train_loss: 0.614249, Test_accuracy: 63.39%, Test_loss: 0.642103\n",
      "batch size: 1024, fold: 1| Epoch 16: Train_accuracy: 67.87%, Train_loss: 0.608916, Test_accuracy: 62.20%, Test_loss: 0.651690\n",
      "batch size: 1024, fold: 1| Epoch 17: Train_accuracy: 69.01%, Train_loss: 0.603499, Test_accuracy: 62.91%, Test_loss: 0.647150\n",
      "batch size: 1024, fold: 1| Epoch 18: Train_accuracy: 69.84%, Train_loss: 0.599651, Test_accuracy: 63.51%, Test_loss: 0.643522\n",
      "batch size: 1024, fold: 1| Epoch 19: Train_accuracy: 69.38%, Train_loss: 0.595647, Test_accuracy: 62.26%, Test_loss: 0.644015\n",
      "batch size: 1024, fold: 1| Epoch 20: Train_accuracy: 69.86%, Train_loss: 0.591604, Test_accuracy: 63.51%, Test_loss: 0.636486\n",
      "batch size: 1024, fold: 1| Epoch 21: Train_accuracy: 70.88%, Train_loss: 0.590445, Test_accuracy: 64.57%, Test_loss: 0.635261\n",
      "batch size: 1024, fold: 1| Epoch 22: Train_accuracy: 71.57%, Train_loss: 0.581703, Test_accuracy: 64.69%, Test_loss: 0.627198\n",
      "batch size: 1024, fold: 1| Epoch 23: Train_accuracy: 71.15%, Train_loss: 0.581451, Test_accuracy: 64.81%, Test_loss: 0.636519\n",
      "batch size: 1024, fold: 1| Epoch 24: Train_accuracy: 72.15%, Train_loss: 0.574466, Test_accuracy: 65.17%, Test_loss: 0.630891\n",
      "batch size: 1024, fold: 1| Epoch 25: Train_accuracy: 72.27%, Train_loss: 0.575975, Test_accuracy: 64.28%, Test_loss: 0.633850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1024, fold: 1| Epoch 26: Train_accuracy: 72.77%, Train_loss: 0.571529, Test_accuracy: 65.11%, Test_loss: 0.630235\n",
      "batch size: 1024, fold: 1| Epoch 27: Train_accuracy: 73.63%, Train_loss: 0.563454, Test_accuracy: 64.40%, Test_loss: 0.637599\n",
      "batch size: 1024, fold: 1| Epoch 28: Train_accuracy: 73.56%, Train_loss: 0.560870, Test_accuracy: 66.88%, Test_loss: 0.619201\n",
      "batch size: 1024, fold: 1| Epoch 29: Train_accuracy: 73.63%, Train_loss: 0.563526, Test_accuracy: 65.64%, Test_loss: 0.618642\n",
      "batch size: 1024, fold: 1| Epoch 30: Train_accuracy: 74.05%, Train_loss: 0.558386, Test_accuracy: 67.06%, Test_loss: 0.622321\n",
      "batch size: 1024, fold: 1| Epoch 31: Train_accuracy: 75.31%, Train_loss: 0.550990, Test_accuracy: 66.05%, Test_loss: 0.626605\n",
      "batch size: 1024, fold: 1| Epoch 32: Train_accuracy: 74.92%, Train_loss: 0.549596, Test_accuracy: 68.25%, Test_loss: 0.613322\n",
      "batch size: 1024, fold: 1| Epoch 33: Train_accuracy: 74.77%, Train_loss: 0.550766, Test_accuracy: 67.12%, Test_loss: 0.612256\n",
      "batch size: 1024, fold: 1| Epoch 34: Train_accuracy: 75.66%, Train_loss: 0.543587, Test_accuracy: 66.35%, Test_loss: 0.620517\n",
      "batch size: 1024, fold: 1| Epoch 35: Train_accuracy: 75.69%, Train_loss: 0.542255, Test_accuracy: 65.82%, Test_loss: 0.631340\n",
      "batch size: 1024, fold: 1| Epoch 36: Train_accuracy: 76.08%, Train_loss: 0.539975, Test_accuracy: 64.57%, Test_loss: 0.634100\n",
      "batch size: 1024, fold: 1| Epoch 37: Train_accuracy: 76.80%, Train_loss: 0.537250, Test_accuracy: 66.00%, Test_loss: 0.628149\n",
      "batch size: 1024, fold: 1| Epoch 38: Train_accuracy: 76.42%, Train_loss: 0.538425, Test_accuracy: 65.64%, Test_loss: 0.630231\n",
      "batch size: 1024, fold: 1| Epoch 39: Train_accuracy: 76.80%, Train_loss: 0.534708, Test_accuracy: 66.77%, Test_loss: 0.616838\n",
      "batch size: 1024, fold: 1| Epoch 40: Train_accuracy: 76.52%, Train_loss: 0.534655, Test_accuracy: 65.40%, Test_loss: 0.629407\n",
      "batch size: 1024, fold: 1| Epoch 41: Train_accuracy: 77.11%, Train_loss: 0.531180, Test_accuracy: 66.77%, Test_loss: 0.614728\n",
      "batch size: 1024, fold: 1| Epoch 42: Train_accuracy: 77.57%, Train_loss: 0.529084, Test_accuracy: 66.71%, Test_loss: 0.626013\n",
      "batch size: 1024, fold: 1| Epoch 43: Train_accuracy: 77.57%, Train_loss: 0.527315, Test_accuracy: 66.77%, Test_loss: 0.619585\n",
      "batch size: 1024, fold: 1| Epoch 44: Train_accuracy: 78.34%, Train_loss: 0.522962, Test_accuracy: 66.00%, Test_loss: 0.621774\n",
      "batch size: 1024, fold: 1| Epoch 45: Train_accuracy: 79.01%, Train_loss: 0.516019, Test_accuracy: 67.00%, Test_loss: 0.618084\n",
      "batch size: 1024, fold: 1| Epoch 46: Train_accuracy: 78.80%, Train_loss: 0.516569, Test_accuracy: 69.02%, Test_loss: 0.608993\n",
      "batch size: 1024, fold: 1| Epoch 47: Train_accuracy: 78.03%, Train_loss: 0.518765, Test_accuracy: 66.71%, Test_loss: 0.626987\n",
      "batch size: 1024, fold: 1| Epoch 48: Train_accuracy: 79.35%, Train_loss: 0.514222, Test_accuracy: 67.54%, Test_loss: 0.614101\n",
      "batch size: 1024, fold: 1| Epoch 49: Train_accuracy: 79.69%, Train_loss: 0.510470, Test_accuracy: 66.23%, Test_loss: 0.626887\n",
      "batch size: 1024, fold: 1| Epoch 50: Train_accuracy: 79.90%, Train_loss: 0.507608, Test_accuracy: 68.19%, Test_loss: 0.609053\n",
      "batch size: 1024, fold: 1| Epoch 51: Train_accuracy: 80.21%, Train_loss: 0.506645, Test_accuracy: 67.00%, Test_loss: 0.622640\n",
      "batch size: 1024, fold: 1| Epoch 52: Train_accuracy: 79.87%, Train_loss: 0.505890, Test_accuracy: 67.36%, Test_loss: 0.622797\n",
      "batch size: 1024, fold: 1| Epoch 53: Train_accuracy: 79.57%, Train_loss: 0.507381, Test_accuracy: 69.08%, Test_loss: 0.604319\n",
      "batch size: 1024, fold: 1| Epoch 54: Train_accuracy: 79.78%, Train_loss: 0.505475, Test_accuracy: 65.46%, Test_loss: 0.621713\n",
      "batch size: 1024, fold: 1| Epoch 55: Train_accuracy: 80.46%, Train_loss: 0.501671, Test_accuracy: 68.90%, Test_loss: 0.604621\n",
      "batch size: 1024, fold: 1| Epoch 56: Train_accuracy: 81.48%, Train_loss: 0.495593, Test_accuracy: 68.90%, Test_loss: 0.607099\n",
      "batch size: 1024, fold: 1| Epoch 57: Train_accuracy: 81.37%, Train_loss: 0.493974, Test_accuracy: 67.30%, Test_loss: 0.613354\n",
      "batch size: 1024, fold: 1| Epoch 58: Train_accuracy: 80.97%, Train_loss: 0.495652, Test_accuracy: 67.06%, Test_loss: 0.614992\n",
      "batch size: 1024, fold: 1| Epoch 59: Train_accuracy: 80.60%, Train_loss: 0.499541, Test_accuracy: 67.12%, Test_loss: 0.614376\n",
      "batch size: 1024, fold: 1| Epoch 60: Train_accuracy: 82.22%, Train_loss: 0.488098, Test_accuracy: 67.36%, Test_loss: 0.614545\n",
      "batch size: 1024, fold: 1| Epoch 61: Train_accuracy: 81.97%, Train_loss: 0.490055, Test_accuracy: 69.37%, Test_loss: 0.605924\n",
      "batch size: 1024, fold: 1| Epoch 62: Train_accuracy: 81.81%, Train_loss: 0.488621, Test_accuracy: 70.26%, Test_loss: 0.589892\n",
      "batch size: 1024, fold: 1| Epoch 63: Train_accuracy: 81.75%, Train_loss: 0.488338, Test_accuracy: 67.48%, Test_loss: 0.610219\n",
      "batch size: 1024, fold: 1| Epoch 64: Train_accuracy: 82.48%, Train_loss: 0.482504, Test_accuracy: 69.02%, Test_loss: 0.598646\n",
      "batch size: 1024, fold: 1| Epoch 65: Train_accuracy: 81.80%, Train_loss: 0.488768, Test_accuracy: 68.54%, Test_loss: 0.609746\n",
      "batch size: 1024, fold: 1| Epoch 66: Train_accuracy: 82.92%, Train_loss: 0.479351, Test_accuracy: 69.55%, Test_loss: 0.609549\n",
      "batch size: 1024, fold: 1| Epoch 67: Train_accuracy: 82.79%, Train_loss: 0.480103, Test_accuracy: 69.08%, Test_loss: 0.598859\n",
      "batch size: 1024, fold: 1| Epoch 68: Train_accuracy: 83.38%, Train_loss: 0.474049, Test_accuracy: 68.19%, Test_loss: 0.606649\n",
      "batch size: 1024, fold: 1| Epoch 69: Train_accuracy: 83.47%, Train_loss: 0.476556, Test_accuracy: 68.60%, Test_loss: 0.609697\n",
      "batch size: 1024, fold: 1| Epoch 70: Train_accuracy: 82.65%, Train_loss: 0.481234, Test_accuracy: 69.61%, Test_loss: 0.602765\n",
      "batch size: 1024, fold: 1| Epoch 71: Train_accuracy: 83.29%, Train_loss: 0.476296, Test_accuracy: 69.55%, Test_loss: 0.595769\n",
      "batch size: 1024, fold: 1| Epoch 72: Train_accuracy: 83.38%, Train_loss: 0.476117, Test_accuracy: 70.32%, Test_loss: 0.597389\n",
      "batch size: 1024, fold: 1| Epoch 73: Train_accuracy: 83.50%, Train_loss: 0.474116, Test_accuracy: 68.60%, Test_loss: 0.598942\n",
      "batch size: 1024, fold: 1| Epoch 74: Train_accuracy: 83.19%, Train_loss: 0.475360, Test_accuracy: 69.67%, Test_loss: 0.597658\n",
      "batch size: 1024, fold: 1| Epoch 75: Train_accuracy: 83.22%, Train_loss: 0.476525, Test_accuracy: 68.48%, Test_loss: 0.608396\n",
      "batch size: 1024, fold: 1| Epoch 76: Train_accuracy: 83.59%, Train_loss: 0.474208, Test_accuracy: 69.37%, Test_loss: 0.603274\n",
      "batch size: 1024, fold: 1| Epoch 77: Train_accuracy: 84.28%, Train_loss: 0.465947, Test_accuracy: 69.85%, Test_loss: 0.601782\n",
      "batch size: 1024, fold: 1| Epoch 78: Train_accuracy: 83.65%, Train_loss: 0.471172, Test_accuracy: 69.55%, Test_loss: 0.598940\n",
      "batch size: 1024, fold: 1| Epoch 79: Train_accuracy: 83.96%, Train_loss: 0.466766, Test_accuracy: 70.44%, Test_loss: 0.591382\n",
      "batch size: 1024, fold: 1| Epoch 80: Train_accuracy: 84.05%, Train_loss: 0.466151, Test_accuracy: 69.43%, Test_loss: 0.603550\n",
      "batch size: 1024, fold: 1| Epoch 81: Train_accuracy: 84.19%, Train_loss: 0.468282, Test_accuracy: 68.84%, Test_loss: 0.603619\n",
      "batch size: 1024, fold: 1| Epoch 82: Train_accuracy: 84.43%, Train_loss: 0.464969, Test_accuracy: 70.26%, Test_loss: 0.593463\n",
      "batch size: 1024, fold: 1| Epoch 83: Train_accuracy: 84.68%, Train_loss: 0.462183, Test_accuracy: 69.19%, Test_loss: 0.599912\n",
      "batch size: 1024, fold: 1| Epoch 84: Train_accuracy: 84.61%, Train_loss: 0.460524, Test_accuracy: 69.08%, Test_loss: 0.599016\n",
      "batch size: 1024, fold: 1| Epoch 85: Train_accuracy: 84.94%, Train_loss: 0.461190, Test_accuracy: 70.91%, Test_loss: 0.592161\n",
      "batch size: 1024, fold: 1| Epoch 86: Train_accuracy: 85.25%, Train_loss: 0.458642, Test_accuracy: 69.43%, Test_loss: 0.600111\n",
      "batch size: 1024, fold: 1| Epoch 87: Train_accuracy: 84.92%, Train_loss: 0.460154, Test_accuracy: 71.27%, Test_loss: 0.578676\n",
      "batch size: 1024, fold: 1| Epoch 88: Train_accuracy: 85.50%, Train_loss: 0.455739, Test_accuracy: 70.73%, Test_loss: 0.590668\n",
      "batch size: 1024, fold: 1| Epoch 89: Train_accuracy: 86.06%, Train_loss: 0.450965, Test_accuracy: 71.39%, Test_loss: 0.583268\n",
      "batch size: 1024, fold: 1| Epoch 90: Train_accuracy: 85.47%, Train_loss: 0.452756, Test_accuracy: 70.73%, Test_loss: 0.592283\n",
      "batch size: 1024, fold: 1| Epoch 91: Train_accuracy: 85.42%, Train_loss: 0.456303, Test_accuracy: 70.85%, Test_loss: 0.597418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1024, fold: 1| Epoch 92: Train_accuracy: 85.44%, Train_loss: 0.453391, Test_accuracy: 69.67%, Test_loss: 0.598852\n",
      "batch size: 1024, fold: 1| Epoch 93: Train_accuracy: 85.35%, Train_loss: 0.454411, Test_accuracy: 70.44%, Test_loss: 0.588073\n",
      "batch size: 1024, fold: 1| Epoch 94: Train_accuracy: 86.39%, Train_loss: 0.448388, Test_accuracy: 70.38%, Test_loss: 0.592929\n",
      "batch size: 1024, fold: 1| Epoch 95: Train_accuracy: 85.75%, Train_loss: 0.449753, Test_accuracy: 70.20%, Test_loss: 0.588634\n",
      "batch size: 1024, fold: 1| Epoch 96: Train_accuracy: 85.93%, Train_loss: 0.450805, Test_accuracy: 70.68%, Test_loss: 0.587709\n",
      "batch size: 1024, fold: 1| Epoch 97: Train_accuracy: 86.70%, Train_loss: 0.443621, Test_accuracy: 71.27%, Test_loss: 0.583997\n",
      "batch size: 1024, fold: 1| Epoch 98: Train_accuracy: 86.19%, Train_loss: 0.448878, Test_accuracy: 70.26%, Test_loss: 0.592126\n",
      "batch size: 1024, fold: 1| Epoch 99: Train_accuracy: 86.33%, Train_loss: 0.444385, Test_accuracy: 69.67%, Test_loss: 0.594275\n",
      "batch size: 1024, fold: 1| Epoch 100: Train_accuracy: 86.31%, Train_loss: 0.445153, Test_accuracy: 70.14%, Test_loss: 0.590258\n",
      "batch size: 1024, fold: 2| Epoch 1: Train_accuracy: 51.67%, Train_loss: 0.692159, Test_accuracy: 50.59%, Test_loss: 0.691620\n",
      "batch size: 1024, fold: 2| Epoch 2: Train_accuracy: 53.16%, Train_loss: 0.688827, Test_accuracy: 54.15%, Test_loss: 0.687987\n",
      "batch size: 1024, fold: 2| Epoch 3: Train_accuracy: 56.54%, Train_loss: 0.683970, Test_accuracy: 55.92%, Test_loss: 0.686410\n",
      "batch size: 1024, fold: 2| Epoch 4: Train_accuracy: 57.38%, Train_loss: 0.678892, Test_accuracy: 55.98%, Test_loss: 0.679856\n",
      "batch size: 1024, fold: 2| Epoch 5: Train_accuracy: 58.69%, Train_loss: 0.672983, Test_accuracy: 57.23%, Test_loss: 0.677714\n",
      "batch size: 1024, fold: 2| Epoch 6: Train_accuracy: 59.52%, Train_loss: 0.666002, Test_accuracy: 58.59%, Test_loss: 0.676529\n",
      "batch size: 1024, fold: 2| Epoch 7: Train_accuracy: 59.98%, Train_loss: 0.659581, Test_accuracy: 59.18%, Test_loss: 0.672182\n",
      "batch size: 1024, fold: 2| Epoch 8: Train_accuracy: 61.83%, Train_loss: 0.653826, Test_accuracy: 58.83%, Test_loss: 0.668599\n",
      "batch size: 1024, fold: 2| Epoch 9: Train_accuracy: 63.12%, Train_loss: 0.646580, Test_accuracy: 58.95%, Test_loss: 0.670917\n",
      "batch size: 1024, fold: 2| Epoch 10: Train_accuracy: 64.39%, Train_loss: 0.641238, Test_accuracy: 56.75%, Test_loss: 0.673960\n",
      "batch size: 1024, fold: 2| Epoch 11: Train_accuracy: 65.50%, Train_loss: 0.631882, Test_accuracy: 60.19%, Test_loss: 0.669650\n",
      "batch size: 1024, fold: 2| Epoch 12: Train_accuracy: 65.96%, Train_loss: 0.628344, Test_accuracy: 59.66%, Test_loss: 0.666461\n",
      "batch size: 1024, fold: 2| Epoch 13: Train_accuracy: 66.21%, Train_loss: 0.622306, Test_accuracy: 60.66%, Test_loss: 0.662239\n",
      "batch size: 1024, fold: 2| Epoch 14: Train_accuracy: 66.60%, Train_loss: 0.620982, Test_accuracy: 60.66%, Test_loss: 0.663788\n",
      "batch size: 1024, fold: 2| Epoch 15: Train_accuracy: 66.97%, Train_loss: 0.616044, Test_accuracy: 60.49%, Test_loss: 0.662685\n",
      "batch size: 1024, fold: 2| Epoch 16: Train_accuracy: 68.42%, Train_loss: 0.609426, Test_accuracy: 61.61%, Test_loss: 0.658645\n",
      "batch size: 1024, fold: 2| Epoch 17: Train_accuracy: 68.73%, Train_loss: 0.605929, Test_accuracy: 61.37%, Test_loss: 0.656878\n",
      "batch size: 1024, fold: 2| Epoch 18: Train_accuracy: 69.06%, Train_loss: 0.602973, Test_accuracy: 62.03%, Test_loss: 0.655913\n",
      "batch size: 1024, fold: 2| Epoch 19: Train_accuracy: 69.06%, Train_loss: 0.603895, Test_accuracy: 62.80%, Test_loss: 0.646997\n",
      "batch size: 1024, fold: 2| Epoch 20: Train_accuracy: 70.49%, Train_loss: 0.593047, Test_accuracy: 62.97%, Test_loss: 0.648765\n",
      "batch size: 1024, fold: 2| Epoch 21: Train_accuracy: 69.86%, Train_loss: 0.592746, Test_accuracy: 63.27%, Test_loss: 0.637536\n",
      "batch size: 1024, fold: 2| Epoch 22: Train_accuracy: 71.44%, Train_loss: 0.584013, Test_accuracy: 63.15%, Test_loss: 0.644349\n",
      "batch size: 1024, fold: 2| Epoch 23: Train_accuracy: 70.73%, Train_loss: 0.587314, Test_accuracy: 63.27%, Test_loss: 0.643843\n",
      "batch size: 1024, fold: 2| Epoch 24: Train_accuracy: 71.15%, Train_loss: 0.584155, Test_accuracy: 63.03%, Test_loss: 0.649520\n",
      "batch size: 1024, fold: 2| Epoch 25: Train_accuracy: 71.60%, Train_loss: 0.580985, Test_accuracy: 63.39%, Test_loss: 0.643814\n",
      "batch size: 1024, fold: 2| Epoch 26: Train_accuracy: 72.30%, Train_loss: 0.572876, Test_accuracy: 62.74%, Test_loss: 0.645434\n",
      "batch size: 1024, fold: 2| Epoch 27: Train_accuracy: 72.89%, Train_loss: 0.571245, Test_accuracy: 65.58%, Test_loss: 0.631665\n",
      "batch size: 1024, fold: 2| Epoch 28: Train_accuracy: 72.60%, Train_loss: 0.571794, Test_accuracy: 63.27%, Test_loss: 0.638941\n",
      "batch size: 1024, fold: 2| Epoch 29: Train_accuracy: 73.28%, Train_loss: 0.565546, Test_accuracy: 64.45%, Test_loss: 0.636736\n",
      "batch size: 1024, fold: 2| Epoch 30: Train_accuracy: 73.68%, Train_loss: 0.562830, Test_accuracy: 63.45%, Test_loss: 0.643734\n",
      "batch size: 1024, fold: 2| Epoch 31: Train_accuracy: 73.49%, Train_loss: 0.562948, Test_accuracy: 64.40%, Test_loss: 0.635507\n",
      "batch size: 1024, fold: 2| Epoch 32: Train_accuracy: 73.59%, Train_loss: 0.563028, Test_accuracy: 63.39%, Test_loss: 0.646486\n",
      "batch size: 1024, fold: 2| Epoch 33: Train_accuracy: 73.94%, Train_loss: 0.559457, Test_accuracy: 66.88%, Test_loss: 0.624506\n",
      "batch size: 1024, fold: 2| Epoch 34: Train_accuracy: 75.11%, Train_loss: 0.549592, Test_accuracy: 64.57%, Test_loss: 0.635653\n",
      "batch size: 1024, fold: 2| Epoch 35: Train_accuracy: 75.20%, Train_loss: 0.549233, Test_accuracy: 64.28%, Test_loss: 0.637748\n",
      "batch size: 1024, fold: 2| Epoch 36: Train_accuracy: 75.16%, Train_loss: 0.549922, Test_accuracy: 65.64%, Test_loss: 0.624656\n",
      "batch size: 1024, fold: 2| Epoch 37: Train_accuracy: 75.86%, Train_loss: 0.540886, Test_accuracy: 65.58%, Test_loss: 0.625704\n",
      "batch size: 1024, fold: 2| Epoch 38: Train_accuracy: 75.84%, Train_loss: 0.545034, Test_accuracy: 66.94%, Test_loss: 0.618980\n",
      "batch size: 1024, fold: 2| Epoch 39: Train_accuracy: 76.23%, Train_loss: 0.539844, Test_accuracy: 66.00%, Test_loss: 0.624471\n",
      "batch size: 1024, fold: 2| Epoch 40: Train_accuracy: 76.36%, Train_loss: 0.536275, Test_accuracy: 67.24%, Test_loss: 0.618626\n",
      "batch size: 1024, fold: 2| Epoch 41: Train_accuracy: 76.55%, Train_loss: 0.536752, Test_accuracy: 66.41%, Test_loss: 0.616243\n",
      "batch size: 1024, fold: 2| Epoch 42: Train_accuracy: 77.87%, Train_loss: 0.528226, Test_accuracy: 65.76%, Test_loss: 0.629280\n",
      "batch size: 1024, fold: 2| Epoch 43: Train_accuracy: 77.53%, Train_loss: 0.528975, Test_accuracy: 67.36%, Test_loss: 0.618075\n",
      "batch size: 1024, fold: 2| Epoch 44: Train_accuracy: 77.31%, Train_loss: 0.530213, Test_accuracy: 67.42%, Test_loss: 0.610240\n",
      "batch size: 1024, fold: 2| Epoch 45: Train_accuracy: 77.31%, Train_loss: 0.528917, Test_accuracy: 66.53%, Test_loss: 0.617194\n",
      "batch size: 1024, fold: 2| Epoch 46: Train_accuracy: 77.54%, Train_loss: 0.527782, Test_accuracy: 67.59%, Test_loss: 0.611746\n",
      "batch size: 1024, fold: 2| Epoch 47: Train_accuracy: 78.45%, Train_loss: 0.521859, Test_accuracy: 68.07%, Test_loss: 0.606862\n",
      "batch size: 1024, fold: 2| Epoch 48: Train_accuracy: 78.34%, Train_loss: 0.520962, Test_accuracy: 65.58%, Test_loss: 0.628070\n",
      "batch size: 1024, fold: 2| Epoch 49: Train_accuracy: 78.11%, Train_loss: 0.522513, Test_accuracy: 67.42%, Test_loss: 0.613025\n",
      "batch size: 1024, fold: 2| Epoch 50: Train_accuracy: 78.89%, Train_loss: 0.517286, Test_accuracy: 68.07%, Test_loss: 0.611980\n",
      "batch size: 1024, fold: 2| Epoch 51: Train_accuracy: 79.16%, Train_loss: 0.515685, Test_accuracy: 67.54%, Test_loss: 0.620384\n",
      "batch size: 1024, fold: 2| Epoch 52: Train_accuracy: 79.53%, Train_loss: 0.512900, Test_accuracy: 66.71%, Test_loss: 0.619554\n",
      "batch size: 1024, fold: 2| Epoch 53: Train_accuracy: 78.77%, Train_loss: 0.517079, Test_accuracy: 68.13%, Test_loss: 0.603018\n",
      "batch size: 1024, fold: 2| Epoch 54: Train_accuracy: 80.05%, Train_loss: 0.508979, Test_accuracy: 67.71%, Test_loss: 0.613443\n",
      "batch size: 1024, fold: 2| Epoch 55: Train_accuracy: 80.20%, Train_loss: 0.504717, Test_accuracy: 68.07%, Test_loss: 0.611573\n",
      "batch size: 1024, fold: 2| Epoch 56: Train_accuracy: 80.14%, Train_loss: 0.506102, Test_accuracy: 67.00%, Test_loss: 0.612200\n",
      "batch size: 1024, fold: 2| Epoch 57: Train_accuracy: 81.28%, Train_loss: 0.497580, Test_accuracy: 67.89%, Test_loss: 0.607959\n",
      "batch size: 1024, fold: 2| Epoch 58: Train_accuracy: 80.63%, Train_loss: 0.500934, Test_accuracy: 66.94%, Test_loss: 0.624999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1024, fold: 2| Epoch 59: Train_accuracy: 80.30%, Train_loss: 0.503241, Test_accuracy: 68.48%, Test_loss: 0.602382\n",
      "batch size: 1024, fold: 2| Epoch 60: Train_accuracy: 81.25%, Train_loss: 0.494983, Test_accuracy: 68.36%, Test_loss: 0.606543\n",
      "batch size: 1024, fold: 2| Epoch 61: Train_accuracy: 81.20%, Train_loss: 0.493935, Test_accuracy: 68.19%, Test_loss: 0.605599\n",
      "batch size: 1024, fold: 2| Epoch 62: Train_accuracy: 81.11%, Train_loss: 0.496727, Test_accuracy: 68.60%, Test_loss: 0.608575\n",
      "batch size: 1024, fold: 2| Epoch 63: Train_accuracy: 81.35%, Train_loss: 0.493670, Test_accuracy: 68.19%, Test_loss: 0.606819\n",
      "batch size: 1024, fold: 2| Epoch 64: Train_accuracy: 81.65%, Train_loss: 0.490296, Test_accuracy: 68.07%, Test_loss: 0.611856\n",
      "batch size: 1024, fold: 2| Epoch 65: Train_accuracy: 81.80%, Train_loss: 0.491351, Test_accuracy: 67.83%, Test_loss: 0.602779\n",
      "batch size: 1024, fold: 2| Epoch 66: Train_accuracy: 81.42%, Train_loss: 0.491083, Test_accuracy: 68.60%, Test_loss: 0.603248\n",
      "batch size: 1024, fold: 2| Epoch 67: Train_accuracy: 82.31%, Train_loss: 0.484033, Test_accuracy: 68.84%, Test_loss: 0.607598\n",
      "batch size: 1024, fold: 2| Epoch 68: Train_accuracy: 82.79%, Train_loss: 0.482062, Test_accuracy: 68.31%, Test_loss: 0.602716\n",
      "batch size: 1024, fold: 2| Epoch 69: Train_accuracy: 82.48%, Train_loss: 0.483662, Test_accuracy: 68.36%, Test_loss: 0.603348\n",
      "batch size: 1024, fold: 2| Epoch 70: Train_accuracy: 82.68%, Train_loss: 0.479414, Test_accuracy: 69.55%, Test_loss: 0.599144\n",
      "batch size: 1024, fold: 2| Epoch 71: Train_accuracy: 82.71%, Train_loss: 0.480448, Test_accuracy: 68.84%, Test_loss: 0.605459\n",
      "batch size: 1024, fold: 2| Epoch 72: Train_accuracy: 82.97%, Train_loss: 0.478786, Test_accuracy: 69.19%, Test_loss: 0.594004\n",
      "batch size: 1024, fold: 2| Epoch 73: Train_accuracy: 83.59%, Train_loss: 0.472515, Test_accuracy: 69.08%, Test_loss: 0.603649\n",
      "batch size: 1024, fold: 2| Epoch 74: Train_accuracy: 83.51%, Train_loss: 0.473636, Test_accuracy: 69.61%, Test_loss: 0.600253\n",
      "batch size: 1024, fold: 2| Epoch 75: Train_accuracy: 83.62%, Train_loss: 0.474665, Test_accuracy: 70.20%, Test_loss: 0.595019\n",
      "batch size: 1024, fold: 2| Epoch 76: Train_accuracy: 82.97%, Train_loss: 0.476531, Test_accuracy: 71.15%, Test_loss: 0.586246\n",
      "batch size: 1024, fold: 2| Epoch 77: Train_accuracy: 83.26%, Train_loss: 0.475330, Test_accuracy: 69.85%, Test_loss: 0.592496\n",
      "batch size: 1024, fold: 2| Epoch 78: Train_accuracy: 83.90%, Train_loss: 0.468889, Test_accuracy: 69.85%, Test_loss: 0.593571\n",
      "batch size: 1024, fold: 2| Epoch 79: Train_accuracy: 83.94%, Train_loss: 0.469511, Test_accuracy: 70.50%, Test_loss: 0.591211\n",
      "batch size: 1024, fold: 2| Epoch 80: Train_accuracy: 83.35%, Train_loss: 0.473212, Test_accuracy: 69.08%, Test_loss: 0.598746\n",
      "batch size: 1024, fold: 2| Epoch 81: Train_accuracy: 83.44%, Train_loss: 0.471828, Test_accuracy: 69.37%, Test_loss: 0.589193\n",
      "batch size: 1024, fold: 2| Epoch 82: Train_accuracy: 83.79%, Train_loss: 0.471066, Test_accuracy: 70.85%, Test_loss: 0.593224\n",
      "batch size: 1024, fold: 2| Epoch 83: Train_accuracy: 84.19%, Train_loss: 0.465522, Test_accuracy: 68.54%, Test_loss: 0.601090\n",
      "batch size: 1024, fold: 2| Epoch 84: Train_accuracy: 84.22%, Train_loss: 0.464023, Test_accuracy: 69.79%, Test_loss: 0.594097\n",
      "batch size: 1024, fold: 2| Epoch 85: Train_accuracy: 84.62%, Train_loss: 0.462459, Test_accuracy: 68.42%, Test_loss: 0.601709\n",
      "batch size: 1024, fold: 2| Epoch 86: Train_accuracy: 85.37%, Train_loss: 0.455735, Test_accuracy: 71.03%, Test_loss: 0.582618\n",
      "batch size: 1024, fold: 2| Epoch 87: Train_accuracy: 84.67%, Train_loss: 0.464051, Test_accuracy: 69.85%, Test_loss: 0.596027\n",
      "batch size: 1024, fold: 2| Epoch 88: Train_accuracy: 84.82%, Train_loss: 0.459464, Test_accuracy: 69.49%, Test_loss: 0.597737\n",
      "batch size: 1024, fold: 2| Epoch 89: Train_accuracy: 85.02%, Train_loss: 0.460846, Test_accuracy: 69.67%, Test_loss: 0.595087\n",
      "batch size: 1024, fold: 2| Epoch 90: Train_accuracy: 84.74%, Train_loss: 0.460775, Test_accuracy: 70.14%, Test_loss: 0.593605\n",
      "batch size: 1024, fold: 2| Epoch 91: Train_accuracy: 85.20%, Train_loss: 0.457174, Test_accuracy: 70.20%, Test_loss: 0.595614\n",
      "batch size: 1024, fold: 2| Epoch 92: Train_accuracy: 85.32%, Train_loss: 0.459095, Test_accuracy: 70.73%, Test_loss: 0.587623\n",
      "batch size: 1024, fold: 2| Epoch 93: Train_accuracy: 85.84%, Train_loss: 0.454766, Test_accuracy: 69.55%, Test_loss: 0.598603\n",
      "batch size: 1024, fold: 2| Epoch 94: Train_accuracy: 84.59%, Train_loss: 0.458769, Test_accuracy: 70.85%, Test_loss: 0.580576\n",
      "batch size: 1024, fold: 2| Epoch 95: Train_accuracy: 84.92%, Train_loss: 0.461773, Test_accuracy: 71.39%, Test_loss: 0.585525\n",
      "batch size: 1024, fold: 2| Epoch 96: Train_accuracy: 85.77%, Train_loss: 0.452593, Test_accuracy: 70.32%, Test_loss: 0.589083\n",
      "batch size: 1024, fold: 2| Epoch 97: Train_accuracy: 85.51%, Train_loss: 0.452770, Test_accuracy: 71.39%, Test_loss: 0.589079\n",
      "batch size: 1024, fold: 2| Epoch 98: Train_accuracy: 85.41%, Train_loss: 0.452319, Test_accuracy: 70.68%, Test_loss: 0.582390\n",
      "batch size: 1024, fold: 2| Epoch 99: Train_accuracy: 85.25%, Train_loss: 0.456396, Test_accuracy: 71.33%, Test_loss: 0.583253\n",
      "batch size: 1024, fold: 2| Epoch 100: Train_accuracy: 85.68%, Train_loss: 0.452013, Test_accuracy: 69.43%, Test_loss: 0.598753\n",
      "batch size: 1024, fold: 3| Epoch 1: Train_accuracy: 51.37%, Train_loss: 0.692118, Test_accuracy: 52.25%, Test_loss: 0.690851\n",
      "batch size: 1024, fold: 3| Epoch 2: Train_accuracy: 53.70%, Train_loss: 0.688835, Test_accuracy: 54.68%, Test_loss: 0.686727\n",
      "batch size: 1024, fold: 3| Epoch 3: Train_accuracy: 56.55%, Train_loss: 0.684995, Test_accuracy: 57.41%, Test_loss: 0.682446\n",
      "batch size: 1024, fold: 3| Epoch 4: Train_accuracy: 58.17%, Train_loss: 0.678426, Test_accuracy: 57.46%, Test_loss: 0.676877\n",
      "batch size: 1024, fold: 3| Epoch 5: Train_accuracy: 58.70%, Train_loss: 0.671800, Test_accuracy: 56.87%, Test_loss: 0.679992\n",
      "batch size: 1024, fold: 3| Epoch 6: Train_accuracy: 59.98%, Train_loss: 0.664856, Test_accuracy: 57.58%, Test_loss: 0.676621\n",
      "batch size: 1024, fold: 3| Epoch 7: Train_accuracy: 61.64%, Train_loss: 0.656925, Test_accuracy: 58.77%, Test_loss: 0.676633\n",
      "batch size: 1024, fold: 3| Epoch 8: Train_accuracy: 62.46%, Train_loss: 0.652740, Test_accuracy: 59.18%, Test_loss: 0.666013\n",
      "batch size: 1024, fold: 3| Epoch 9: Train_accuracy: 63.10%, Train_loss: 0.646189, Test_accuracy: 61.55%, Test_loss: 0.663797\n",
      "batch size: 1024, fold: 3| Epoch 10: Train_accuracy: 63.46%, Train_loss: 0.640824, Test_accuracy: 60.13%, Test_loss: 0.659461\n",
      "batch size: 1024, fold: 3| Epoch 11: Train_accuracy: 64.76%, Train_loss: 0.634457, Test_accuracy: 59.42%, Test_loss: 0.667923\n",
      "batch size: 1024, fold: 3| Epoch 12: Train_accuracy: 65.50%, Train_loss: 0.627914, Test_accuracy: 60.84%, Test_loss: 0.659985\n",
      "batch size: 1024, fold: 3| Epoch 13: Train_accuracy: 66.46%, Train_loss: 0.622900, Test_accuracy: 61.08%, Test_loss: 0.657075\n",
      "batch size: 1024, fold: 3| Epoch 14: Train_accuracy: 66.38%, Train_loss: 0.623401, Test_accuracy: 59.89%, Test_loss: 0.672186\n",
      "batch size: 1024, fold: 3| Epoch 15: Train_accuracy: 67.15%, Train_loss: 0.620916, Test_accuracy: 61.26%, Test_loss: 0.662348\n",
      "batch size: 1024, fold: 3| Epoch 16: Train_accuracy: 67.78%, Train_loss: 0.611584, Test_accuracy: 59.42%, Test_loss: 0.670270\n",
      "batch size: 1024, fold: 3| Epoch 17: Train_accuracy: 68.05%, Train_loss: 0.606359, Test_accuracy: 61.85%, Test_loss: 0.656527\n",
      "batch size: 1024, fold: 3| Epoch 18: Train_accuracy: 68.35%, Train_loss: 0.606016, Test_accuracy: 61.73%, Test_loss: 0.652019\n",
      "batch size: 1024, fold: 3| Epoch 19: Train_accuracy: 69.15%, Train_loss: 0.598453, Test_accuracy: 62.14%, Test_loss: 0.651819\n",
      "batch size: 1024, fold: 3| Epoch 20: Train_accuracy: 69.93%, Train_loss: 0.594307, Test_accuracy: 61.43%, Test_loss: 0.658575\n",
      "batch size: 1024, fold: 3| Epoch 21: Train_accuracy: 70.15%, Train_loss: 0.595196, Test_accuracy: 62.44%, Test_loss: 0.662468\n",
      "batch size: 1024, fold: 3| Epoch 22: Train_accuracy: 70.73%, Train_loss: 0.592380, Test_accuracy: 63.27%, Test_loss: 0.648485\n",
      "batch size: 1024, fold: 3| Epoch 23: Train_accuracy: 70.75%, Train_loss: 0.584433, Test_accuracy: 61.26%, Test_loss: 0.658635\n",
      "batch size: 1024, fold: 3| Epoch 24: Train_accuracy: 71.84%, Train_loss: 0.581591, Test_accuracy: 63.74%, Test_loss: 0.642221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1024, fold: 3| Epoch 25: Train_accuracy: 71.62%, Train_loss: 0.577930, Test_accuracy: 63.74%, Test_loss: 0.646716\n",
      "batch size: 1024, fold: 3| Epoch 26: Train_accuracy: 72.88%, Train_loss: 0.573200, Test_accuracy: 64.40%, Test_loss: 0.642784\n",
      "batch size: 1024, fold: 3| Epoch 27: Train_accuracy: 73.25%, Train_loss: 0.570895, Test_accuracy: 63.98%, Test_loss: 0.651444\n",
      "batch size: 1024, fold: 3| Epoch 28: Train_accuracy: 73.16%, Train_loss: 0.567587, Test_accuracy: 64.63%, Test_loss: 0.641333\n",
      "batch size: 1024, fold: 3| Epoch 29: Train_accuracy: 73.97%, Train_loss: 0.564503, Test_accuracy: 63.09%, Test_loss: 0.650514\n",
      "batch size: 1024, fold: 3| Epoch 30: Train_accuracy: 73.75%, Train_loss: 0.563382, Test_accuracy: 64.28%, Test_loss: 0.641891\n",
      "batch size: 1024, fold: 3| Epoch 31: Train_accuracy: 73.94%, Train_loss: 0.563487, Test_accuracy: 65.11%, Test_loss: 0.633599\n",
      "batch size: 1024, fold: 3| Epoch 32: Train_accuracy: 74.89%, Train_loss: 0.552524, Test_accuracy: 63.80%, Test_loss: 0.643620\n",
      "batch size: 1024, fold: 3| Epoch 33: Train_accuracy: 74.09%, Train_loss: 0.555696, Test_accuracy: 66.23%, Test_loss: 0.623273\n",
      "batch size: 1024, fold: 3| Epoch 34: Train_accuracy: 75.06%, Train_loss: 0.553948, Test_accuracy: 65.76%, Test_loss: 0.626924\n",
      "batch size: 1024, fold: 3| Epoch 35: Train_accuracy: 75.54%, Train_loss: 0.545641, Test_accuracy: 66.00%, Test_loss: 0.628765\n",
      "batch size: 1024, fold: 3| Epoch 36: Train_accuracy: 75.89%, Train_loss: 0.544857, Test_accuracy: 65.70%, Test_loss: 0.632794\n",
      "batch size: 1024, fold: 3| Epoch 37: Train_accuracy: 75.69%, Train_loss: 0.545980, Test_accuracy: 65.23%, Test_loss: 0.637186\n",
      "batch size: 1024, fold: 3| Epoch 38: Train_accuracy: 75.63%, Train_loss: 0.545840, Test_accuracy: 64.51%, Test_loss: 0.642976\n",
      "batch size: 1024, fold: 3| Epoch 39: Train_accuracy: 75.57%, Train_loss: 0.543189, Test_accuracy: 64.75%, Test_loss: 0.637429\n",
      "batch size: 1024, fold: 3| Epoch 40: Train_accuracy: 76.39%, Train_loss: 0.539577, Test_accuracy: 64.81%, Test_loss: 0.639083\n",
      "batch size: 1024, fold: 3| Epoch 41: Train_accuracy: 77.03%, Train_loss: 0.533570, Test_accuracy: 65.05%, Test_loss: 0.635219\n",
      "batch size: 1024, fold: 3| Epoch 42: Train_accuracy: 77.37%, Train_loss: 0.531689, Test_accuracy: 65.52%, Test_loss: 0.624662\n",
      "batch size: 1024, fold: 3| Epoch 43: Train_accuracy: 76.92%, Train_loss: 0.534692, Test_accuracy: 66.94%, Test_loss: 0.623537\n",
      "batch size: 1024, fold: 3| Epoch 44: Train_accuracy: 77.86%, Train_loss: 0.526582, Test_accuracy: 66.35%, Test_loss: 0.621667\n",
      "batch size: 1024, fold: 3| Epoch 45: Train_accuracy: 78.46%, Train_loss: 0.523335, Test_accuracy: 66.53%, Test_loss: 0.622698\n",
      "batch size: 1024, fold: 3| Epoch 46: Train_accuracy: 77.74%, Train_loss: 0.524481, Test_accuracy: 65.64%, Test_loss: 0.633346\n",
      "batch size: 1024, fold: 3| Epoch 47: Train_accuracy: 78.61%, Train_loss: 0.522930, Test_accuracy: 67.12%, Test_loss: 0.619556\n",
      "batch size: 1024, fold: 3| Epoch 48: Train_accuracy: 78.94%, Train_loss: 0.517006, Test_accuracy: 67.71%, Test_loss: 0.615425\n",
      "batch size: 1024, fold: 3| Epoch 49: Train_accuracy: 78.60%, Train_loss: 0.519718, Test_accuracy: 66.94%, Test_loss: 0.617049\n",
      "batch size: 1024, fold: 3| Epoch 50: Train_accuracy: 79.37%, Train_loss: 0.514113, Test_accuracy: 67.12%, Test_loss: 0.619949\n",
      "batch size: 1024, fold: 3| Epoch 51: Train_accuracy: 79.00%, Train_loss: 0.513927, Test_accuracy: 67.89%, Test_loss: 0.616454\n",
      "batch size: 1024, fold: 3| Epoch 52: Train_accuracy: 79.25%, Train_loss: 0.514785, Test_accuracy: 65.23%, Test_loss: 0.632414\n",
      "batch size: 1024, fold: 3| Epoch 53: Train_accuracy: 80.00%, Train_loss: 0.507605, Test_accuracy: 67.54%, Test_loss: 0.617327\n",
      "batch size: 1024, fold: 3| Epoch 54: Train_accuracy: 79.88%, Train_loss: 0.509122, Test_accuracy: 66.65%, Test_loss: 0.624612\n",
      "batch size: 1024, fold: 3| Epoch 55: Train_accuracy: 79.62%, Train_loss: 0.509015, Test_accuracy: 67.77%, Test_loss: 0.613992\n",
      "batch size: 1024, fold: 3| Epoch 56: Train_accuracy: 80.49%, Train_loss: 0.503754, Test_accuracy: 67.24%, Test_loss: 0.616161\n",
      "batch size: 1024, fold: 3| Epoch 57: Train_accuracy: 80.34%, Train_loss: 0.504840, Test_accuracy: 67.42%, Test_loss: 0.613320\n",
      "batch size: 1024, fold: 3| Epoch 58: Train_accuracy: 81.20%, Train_loss: 0.498427, Test_accuracy: 66.71%, Test_loss: 0.618646\n",
      "batch size: 1024, fold: 3| Epoch 59: Train_accuracy: 80.40%, Train_loss: 0.500401, Test_accuracy: 68.19%, Test_loss: 0.611131\n",
      "batch size: 1024, fold: 3| Epoch 60: Train_accuracy: 81.03%, Train_loss: 0.496396, Test_accuracy: 68.60%, Test_loss: 0.607194\n",
      "batch size: 1024, fold: 3| Epoch 61: Train_accuracy: 81.38%, Train_loss: 0.492140, Test_accuracy: 66.82%, Test_loss: 0.619624\n",
      "batch size: 1024, fold: 3| Epoch 62: Train_accuracy: 80.88%, Train_loss: 0.496236, Test_accuracy: 67.30%, Test_loss: 0.616173\n",
      "batch size: 1024, fold: 3| Epoch 63: Train_accuracy: 80.80%, Train_loss: 0.497173, Test_accuracy: 67.65%, Test_loss: 0.610812\n",
      "batch size: 1024, fold: 3| Epoch 64: Train_accuracy: 81.53%, Train_loss: 0.493078, Test_accuracy: 67.12%, Test_loss: 0.620614\n",
      "batch size: 1024, fold: 3| Epoch 65: Train_accuracy: 82.02%, Train_loss: 0.487900, Test_accuracy: 68.96%, Test_loss: 0.606085\n",
      "batch size: 1024, fold: 3| Epoch 66: Train_accuracy: 81.40%, Train_loss: 0.492379, Test_accuracy: 67.30%, Test_loss: 0.617175\n",
      "batch size: 1024, fold: 3| Epoch 67: Train_accuracy: 81.87%, Train_loss: 0.489689, Test_accuracy: 67.83%, Test_loss: 0.613003\n",
      "batch size: 1024, fold: 3| Epoch 68: Train_accuracy: 81.54%, Train_loss: 0.489369, Test_accuracy: 67.24%, Test_loss: 0.616436\n",
      "batch size: 1024, fold: 3| Epoch 69: Train_accuracy: 82.14%, Train_loss: 0.486839, Test_accuracy: 67.12%, Test_loss: 0.618737\n",
      "batch size: 1024, fold: 3| Epoch 70: Train_accuracy: 82.51%, Train_loss: 0.484344, Test_accuracy: 68.48%, Test_loss: 0.608353\n",
      "batch size: 1024, fold: 3| Epoch 71: Train_accuracy: 82.58%, Train_loss: 0.484426, Test_accuracy: 65.46%, Test_loss: 0.630085\n",
      "batch size: 1024, fold: 3| Epoch 72: Train_accuracy: 82.33%, Train_loss: 0.485074, Test_accuracy: 69.19%, Test_loss: 0.610238\n",
      "batch size: 1024, fold: 3| Epoch 73: Train_accuracy: 82.80%, Train_loss: 0.482043, Test_accuracy: 69.25%, Test_loss: 0.606922\n",
      "batch size: 1024, fold: 3| Epoch 74: Train_accuracy: 82.62%, Train_loss: 0.479442, Test_accuracy: 68.36%, Test_loss: 0.613516\n",
      "batch size: 1024, fold: 3| Epoch 75: Train_accuracy: 83.79%, Train_loss: 0.472326, Test_accuracy: 69.31%, Test_loss: 0.606665\n",
      "batch size: 1024, fold: 3| Epoch 76: Train_accuracy: 83.82%, Train_loss: 0.473087, Test_accuracy: 68.42%, Test_loss: 0.611317\n",
      "batch size: 1024, fold: 3| Epoch 77: Train_accuracy: 83.20%, Train_loss: 0.475527, Test_accuracy: 69.61%, Test_loss: 0.600904\n",
      "batch size: 1024, fold: 3| Epoch 78: Train_accuracy: 82.95%, Train_loss: 0.478412, Test_accuracy: 68.48%, Test_loss: 0.608652\n",
      "batch size: 1024, fold: 3| Epoch 79: Train_accuracy: 83.31%, Train_loss: 0.474446, Test_accuracy: 69.49%, Test_loss: 0.599821\n",
      "batch size: 1024, fold: 3| Epoch 80: Train_accuracy: 83.87%, Train_loss: 0.468920, Test_accuracy: 68.31%, Test_loss: 0.609546\n",
      "batch size: 1024, fold: 3| Epoch 81: Train_accuracy: 83.66%, Train_loss: 0.470586, Test_accuracy: 69.08%, Test_loss: 0.599170\n",
      "batch size: 1024, fold: 3| Epoch 82: Train_accuracy: 83.96%, Train_loss: 0.468472, Test_accuracy: 69.55%, Test_loss: 0.598093\n",
      "batch size: 1024, fold: 3| Epoch 83: Train_accuracy: 83.87%, Train_loss: 0.469392, Test_accuracy: 69.02%, Test_loss: 0.600966\n",
      "batch size: 1024, fold: 3| Epoch 84: Train_accuracy: 83.94%, Train_loss: 0.467768, Test_accuracy: 68.07%, Test_loss: 0.615687\n",
      "batch size: 1024, fold: 3| Epoch 85: Train_accuracy: 84.08%, Train_loss: 0.465536, Test_accuracy: 69.43%, Test_loss: 0.607785\n",
      "batch size: 1024, fold: 3| Epoch 86: Train_accuracy: 84.14%, Train_loss: 0.466154, Test_accuracy: 67.18%, Test_loss: 0.615757\n",
      "batch size: 1024, fold: 3| Epoch 87: Train_accuracy: 84.22%, Train_loss: 0.465017, Test_accuracy: 68.31%, Test_loss: 0.605736\n",
      "batch size: 1024, fold: 3| Epoch 88: Train_accuracy: 84.73%, Train_loss: 0.460492, Test_accuracy: 69.14%, Test_loss: 0.601504\n",
      "batch size: 1024, fold: 3| Epoch 89: Train_accuracy: 84.88%, Train_loss: 0.460138, Test_accuracy: 70.44%, Test_loss: 0.593288\n",
      "batch size: 1024, fold: 3| Epoch 90: Train_accuracy: 83.79%, Train_loss: 0.469482, Test_accuracy: 68.66%, Test_loss: 0.612362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1024, fold: 3| Epoch 91: Train_accuracy: 85.22%, Train_loss: 0.459059, Test_accuracy: 68.36%, Test_loss: 0.612192\n",
      "batch size: 1024, fold: 3| Epoch 92: Train_accuracy: 84.65%, Train_loss: 0.461318, Test_accuracy: 67.59%, Test_loss: 0.612343\n",
      "batch size: 1024, fold: 3| Epoch 93: Train_accuracy: 84.74%, Train_loss: 0.460667, Test_accuracy: 68.78%, Test_loss: 0.604835\n",
      "batch size: 1024, fold: 3| Epoch 94: Train_accuracy: 85.19%, Train_loss: 0.455879, Test_accuracy: 68.25%, Test_loss: 0.607084\n",
      "batch size: 1024, fold: 3| Epoch 95: Train_accuracy: 84.61%, Train_loss: 0.462279, Test_accuracy: 69.08%, Test_loss: 0.604055\n",
      "batch size: 1024, fold: 3| Epoch 96: Train_accuracy: 85.66%, Train_loss: 0.454967, Test_accuracy: 67.65%, Test_loss: 0.618875\n",
      "batch size: 1024, fold: 3| Epoch 97: Train_accuracy: 85.22%, Train_loss: 0.455923, Test_accuracy: 67.95%, Test_loss: 0.602286\n",
      "batch size: 1024, fold: 3| Epoch 98: Train_accuracy: 84.92%, Train_loss: 0.457009, Test_accuracy: 67.95%, Test_loss: 0.611729\n",
      "batch size: 1024, fold: 3| Epoch 99: Train_accuracy: 85.71%, Train_loss: 0.451941, Test_accuracy: 69.61%, Test_loss: 0.601154\n",
      "batch size: 1024, fold: 3| Epoch 100: Train_accuracy: 85.39%, Train_loss: 0.453561, Test_accuracy: 68.78%, Test_loss: 0.598825\n",
      "batch size: 1024, fold: 4| Epoch 1: Train_accuracy: 50.14%, Train_loss: 0.693033, Test_accuracy: 53.32%, Test_loss: 0.691808\n",
      "batch size: 1024, fold: 4| Epoch 2: Train_accuracy: 54.27%, Train_loss: 0.689764, Test_accuracy: 53.32%, Test_loss: 0.688530\n",
      "batch size: 1024, fold: 4| Epoch 3: Train_accuracy: 56.01%, Train_loss: 0.684436, Test_accuracy: 55.57%, Test_loss: 0.685707\n",
      "batch size: 1024, fold: 4| Epoch 4: Train_accuracy: 57.30%, Train_loss: 0.680303, Test_accuracy: 56.64%, Test_loss: 0.681326\n",
      "batch size: 1024, fold: 4| Epoch 5: Train_accuracy: 59.19%, Train_loss: 0.672467, Test_accuracy: 57.35%, Test_loss: 0.678689\n",
      "batch size: 1024, fold: 4| Epoch 6: Train_accuracy: 59.65%, Train_loss: 0.665990, Test_accuracy: 58.41%, Test_loss: 0.675464\n",
      "batch size: 1024, fold: 4| Epoch 7: Train_accuracy: 60.95%, Train_loss: 0.659046, Test_accuracy: 58.18%, Test_loss: 0.674854\n",
      "batch size: 1024, fold: 4| Epoch 8: Train_accuracy: 61.56%, Train_loss: 0.655707, Test_accuracy: 59.12%, Test_loss: 0.669598\n",
      "batch size: 1024, fold: 4| Epoch 9: Train_accuracy: 62.33%, Train_loss: 0.648751, Test_accuracy: 59.77%, Test_loss: 0.665249\n",
      "batch size: 1024, fold: 4| Epoch 10: Train_accuracy: 63.77%, Train_loss: 0.642833, Test_accuracy: 60.66%, Test_loss: 0.665076\n",
      "batch size: 1024, fold: 4| Epoch 11: Train_accuracy: 65.06%, Train_loss: 0.633469, Test_accuracy: 60.84%, Test_loss: 0.661056\n",
      "batch size: 1024, fold: 4| Epoch 12: Train_accuracy: 65.46%, Train_loss: 0.630105, Test_accuracy: 59.00%, Test_loss: 0.667066\n",
      "batch size: 1024, fold: 4| Epoch 13: Train_accuracy: 65.75%, Train_loss: 0.627647, Test_accuracy: 60.31%, Test_loss: 0.654129\n",
      "batch size: 1024, fold: 4| Epoch 14: Train_accuracy: 68.12%, Train_loss: 0.615834, Test_accuracy: 60.19%, Test_loss: 0.665830\n",
      "batch size: 1024, fold: 4| Epoch 15: Train_accuracy: 67.60%, Train_loss: 0.611497, Test_accuracy: 62.14%, Test_loss: 0.652066\n",
      "batch size: 1024, fold: 4| Epoch 16: Train_accuracy: 67.89%, Train_loss: 0.612404, Test_accuracy: 61.26%, Test_loss: 0.657963\n",
      "batch size: 1024, fold: 4| Epoch 17: Train_accuracy: 68.58%, Train_loss: 0.605207, Test_accuracy: 62.03%, Test_loss: 0.650088\n",
      "batch size: 1024, fold: 4| Epoch 18: Train_accuracy: 69.46%, Train_loss: 0.599157, Test_accuracy: 63.21%, Test_loss: 0.645663\n",
      "batch size: 1024, fold: 4| Epoch 19: Train_accuracy: 70.76%, Train_loss: 0.590989, Test_accuracy: 63.09%, Test_loss: 0.645077\n",
      "batch size: 1024, fold: 4| Epoch 20: Train_accuracy: 70.57%, Train_loss: 0.590018, Test_accuracy: 63.63%, Test_loss: 0.652444\n",
      "batch size: 1024, fold: 4| Epoch 21: Train_accuracy: 71.40%, Train_loss: 0.586571, Test_accuracy: 62.38%, Test_loss: 0.649942\n",
      "batch size: 1024, fold: 4| Epoch 22: Train_accuracy: 71.80%, Train_loss: 0.579865, Test_accuracy: 62.86%, Test_loss: 0.651875\n",
      "batch size: 1024, fold: 4| Epoch 23: Train_accuracy: 72.05%, Train_loss: 0.574376, Test_accuracy: 64.04%, Test_loss: 0.640540\n",
      "batch size: 1024, fold: 4| Epoch 24: Train_accuracy: 72.69%, Train_loss: 0.571780, Test_accuracy: 62.50%, Test_loss: 0.647540\n",
      "batch size: 1024, fold: 4| Epoch 25: Train_accuracy: 72.76%, Train_loss: 0.568663, Test_accuracy: 64.34%, Test_loss: 0.642335\n",
      "batch size: 1024, fold: 4| Epoch 26: Train_accuracy: 73.53%, Train_loss: 0.565674, Test_accuracy: 64.04%, Test_loss: 0.638971\n",
      "batch size: 1024, fold: 4| Epoch 27: Train_accuracy: 74.66%, Train_loss: 0.556587, Test_accuracy: 65.05%, Test_loss: 0.634931\n",
      "batch size: 1024, fold: 4| Epoch 28: Train_accuracy: 74.85%, Train_loss: 0.557079, Test_accuracy: 64.28%, Test_loss: 0.643084\n",
      "batch size: 1024, fold: 4| Epoch 29: Train_accuracy: 74.73%, Train_loss: 0.555244, Test_accuracy: 64.10%, Test_loss: 0.646556\n",
      "batch size: 1024, fold: 4| Epoch 30: Train_accuracy: 75.20%, Train_loss: 0.551275, Test_accuracy: 64.81%, Test_loss: 0.638891\n",
      "batch size: 1024, fold: 4| Epoch 31: Train_accuracy: 76.17%, Train_loss: 0.541459, Test_accuracy: 64.40%, Test_loss: 0.642314\n",
      "batch size: 1024, fold: 4| Epoch 32: Train_accuracy: 75.51%, Train_loss: 0.545176, Test_accuracy: 65.17%, Test_loss: 0.636869\n",
      "batch size: 1024, fold: 4| Epoch 33: Train_accuracy: 76.80%, Train_loss: 0.537879, Test_accuracy: 66.35%, Test_loss: 0.627003\n",
      "batch size: 1024, fold: 4| Epoch 34: Train_accuracy: 76.02%, Train_loss: 0.542412, Test_accuracy: 66.11%, Test_loss: 0.628090\n",
      "batch size: 1024, fold: 4| Epoch 35: Train_accuracy: 76.45%, Train_loss: 0.539326, Test_accuracy: 64.45%, Test_loss: 0.634407\n",
      "batch size: 1024, fold: 4| Epoch 36: Train_accuracy: 76.18%, Train_loss: 0.538997, Test_accuracy: 65.58%, Test_loss: 0.634416\n",
      "batch size: 1024, fold: 4| Epoch 37: Train_accuracy: 76.20%, Train_loss: 0.539365, Test_accuracy: 64.81%, Test_loss: 0.633882\n",
      "batch size: 1024, fold: 4| Epoch 38: Train_accuracy: 77.08%, Train_loss: 0.531101, Test_accuracy: 65.52%, Test_loss: 0.631462\n",
      "batch size: 1024, fold: 4| Epoch 39: Train_accuracy: 78.06%, Train_loss: 0.524100, Test_accuracy: 65.40%, Test_loss: 0.630837\n",
      "batch size: 1024, fold: 4| Epoch 40: Train_accuracy: 78.23%, Train_loss: 0.526216, Test_accuracy: 66.59%, Test_loss: 0.620585\n",
      "batch size: 1024, fold: 4| Epoch 41: Train_accuracy: 78.89%, Train_loss: 0.520805, Test_accuracy: 67.59%, Test_loss: 0.616620\n",
      "batch size: 1024, fold: 4| Epoch 42: Train_accuracy: 79.19%, Train_loss: 0.513956, Test_accuracy: 66.88%, Test_loss: 0.619572\n",
      "batch size: 1024, fold: 4| Epoch 43: Train_accuracy: 79.20%, Train_loss: 0.515857, Test_accuracy: 67.36%, Test_loss: 0.619970\n",
      "batch size: 1024, fold: 4| Epoch 44: Train_accuracy: 78.26%, Train_loss: 0.523118, Test_accuracy: 65.34%, Test_loss: 0.635126\n",
      "batch size: 1024, fold: 4| Epoch 45: Train_accuracy: 78.63%, Train_loss: 0.518170, Test_accuracy: 66.71%, Test_loss: 0.621709\n",
      "batch size: 1024, fold: 4| Epoch 46: Train_accuracy: 80.09%, Train_loss: 0.506352, Test_accuracy: 66.88%, Test_loss: 0.620420\n",
      "batch size: 1024, fold: 4| Epoch 47: Train_accuracy: 79.35%, Train_loss: 0.511532, Test_accuracy: 67.89%, Test_loss: 0.612642\n",
      "batch size: 1024, fold: 4| Epoch 48: Train_accuracy: 80.14%, Train_loss: 0.503789, Test_accuracy: 66.77%, Test_loss: 0.619567\n",
      "batch size: 1024, fold: 4| Epoch 49: Train_accuracy: 79.81%, Train_loss: 0.508107, Test_accuracy: 67.65%, Test_loss: 0.613480\n",
      "batch size: 1024, fold: 4| Epoch 50: Train_accuracy: 80.54%, Train_loss: 0.500998, Test_accuracy: 68.31%, Test_loss: 0.613049\n",
      "batch size: 1024, fold: 4| Epoch 51: Train_accuracy: 80.28%, Train_loss: 0.502836, Test_accuracy: 67.48%, Test_loss: 0.622286\n",
      "batch size: 1024, fold: 4| Epoch 52: Train_accuracy: 80.64%, Train_loss: 0.500943, Test_accuracy: 67.18%, Test_loss: 0.621438\n",
      "batch size: 1024, fold: 4| Epoch 53: Train_accuracy: 81.40%, Train_loss: 0.495359, Test_accuracy: 69.55%, Test_loss: 0.598707\n",
      "batch size: 1024, fold: 4| Epoch 54: Train_accuracy: 81.04%, Train_loss: 0.496673, Test_accuracy: 65.88%, Test_loss: 0.630477\n",
      "batch size: 1024, fold: 4| Epoch 55: Train_accuracy: 81.87%, Train_loss: 0.490348, Test_accuracy: 66.59%, Test_loss: 0.620295\n",
      "batch size: 1024, fold: 4| Epoch 56: Train_accuracy: 80.71%, Train_loss: 0.497389, Test_accuracy: 66.94%, Test_loss: 0.623354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1024, fold: 4| Epoch 57: Train_accuracy: 81.60%, Train_loss: 0.491440, Test_accuracy: 68.48%, Test_loss: 0.605989\n",
      "batch size: 1024, fold: 4| Epoch 58: Train_accuracy: 81.96%, Train_loss: 0.487981, Test_accuracy: 68.07%, Test_loss: 0.613587\n",
      "batch size: 1024, fold: 4| Epoch 59: Train_accuracy: 81.63%, Train_loss: 0.492763, Test_accuracy: 67.24%, Test_loss: 0.623096\n",
      "batch size: 1024, fold: 4| Epoch 60: Train_accuracy: 82.08%, Train_loss: 0.486768, Test_accuracy: 66.88%, Test_loss: 0.620277\n",
      "batch size: 1024, fold: 4| Epoch 61: Train_accuracy: 82.70%, Train_loss: 0.482771, Test_accuracy: 67.71%, Test_loss: 0.623022\n",
      "batch size: 1024, fold: 4| Epoch 62: Train_accuracy: 82.30%, Train_loss: 0.484688, Test_accuracy: 67.71%, Test_loss: 0.613492\n",
      "batch size: 1024, fold: 4| Epoch 63: Train_accuracy: 83.00%, Train_loss: 0.478019, Test_accuracy: 67.48%, Test_loss: 0.616978\n",
      "batch size: 1024, fold: 4| Epoch 64: Train_accuracy: 83.20%, Train_loss: 0.477217, Test_accuracy: 67.95%, Test_loss: 0.614431\n",
      "batch size: 1024, fold: 4| Epoch 65: Train_accuracy: 83.54%, Train_loss: 0.476247, Test_accuracy: 68.42%, Test_loss: 0.608047\n",
      "batch size: 1024, fold: 4| Epoch 66: Train_accuracy: 83.22%, Train_loss: 0.478240, Test_accuracy: 69.96%, Test_loss: 0.599923\n",
      "batch size: 1024, fold: 4| Epoch 67: Train_accuracy: 82.34%, Train_loss: 0.482538, Test_accuracy: 69.55%, Test_loss: 0.606027\n",
      "batch size: 1024, fold: 4| Epoch 68: Train_accuracy: 82.91%, Train_loss: 0.481046, Test_accuracy: 69.49%, Test_loss: 0.600132\n",
      "batch size: 1024, fold: 4| Epoch 69: Train_accuracy: 83.65%, Train_loss: 0.474799, Test_accuracy: 68.48%, Test_loss: 0.616408\n",
      "batch size: 1024, fold: 4| Epoch 70: Train_accuracy: 83.44%, Train_loss: 0.474720, Test_accuracy: 68.13%, Test_loss: 0.610630\n",
      "batch size: 1024, fold: 4| Epoch 71: Train_accuracy: 83.63%, Train_loss: 0.470958, Test_accuracy: 68.19%, Test_loss: 0.610366\n",
      "batch size: 1024, fold: 4| Epoch 72: Train_accuracy: 83.47%, Train_loss: 0.472128, Test_accuracy: 68.66%, Test_loss: 0.612107\n",
      "batch size: 1024, fold: 4| Epoch 73: Train_accuracy: 84.61%, Train_loss: 0.465298, Test_accuracy: 68.84%, Test_loss: 0.607090\n",
      "batch size: 1024, fold: 4| Epoch 74: Train_accuracy: 83.88%, Train_loss: 0.469269, Test_accuracy: 68.19%, Test_loss: 0.619399\n",
      "batch size: 1024, fold: 4| Epoch 75: Train_accuracy: 83.84%, Train_loss: 0.468587, Test_accuracy: 68.66%, Test_loss: 0.609758\n",
      "batch size: 1024, fold: 4| Epoch 76: Train_accuracy: 84.08%, Train_loss: 0.467563, Test_accuracy: 68.25%, Test_loss: 0.611545\n",
      "batch size: 1024, fold: 4| Epoch 77: Train_accuracy: 84.37%, Train_loss: 0.462951, Test_accuracy: 67.42%, Test_loss: 0.611854\n",
      "batch size: 1024, fold: 4| Epoch 78: Train_accuracy: 84.83%, Train_loss: 0.461929, Test_accuracy: 68.42%, Test_loss: 0.611237\n",
      "batch size: 1024, fold: 4| Epoch 79: Train_accuracy: 84.45%, Train_loss: 0.463561, Test_accuracy: 67.65%, Test_loss: 0.613582\n",
      "batch size: 1024, fold: 4| Epoch 80: Train_accuracy: 85.28%, Train_loss: 0.457726, Test_accuracy: 68.07%, Test_loss: 0.620411\n",
      "batch size: 1024, fold: 4| Epoch 81: Train_accuracy: 84.18%, Train_loss: 0.467482, Test_accuracy: 68.72%, Test_loss: 0.602160\n",
      "batch size: 1024, fold: 4| Epoch 82: Train_accuracy: 84.89%, Train_loss: 0.461545, Test_accuracy: 67.89%, Test_loss: 0.616588\n",
      "batch size: 1024, fold: 4| Epoch 83: Train_accuracy: 85.35%, Train_loss: 0.457014, Test_accuracy: 71.03%, Test_loss: 0.595310\n",
      "batch size: 1024, fold: 4| Epoch 84: Train_accuracy: 85.68%, Train_loss: 0.453746, Test_accuracy: 70.02%, Test_loss: 0.596280\n",
      "batch size: 1024, fold: 4| Epoch 85: Train_accuracy: 84.86%, Train_loss: 0.458471, Test_accuracy: 68.66%, Test_loss: 0.600241\n",
      "batch size: 1024, fold: 4| Epoch 86: Train_accuracy: 84.85%, Train_loss: 0.458767, Test_accuracy: 69.67%, Test_loss: 0.597186\n",
      "batch size: 1024, fold: 4| Epoch 87: Train_accuracy: 86.70%, Train_loss: 0.447422, Test_accuracy: 69.43%, Test_loss: 0.607823\n",
      "batch size: 1024, fold: 4| Epoch 88: Train_accuracy: 85.39%, Train_loss: 0.455240, Test_accuracy: 69.55%, Test_loss: 0.598835\n",
      "batch size: 1024, fold: 4| Epoch 89: Train_accuracy: 85.37%, Train_loss: 0.452202, Test_accuracy: 69.08%, Test_loss: 0.599052\n",
      "batch size: 1024, fold: 4| Epoch 90: Train_accuracy: 85.51%, Train_loss: 0.453470, Test_accuracy: 69.85%, Test_loss: 0.593483\n",
      "batch size: 1024, fold: 4| Epoch 91: Train_accuracy: 85.59%, Train_loss: 0.454369, Test_accuracy: 69.79%, Test_loss: 0.601487\n",
      "batch size: 1024, fold: 4| Epoch 92: Train_accuracy: 86.05%, Train_loss: 0.450517, Test_accuracy: 68.78%, Test_loss: 0.604364\n",
      "batch size: 1024, fold: 4| Epoch 93: Train_accuracy: 86.22%, Train_loss: 0.449377, Test_accuracy: 69.25%, Test_loss: 0.603441\n",
      "batch size: 1024, fold: 4| Epoch 94: Train_accuracy: 86.33%, Train_loss: 0.445849, Test_accuracy: 69.73%, Test_loss: 0.599395\n",
      "batch size: 1024, fold: 4| Epoch 95: Train_accuracy: 87.02%, Train_loss: 0.438075, Test_accuracy: 70.02%, Test_loss: 0.603634\n",
      "batch size: 1024, fold: 4| Epoch 96: Train_accuracy: 86.94%, Train_loss: 0.443876, Test_accuracy: 69.73%, Test_loss: 0.598092\n",
      "batch size: 1024, fold: 4| Epoch 97: Train_accuracy: 86.58%, Train_loss: 0.445762, Test_accuracy: 70.44%, Test_loss: 0.591949\n",
      "batch size: 1024, fold: 4| Epoch 98: Train_accuracy: 87.20%, Train_loss: 0.439871, Test_accuracy: 70.02%, Test_loss: 0.599120\n",
      "batch size: 1024, fold: 4| Epoch 99: Train_accuracy: 85.91%, Train_loss: 0.450713, Test_accuracy: 68.54%, Test_loss: 0.605604\n",
      "batch size: 1024, fold: 4| Epoch 100: Train_accuracy: 86.76%, Train_loss: 0.443223, Test_accuracy: 68.48%, Test_loss: 0.608666\n",
      "batch size: 1024, fold: 5| Epoch 1: Train_accuracy: 51.39%, Train_loss: 0.692308, Test_accuracy: 53.65%, Test_loss: 0.689952\n",
      "batch size: 1024, fold: 5| Epoch 2: Train_accuracy: 55.04%, Train_loss: 0.689453, Test_accuracy: 54.36%, Test_loss: 0.686483\n",
      "batch size: 1024, fold: 5| Epoch 3: Train_accuracy: 55.41%, Train_loss: 0.684315, Test_accuracy: 56.97%, Test_loss: 0.680648\n",
      "batch size: 1024, fold: 5| Epoch 4: Train_accuracy: 57.69%, Train_loss: 0.678428, Test_accuracy: 56.67%, Test_loss: 0.680969\n",
      "batch size: 1024, fold: 5| Epoch 5: Train_accuracy: 58.74%, Train_loss: 0.672633, Test_accuracy: 57.26%, Test_loss: 0.672819\n",
      "batch size: 1024, fold: 5| Epoch 6: Train_accuracy: 59.75%, Train_loss: 0.666246, Test_accuracy: 58.27%, Test_loss: 0.673670\n",
      "batch size: 1024, fold: 5| Epoch 7: Train_accuracy: 61.15%, Train_loss: 0.660534, Test_accuracy: 58.74%, Test_loss: 0.666720\n",
      "batch size: 1024, fold: 5| Epoch 8: Train_accuracy: 62.41%, Train_loss: 0.651852, Test_accuracy: 58.21%, Test_loss: 0.670456\n",
      "batch size: 1024, fold: 5| Epoch 9: Train_accuracy: 62.80%, Train_loss: 0.647528, Test_accuracy: 60.17%, Test_loss: 0.664699\n",
      "batch size: 1024, fold: 5| Epoch 10: Train_accuracy: 63.85%, Train_loss: 0.640495, Test_accuracy: 60.23%, Test_loss: 0.663076\n",
      "batch size: 1024, fold: 5| Epoch 11: Train_accuracy: 64.03%, Train_loss: 0.640107, Test_accuracy: 60.58%, Test_loss: 0.661374\n",
      "batch size: 1024, fold: 5| Epoch 12: Train_accuracy: 65.17%, Train_loss: 0.630008, Test_accuracy: 62.06%, Test_loss: 0.651213\n",
      "batch size: 1024, fold: 5| Epoch 13: Train_accuracy: 65.71%, Train_loss: 0.622895, Test_accuracy: 61.89%, Test_loss: 0.646868\n",
      "batch size: 1024, fold: 5| Epoch 14: Train_accuracy: 67.33%, Train_loss: 0.618314, Test_accuracy: 61.83%, Test_loss: 0.651613\n",
      "batch size: 1024, fold: 5| Epoch 15: Train_accuracy: 68.63%, Train_loss: 0.609360, Test_accuracy: 62.83%, Test_loss: 0.648820\n",
      "batch size: 1024, fold: 5| Epoch 16: Train_accuracy: 68.65%, Train_loss: 0.603734, Test_accuracy: 61.59%, Test_loss: 0.658953\n",
      "batch size: 1024, fold: 5| Epoch 17: Train_accuracy: 68.19%, Train_loss: 0.607669, Test_accuracy: 62.89%, Test_loss: 0.646853\n",
      "batch size: 1024, fold: 5| Epoch 18: Train_accuracy: 68.96%, Train_loss: 0.601321, Test_accuracy: 64.37%, Test_loss: 0.638322\n",
      "batch size: 1024, fold: 5| Epoch 19: Train_accuracy: 69.42%, Train_loss: 0.599083, Test_accuracy: 64.20%, Test_loss: 0.642171\n",
      "batch size: 1024, fold: 5| Epoch 20: Train_accuracy: 70.33%, Train_loss: 0.593721, Test_accuracy: 63.43%, Test_loss: 0.641484\n",
      "batch size: 1024, fold: 5| Epoch 21: Train_accuracy: 70.63%, Train_loss: 0.588236, Test_accuracy: 64.26%, Test_loss: 0.643983\n",
      "batch size: 1024, fold: 5| Epoch 22: Train_accuracy: 71.39%, Train_loss: 0.583286, Test_accuracy: 64.73%, Test_loss: 0.636269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1024, fold: 5| Epoch 23: Train_accuracy: 71.96%, Train_loss: 0.581904, Test_accuracy: 64.14%, Test_loss: 0.639417\n",
      "batch size: 1024, fold: 5| Epoch 24: Train_accuracy: 72.33%, Train_loss: 0.578195, Test_accuracy: 65.44%, Test_loss: 0.634641\n",
      "batch size: 1024, fold: 5| Epoch 25: Train_accuracy: 72.01%, Train_loss: 0.577045, Test_accuracy: 65.15%, Test_loss: 0.630808\n",
      "batch size: 1024, fold: 5| Epoch 26: Train_accuracy: 72.87%, Train_loss: 0.572309, Test_accuracy: 64.67%, Test_loss: 0.639194\n",
      "batch size: 1024, fold: 5| Epoch 27: Train_accuracy: 73.71%, Train_loss: 0.564387, Test_accuracy: 66.21%, Test_loss: 0.623874\n",
      "batch size: 1024, fold: 5| Epoch 28: Train_accuracy: 73.37%, Train_loss: 0.564872, Test_accuracy: 65.50%, Test_loss: 0.624753\n",
      "batch size: 1024, fold: 5| Epoch 29: Train_accuracy: 73.61%, Train_loss: 0.561308, Test_accuracy: 65.38%, Test_loss: 0.635943\n",
      "batch size: 1024, fold: 5| Epoch 30: Train_accuracy: 74.54%, Train_loss: 0.556393, Test_accuracy: 65.86%, Test_loss: 0.623055\n",
      "batch size: 1024, fold: 5| Epoch 31: Train_accuracy: 74.41%, Train_loss: 0.555507, Test_accuracy: 65.50%, Test_loss: 0.626385\n",
      "batch size: 1024, fold: 5| Epoch 32: Train_accuracy: 75.39%, Train_loss: 0.548340, Test_accuracy: 66.57%, Test_loss: 0.618702\n",
      "batch size: 1024, fold: 5| Epoch 33: Train_accuracy: 74.94%, Train_loss: 0.549986, Test_accuracy: 67.28%, Test_loss: 0.619206\n",
      "batch size: 1024, fold: 5| Epoch 34: Train_accuracy: 76.21%, Train_loss: 0.543788, Test_accuracy: 67.58%, Test_loss: 0.611616\n",
      "batch size: 1024, fold: 5| Epoch 35: Train_accuracy: 76.32%, Train_loss: 0.539804, Test_accuracy: 66.21%, Test_loss: 0.631477\n",
      "batch size: 1024, fold: 5| Epoch 36: Train_accuracy: 75.98%, Train_loss: 0.544094, Test_accuracy: 67.40%, Test_loss: 0.620274\n",
      "batch size: 1024, fold: 5| Epoch 37: Train_accuracy: 76.32%, Train_loss: 0.540066, Test_accuracy: 67.28%, Test_loss: 0.614428\n",
      "batch size: 1024, fold: 5| Epoch 38: Train_accuracy: 76.75%, Train_loss: 0.535196, Test_accuracy: 65.44%, Test_loss: 0.623559\n",
      "batch size: 1024, fold: 5| Epoch 39: Train_accuracy: 76.50%, Train_loss: 0.536980, Test_accuracy: 67.04%, Test_loss: 0.627139\n",
      "batch size: 1024, fold: 5| Epoch 40: Train_accuracy: 77.35%, Train_loss: 0.530661, Test_accuracy: 68.52%, Test_loss: 0.615983\n",
      "batch size: 1024, fold: 5| Epoch 41: Train_accuracy: 77.77%, Train_loss: 0.528113, Test_accuracy: 67.34%, Test_loss: 0.621834\n",
      "batch size: 1024, fold: 5| Epoch 42: Train_accuracy: 78.07%, Train_loss: 0.526954, Test_accuracy: 68.70%, Test_loss: 0.602808\n",
      "batch size: 1024, fold: 5| Epoch 43: Train_accuracy: 77.28%, Train_loss: 0.529927, Test_accuracy: 66.45%, Test_loss: 0.624130\n",
      "batch size: 1024, fold: 5| Epoch 44: Train_accuracy: 78.69%, Train_loss: 0.519170, Test_accuracy: 66.33%, Test_loss: 0.619879\n",
      "batch size: 1024, fold: 5| Epoch 45: Train_accuracy: 77.80%, Train_loss: 0.524794, Test_accuracy: 67.22%, Test_loss: 0.622974\n",
      "batch size: 1024, fold: 5| Epoch 46: Train_accuracy: 78.92%, Train_loss: 0.515249, Test_accuracy: 66.45%, Test_loss: 0.622492\n",
      "batch size: 1024, fold: 5| Epoch 47: Train_accuracy: 78.78%, Train_loss: 0.518019, Test_accuracy: 67.58%, Test_loss: 0.613640\n",
      "batch size: 1024, fold: 5| Epoch 48: Train_accuracy: 79.71%, Train_loss: 0.510709, Test_accuracy: 67.99%, Test_loss: 0.607079\n",
      "batch size: 1024, fold: 5| Epoch 49: Train_accuracy: 79.55%, Train_loss: 0.512507, Test_accuracy: 67.63%, Test_loss: 0.612130\n",
      "batch size: 1024, fold: 5| Epoch 50: Train_accuracy: 79.84%, Train_loss: 0.509709, Test_accuracy: 69.65%, Test_loss: 0.595664\n",
      "batch size: 1024, fold: 5| Epoch 51: Train_accuracy: 79.90%, Train_loss: 0.508363, Test_accuracy: 70.01%, Test_loss: 0.604990\n",
      "batch size: 1024, fold: 5| Epoch 52: Train_accuracy: 80.39%, Train_loss: 0.505940, Test_accuracy: 68.05%, Test_loss: 0.613432\n",
      "batch size: 1024, fold: 5| Epoch 53: Train_accuracy: 80.72%, Train_loss: 0.498774, Test_accuracy: 69.24%, Test_loss: 0.601281\n",
      "batch size: 1024, fold: 5| Epoch 54: Train_accuracy: 80.32%, Train_loss: 0.504242, Test_accuracy: 68.11%, Test_loss: 0.610428\n",
      "batch size: 1024, fold: 5| Epoch 55: Train_accuracy: 80.66%, Train_loss: 0.501140, Test_accuracy: 67.93%, Test_loss: 0.611335\n",
      "batch size: 1024, fold: 5| Epoch 56: Train_accuracy: 80.70%, Train_loss: 0.499307, Test_accuracy: 69.35%, Test_loss: 0.605314\n",
      "batch size: 1024, fold: 5| Epoch 57: Train_accuracy: 80.70%, Train_loss: 0.500156, Test_accuracy: 67.99%, Test_loss: 0.610184\n",
      "batch size: 1024, fold: 5| Epoch 58: Train_accuracy: 80.97%, Train_loss: 0.494671, Test_accuracy: 68.46%, Test_loss: 0.603849\n",
      "batch size: 1024, fold: 5| Epoch 59: Train_accuracy: 81.38%, Train_loss: 0.493592, Test_accuracy: 68.46%, Test_loss: 0.602825\n",
      "batch size: 1024, fold: 5| Epoch 60: Train_accuracy: 82.03%, Train_loss: 0.488812, Test_accuracy: 68.94%, Test_loss: 0.609634\n",
      "batch size: 1024, fold: 5| Epoch 61: Train_accuracy: 81.65%, Train_loss: 0.489719, Test_accuracy: 68.88%, Test_loss: 0.607270\n",
      "batch size: 1024, fold: 5| Epoch 62: Train_accuracy: 82.26%, Train_loss: 0.487278, Test_accuracy: 67.87%, Test_loss: 0.612969\n",
      "batch size: 1024, fold: 5| Epoch 63: Train_accuracy: 81.68%, Train_loss: 0.490386, Test_accuracy: 68.41%, Test_loss: 0.606445\n",
      "batch size: 1024, fold: 5| Epoch 64: Train_accuracy: 82.58%, Train_loss: 0.483129, Test_accuracy: 69.95%, Test_loss: 0.596665\n",
      "batch size: 1024, fold: 5| Epoch 65: Train_accuracy: 81.83%, Train_loss: 0.485506, Test_accuracy: 69.77%, Test_loss: 0.595532\n",
      "batch size: 1024, fold: 5| Epoch 66: Train_accuracy: 82.36%, Train_loss: 0.483541, Test_accuracy: 68.41%, Test_loss: 0.605234\n",
      "batch size: 1024, fold: 5| Epoch 67: Train_accuracy: 82.55%, Train_loss: 0.481280, Test_accuracy: 68.82%, Test_loss: 0.602606\n",
      "batch size: 1024, fold: 5| Epoch 68: Train_accuracy: 81.98%, Train_loss: 0.487611, Test_accuracy: 70.42%, Test_loss: 0.587825\n",
      "batch size: 1024, fold: 5| Epoch 69: Train_accuracy: 82.82%, Train_loss: 0.478960, Test_accuracy: 70.07%, Test_loss: 0.587329\n",
      "batch size: 1024, fold: 5| Epoch 70: Train_accuracy: 83.75%, Train_loss: 0.473476, Test_accuracy: 69.47%, Test_loss: 0.596004\n",
      "batch size: 1024, fold: 5| Epoch 71: Train_accuracy: 83.43%, Train_loss: 0.477686, Test_accuracy: 69.77%, Test_loss: 0.593592\n",
      "batch size: 1024, fold: 5| Epoch 72: Train_accuracy: 83.75%, Train_loss: 0.471988, Test_accuracy: 69.71%, Test_loss: 0.594495\n",
      "batch size: 1024, fold: 5| Epoch 73: Train_accuracy: 83.22%, Train_loss: 0.477353, Test_accuracy: 69.53%, Test_loss: 0.601346\n",
      "batch size: 1024, fold: 5| Epoch 74: Train_accuracy: 83.84%, Train_loss: 0.469419, Test_accuracy: 69.89%, Test_loss: 0.597873\n",
      "batch size: 1024, fold: 5| Epoch 75: Train_accuracy: 83.22%, Train_loss: 0.477008, Test_accuracy: 69.53%, Test_loss: 0.593253\n",
      "batch size: 1024, fold: 5| Epoch 76: Train_accuracy: 83.68%, Train_loss: 0.470842, Test_accuracy: 70.66%, Test_loss: 0.585630\n",
      "batch size: 1024, fold: 5| Epoch 77: Train_accuracy: 84.00%, Train_loss: 0.470669, Test_accuracy: 70.60%, Test_loss: 0.590563\n",
      "batch size: 1024, fold: 5| Epoch 78: Train_accuracy: 83.72%, Train_loss: 0.469126, Test_accuracy: 71.31%, Test_loss: 0.582192\n",
      "batch size: 1024, fold: 5| Epoch 79: Train_accuracy: 84.92%, Train_loss: 0.460347, Test_accuracy: 70.36%, Test_loss: 0.593814\n",
      "batch size: 1024, fold: 5| Epoch 80: Train_accuracy: 84.02%, Train_loss: 0.470349, Test_accuracy: 68.82%, Test_loss: 0.606191\n",
      "batch size: 1024, fold: 5| Epoch 81: Train_accuracy: 84.38%, Train_loss: 0.465361, Test_accuracy: 69.71%, Test_loss: 0.598521\n",
      "batch size: 1024, fold: 5| Epoch 82: Train_accuracy: 84.86%, Train_loss: 0.461474, Test_accuracy: 67.81%, Test_loss: 0.606896\n",
      "batch size: 1024, fold: 5| Epoch 83: Train_accuracy: 84.98%, Train_loss: 0.459845, Test_accuracy: 72.20%, Test_loss: 0.579950\n",
      "batch size: 1024, fold: 5| Epoch 84: Train_accuracy: 84.67%, Train_loss: 0.461974, Test_accuracy: 70.30%, Test_loss: 0.596726\n",
      "batch size: 1024, fold: 5| Epoch 85: Train_accuracy: 85.40%, Train_loss: 0.458049, Test_accuracy: 69.06%, Test_loss: 0.600065\n",
      "batch size: 1024, fold: 5| Epoch 86: Train_accuracy: 85.23%, Train_loss: 0.458370, Test_accuracy: 70.95%, Test_loss: 0.588031\n",
      "batch size: 1024, fold: 5| Epoch 87: Train_accuracy: 84.89%, Train_loss: 0.460523, Test_accuracy: 71.31%, Test_loss: 0.584124\n",
      "batch size: 1024, fold: 5| Epoch 88: Train_accuracy: 85.15%, Train_loss: 0.457032, Test_accuracy: 69.53%, Test_loss: 0.599688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1024, fold: 5| Epoch 89: Train_accuracy: 86.08%, Train_loss: 0.450664, Test_accuracy: 69.65%, Test_loss: 0.598799\n",
      "batch size: 1024, fold: 5| Epoch 90: Train_accuracy: 85.59%, Train_loss: 0.453012, Test_accuracy: 69.71%, Test_loss: 0.597551\n",
      "batch size: 1024, fold: 5| Epoch 91: Train_accuracy: 85.43%, Train_loss: 0.455021, Test_accuracy: 69.95%, Test_loss: 0.593850\n",
      "batch size: 1024, fold: 5| Epoch 92: Train_accuracy: 85.74%, Train_loss: 0.452243, Test_accuracy: 70.36%, Test_loss: 0.589383\n",
      "batch size: 1024, fold: 5| Epoch 93: Train_accuracy: 85.99%, Train_loss: 0.450293, Test_accuracy: 71.96%, Test_loss: 0.578022\n",
      "batch size: 1024, fold: 5| Epoch 94: Train_accuracy: 85.93%, Train_loss: 0.450104, Test_accuracy: 71.13%, Test_loss: 0.586021\n",
      "batch size: 1024, fold: 5| Epoch 95: Train_accuracy: 85.31%, Train_loss: 0.457021, Test_accuracy: 70.42%, Test_loss: 0.597054\n",
      "batch size: 1024, fold: 5| Epoch 96: Train_accuracy: 86.20%, Train_loss: 0.448101, Test_accuracy: 70.42%, Test_loss: 0.593416\n",
      "batch size: 1024, fold: 5| Epoch 97: Train_accuracy: 86.14%, Train_loss: 0.447862, Test_accuracy: 70.66%, Test_loss: 0.585332\n",
      "batch size: 1024, fold: 5| Epoch 98: Train_accuracy: 86.67%, Train_loss: 0.444414, Test_accuracy: 70.12%, Test_loss: 0.599027\n",
      "batch size: 1024, fold: 5| Epoch 99: Train_accuracy: 85.84%, Train_loss: 0.449190, Test_accuracy: 70.07%, Test_loss: 0.593596\n",
      "batch size: 1024, fold: 5| Epoch 100: Train_accuracy: 86.20%, Train_loss: 0.448736, Test_accuracy: 70.24%, Test_loss: 0.586580\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# YOUR CODE HERE\n",
    "from common_utils import train_loop, test_loop, EarlyStopper\n",
    "\n",
    "def intialise_loaders(X_train_scaled, y_train, X_test_scaled, y_test, bs):\n",
    "    # YOUR CODE HERE\n",
    "    train_dataset = CustomDataset(X_train_scaled, y_train)\n",
    "    test_dataset = CustomDataset(X_test_scaled, y_test)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=bs, shuffle=True)\n",
    "    return train_dataloader, test_dataloader\n",
    "            \n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, hyperparameter):\n",
    "    \"\"\"\n",
    "    Train and evaluate models with different batch sizes and a specified hyperparameter.\n",
    "\n",
    "    Args:\n",
    "    - X_train_scaled_dict (dict): Dictionary of preprocessed training data for different batch sizes.\n",
    "    - X_val_scaled_dict (dict): Dictionary of preprocessed validation data for different batch sizes.\n",
    "    - y_train_dict (dict): Dictionary of labels for the training data for different batch sizes.\n",
    "    - y_val_dict (dict): Dictionary of labels for the validation data for different batch sizes.\n",
    "    - batch_sizes (list): List of batch sizes to experiment with.\n",
    "    - hyperparameter (float): The hyperparameter to use for model training.\n",
    "\n",
    "    Returns:\n",
    "    - results (dict): A dictionary containing batch sizes as keys and their corresponding evaluation metrics as values.\n",
    "    \"\"\"\n",
    "\n",
    "    cross_validation_accuracies = {128: [], 256: [], 512: [], 1024: []}\n",
    "    cross_validation_times = {128: [], 256: [], 512: [], 1024: []}\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        \n",
    "        for fold in range(5):  # 5-fold cross-validation\n",
    "            # Create and train your neural network using the current batch size and hyperparameter\n",
    "            model = MLP(no_features=X_train_scaled_dict[batch_size][fold].shape[1], no_hidden=128, no_labels=2)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            X_train = X_train_scaled_dict[batch_size][fold]\n",
    "            y_train = y_train_dict[batch_size][fold]\n",
    "            X_val = X_val_scaled_dict[batch_size][fold]\n",
    "            y_val = y_val_dict[batch_size][fold]\n",
    "            \n",
    "            train_dataloader, test_dataloader = intialise_loaders(X_train, y_train, X_val, y_val, batch_size)\n",
    "            epochs = 100\n",
    "#             early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "            tr_loss, tr_correct = [], []\n",
    "            te_loss, te_correct = [], []\n",
    "            epoch_training_time_list = []\n",
    "            \n",
    "            # Train your model on X_train and y_train\n",
    "            for t in range(epochs):\n",
    "                epoch_starttime = time.time()                \n",
    "                train_loss, train_correct = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "                epoch_training_time = time.time()-epoch_starttime\n",
    "                epoch_training_time_list.append(epoch_training_time)\n",
    "                \n",
    "                test_loss, test_correct = test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "                tr_loss.append(train_loss), tr_correct.append(train_correct)\n",
    "                te_loss.append(test_loss), te_correct.append(test_correct)\n",
    "                \n",
    "                print(f\"batch size: {batch_size}, fold: {fold+1}| Epoch {t+1}: Train_accuracy: {(100*train_correct):>0.2f}%, Train_loss: {train_loss:>8f}, Test_accuracy: {(100*test_correct):>0.2f}%, Test_loss: {test_loss:>8f}\")\n",
    "\n",
    "#                 if early_stopper.early_stop(test_loss): \n",
    "#                     print(\"Done!\")\n",
    "#                     break\n",
    "            cross_validation_accuracies[batch_size].append(te_correct[-1])\n",
    "            cross_validation_times[batch_size].append(epoch_training_time_list[-1])\n",
    "            \n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975e552e751c4efb2cec0eac214f85cd",
     "grade": true,
     "grade_id": "correct_hyperparameter_tuning",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17599eb29fd6e3a1e2812f0ff7cba983",
     "grade": true,
     "grade_id": "plot",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{128: [0.7274881516587678, 0.7345971563981043, 0.7144549763033176, 0.7079383886255924, 0.7296976882039122], 256: [0.7215639810426541, 0.7156398104265402, 0.7257109004739336, 0.6937203791469194, 0.7291049199762892], 512: [0.7091232227488151, 0.7197867298578199, 0.7191943127962085, 0.7008293838862559, 0.7267338470657972], 1024: [0.7014218009478673, 0.6943127962085308, 0.6877962085308057, 0.6848341232227488, 0.7024303497332542]}\n",
      "{128: [0.28375864028930664, 0.2619607448577881, 0.25820088386535645, 0.25817370414733887, 0.25881195068359375], 256: [0.2079000473022461, 0.1935882568359375, 0.306612491607666, 0.19943928718566895, 0.31197237968444824], 512: [0.15975379943847656, 0.14052271842956543, 0.13503193855285645, 0.13271427154541016, 0.14849138259887695], 1024: [0.11652207374572754, 0.13413786888122559, 0.17096233367919922, 0.11851000785827637, 0.13404107093811035]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the mean accuracies for each batch size\n",
    "batch_sizes = []\n",
    "mean_accuracies = []\n",
    "\n",
    "for batch_size, accuracies in cross_validation_accuracies.items():\n",
    "    batch_sizes.append(batch_size)\n",
    "    mean_accuracies.append(sum(accuracies) / len(accuracies))\n",
    "# Create a scatterplot\n",
    "plt.scatter(batch_sizes, mean_accuracies, label='Mean Accuracies', marker='x')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Mean Accuracies vs. Batch Size')\n",
    "plt.xticks(batch_sizes)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
   "metadata": {
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18e30a9850c282ad725336848222a62",
     "grade": false,
     "grade_id": "times",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch Size  Last Epoch Time\n",
      "0         128         0.264181\n",
      "1         256         0.243902\n",
      "2         512         0.143303\n",
      "3        1024         0.134835\n",
      "[0.722835272237939, 0.7171479982132674, 0.7151334992709792, 0.6941590557286414]\n",
      "[0.26418118476867675, 0.24390249252319335, 0.1433028221130371, 0.1348346710205078]\n",
      "3.9671855553637183\n",
      "0.28169550780962305\n",
      "-3.3117687214344538\n",
      "-95.929713603481\n",
      "-8.314261996955624\n",
      "-70.20076012934577\n"
     ]
    }
   ],
   "source": [
    "mean_times = [sum(values) / len(values) for key, values in cross_validation_times.items()]\n",
    "df = pd.DataFrame({'Batch Size': [128, 256, 512, 1024],\n",
    "                   'Last Epoch Time':mean_times\n",
    "                  })\n",
    "\n",
    "print(df)\n",
    "# print(mean_accuracies)\n",
    "# print(mean_times)\n",
    "# print((mean_accuracies[0]-mean_accuracies[3])*100/mean_accuracies[0])\n",
    "# print((mean_accuracies[1]-mean_accuracies[2])*100/mean_accuracies[2])\n",
    "# print((mean_accuracies[3]-mean_accuracies[1])*100/mean_accuracies[3])\n",
    "\n",
    "# print((mean_times[3]-mean_times[0])*100/mean_times[3])\n",
    "# print((mean_times[1]-mean_times[0])*100/mean_times[1])\n",
    "# print((mean_times[2]-mean_times[1])*100/mean_times[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fc4a52c2a0af7ea586ea85cec9b3e9",
     "grade": true,
     "grade_id": "correct_times",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 256\n",
    "reason =\"\"\"-The training time for each batch size [128, 256, 512, 1024] has been calculated by averaging the last epoch training times over the 5 folds. \n",
    "-The fastest training time is achieved by batch size 1024 but the accuracy is the lowest ie., 0.6942. \n",
    "-The accuracy of batch size 128 is the highest and it is 3.97% higher than the accuracy of batch size 1024.\n",
    "-The training time difference between the batch sizes of 1024 and 128 is significant (137.37% difference).\n",
    "-Analysing the numbers, the ideal batch size is 256. It has an ideal compromise between training time and mean accuracy.\n",
    "-The values of batch size 256 has similar values to batch size 512 but since 256 has a better accuracy and a slightly slower training time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f695b961ed43ec6a31b7647e078fd8d6",
     "grade": true,
     "grade_id": "correct_batch_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
